row,Desc_content,Requirements
/job/avp-ai-deployment-engineer-ibg-digital-institutional-banking-group-dbs-bank-ed58ebbae1bdf3f2d7af4cb80d25bcea,"Job Purpose  The AI (Artificial Intelligence) Deployment Engineer will provide software engineering support to the Institutional Banking Group (IBG) Business Analytics Team in various data science projects. This role’s primary job responsibility is facilitating the wrapping of data science work into a viable product. The right candidate will be one excited by opportunities to apply software engineering in the fast-growing area of AI, help build AI development and production infrastructure, as well as to set technical standards. Responsibilities  Build, manage and automate pipelines for AI model development Adopt maintainable, readable, modular solutions using modern software engineering best practices Transform Data Science work into pilot and minimum viable products Perform code optimization, code reviews to improve the quality of Data Scientist’s work Create APIs for integrate data source into applications Create APIs for downstream usage of AI models Create visualisations to display views of AI models Keep track of model development iterations with a versioning control system  Automate software testing: unit test, branch test, integration test and security test  Monitor AI model releases, branches for different issues and user stories ","Requirements Master’s Degree in software Engineering, Computer Science or related fields with minimum 5 years software engineering work experience on enterprise products Experience with multi-tier software application development with best software engineering practices Familiar with tools such as Anaconda, Jupyter, Eclipse, R Studio, Jira, Git, SVN, Jenkins, etc Demonstrated proficiency in Python (Pandas, SciPy, NumPy, PySpark, etc), Scala, R, Java, Java Script, SQL, Shell Script  Experience with big data stack (Hadoop, Spark, Kafka, etc), and structured (SQL) and unstructured databases (Graph Database, NoSQL) Experience with virtual computing (virtual machine and Docker) for creation of easily transportable and self-contained environments Experience with converting AI models and integrating them into production Experience with code reviews, building interfaces, and deployment systems Demonstrated strong interests in learning about AI through own initiatives "
/job/senior-associate-ai-deployment-engineer-ibg-digital-institutional-banking-group-dbs-bank-952541ff26aba4d294d73ad80645597c,"Job Purpose  The AI (Artificial Intelligence) Deployment Engineer will provide software engineering support to the Institutional Banking Group (IBG) Business Analytics Team in various data science projects. This role’s primary job responsibility is facilitating the wrapping of data science work into a viable product. The right candidate will be one excited by opportunities to apply software engineering in the fast-growing area of AI, help build AI development and production infrastructure, as well as to set technical standards. Responsibilities  Build, manage and automate pipelines for AI model development Adopt maintainable, readable, modular solutions using modern software engineering best practices Transform Data Science work into pilot and minimum viable products Perform code optimization, code reviews to improve the quality of Data Scientist’s work Create APIs for integrate data source into applications Create APIs for downstream usage of AI models Create visualisations to display views of AI models Keep track of model development iterations with a versioning control system  Automate software testing: unit test, branch test, integration test and security test  Monitor AI model releases, branches for different issues and user stories ","Requirements Master’s Degree in software Engineering, Computer Science or related fields with minimum 5 years software engineering work experience on enterprise products Experience with multi-tier software application development with best software engineering practices Familiar with tools such as Anaconda, Jupyter, Eclipse, R Studio, Jira, Git, SVN, Jenkins, etc Demonstrated proficiency in Python (Pandas, SciPy, NumPy, PySpark, etc), Scala, R, Java, Java Script, SQL, Shell Script  Experience with big data stack (Hadoop, Spark, Kafka, etc), and structured (SQL) and unstructured databases (Graph Database, NoSQL) Experience with virtual computing (virtual machine and Docker) for creation of easily transportable and self-contained environments Experience with converting AI models and integrating them into production Experience with code reviews, building interfaces, and deployment systems Demonstrated strong interests in learning about AI through own initiatives "
/job/data-scientist-sephora-digital-sea-6ab4ba4202655abf13f033b752f440ba,"Sephora, a division of LVMH – Moët Hennessy Louis Vuitton global luxury leader, is a global leader in beauty retailing. It successfully operates more than three thousand points of sale across Americas, Europe, Middle East and Asia. Its aim is to animate the most loved beauty community in the world. Sephora South East Asia is a high growth division of leading global beauty retailer, Sephora. Our teams run omni-channel retail businesses in Singapore, Thailand, Australia and Malaysia, franchise operations in India & Indonesia and we run ecommerce only businesses (the first in the world globally for Sephora!) in Philippines, Hong Kong and New Zealand. Our success is built on innovation, a unique product portfolio, market leading digital capability, and our exceptional people! With ambitious growth plans we are always looking for talented people who are passionate about building businesses and developing themselves and our customers'​experience. The Sephora Data team is expanding. As a critical business function, finding the right people to contribute to our high growth, fast changing environment is critical and challenging. The Data team’s mission is to create the necessary data pipelines between our applications and enable teams across the business to use the date for informed decision making.   To succeed in this team You’ll be super smart, passionate about innovation and trying new approaches, and you’ll be a skilled programmer with strong commercial instincts and passion for business success. We are looking for an exceptional Data Scientist to add to our team. To be successful in this role  You will need to be well-versed in all major Machine Learning paradigms (including but not restricted to processing of structured and unstructured data, bias/variance tradeoff, classic classification/regression algorithms, deep learning concepts, representation learning, explainability, unsupervised methods). You will need to be able to communicate clearly with our internal stakeholders, technical or non-technical, deeply understand business priorities and formalize them into challenges that can be tackled with engineering effort, whether it may involve ML or not. You will enjoy being an advocate for Data Science within Sephora SEA and the LVMH group. This involves being naturally prone to knowledge sharing and promotion of a healthy intellectual sharing environment. You will need to be able to work autonomously and have the initiative to come up with original solutions to meaningful challenges. You will need to be able to deal with several concurrent projects and prioritize according to objectives and business impact. ","Requirements You are a Python master and numerical libraries are of no mystery to you. Big bonus points if you are also familiar with either of Node.js/Go. You write SQL like you write English. Bonus points if BigQuery is not unknown to you. Expertise in a deep learning framework (tensorflow/pytorch) is a big plus. You have experience in getting your hands dirty and are conscious of the reality of datasets (in contrast to academic datasets). You are result-driven. Not only do you care about benchmarks scores, you are also keen on deploying your algorithms and make them available to use to your stakeholders. Experience with Cloud services (Google Cloud/AWS) for Machine Learning pipeline deployment is highly appreciated.    If taking on the responsibilities of one or more of these roles seems like your ideal job or you have other ideas of how you can contribute to our team, please apply! Your attitude, experience and passion is more important than specific experience. You might be a fresh grad, you might have 10 or more years experience. It’s all about the passion to excel that you will bring to our team & our business."
/job/data-scientist-singapore-telecommunications-b495b5797dee28b2ad624403e81945e6,"We are looking for a creative data scientist to join our project team that builds robust cyber security software and services. The candidate will be responsible for building and executing analytics modules:  Own and complete work streams for execution and delivery. Able to make presentations to internal and external stakeholders for own work Able to perform ETL, feature selections, modeling, model validation and conducting data analyses Self-motivated, independent learner, and enjoy sharing knowledge with team members ","Requirements Relevant degree in Computer Science, Computer Engineering, Mathematics, Statistics or a related field with exposure to Machine Learning and/or Advanced Analytics with 2+ years of experience in predictive analytics and exposure to big data analytics Experience in cyber security domain is a plus Strong coding skills in Python is a must Hands-on experience with Python libraries - NumPy, Pandas, sklearn Hands-on knowledge of working with scalable platforms such as Hive, Hadoop or Spark (PySpark) is a plus. Comfortable with working on Unix, Windows and both SQL and NoSQL databases Sound knowledge of machine learning concepts. "
/job/data-scientist-moka-technology-solutions-33525243d898a573696fb6fd709d893e,"Do you have a passion for data? Are you keen to understand the customer journey and improve the customer experience that merchants have with us? Are you looking to push the frontiers of innovation and build the Next Big Data Product? We are looking for Data Scientists who are keen to help us uncover insights in our data and drive big data solutions. You will:  Consult and partner with business and technology stakeholders to understand their problems and develop and implement high impact, data-driven solutions. Utilize various sources of data to support analytical projects, conduct deep dive analysis and create new products. Experience in fraud detection, text mining is a plus.   Deliver key insights and recommendations to drive business. Promote a data and analytics driven culture within the company. ","Requirements Graduate degree in Statistics, Mathematics, Machine Learning, Computer Science, Econometrics or related field. At least 4 years relevant experience (Statistics or Data Science roles). Proven track record in analyzing large scale quantitative data. Deep understanding of statistical and machine learning techniques, knowledge of text analytics a plus. Proficiency in SQL/Hive, R/Python or other programming languages. Experience with distributed systems (Redshift, Hadoop, Spark etc). Excellent communications skills and attention to detail. Team player willing to go the extra mile. "
/job/data-engineer-machine-learning-engineer-oneconnect-financial-technology-cb7271da6bec8cfefa49c74f9184a096,"As a data/Machine learning engineer, your primary goal is to work with data scientist and software developers to implement and deploy machine learning algorithms driven data solutions in commercial environment. You’ll work with data scientist to build specialized tools to facilitate data preprocessing, data quality check, data cleansing, ETL and data integration. You’ll work with backend and frontend app-dev team to implement high performance machine learning algorithms on commercial enterprise software platform. Key requirement:  Advanced degree in Computer Science, Electronic Engineering, Statistics, Applied Mathematics, or related technical fields. Minimum 2 years relevant experience. Proficiency in a high performance programming language such as Java/C++. Good working knowledge in a scripting language such as Python/R. Experience implementing algorithms in big data/cloud computing environment. Experience in solving real-world data challenges and dealing with anomalies. Good knowledge working with relational database and NoSQL database Good communication skills ","RequirementsPreferred requirement:  Experience building labeled datasets from scratch, or developing tools protocol formalizing unstructured unlabeled data. Experience handling high-volume real-time data stream Experience building complete data pipeline, ingesting data from multiple source systems (potentially asynchronous and different rate) Experience building large scale parallel/distributed data processing, machine learning solutions Experience building robust and high-throughput API for analytics-as-a-service solutions Experience working with enterprise app engine technology such as cloud computing, container technology for high availability and robust deployment. "
/job/avp-senior-associate-data-analyst-analytic-center-excellence-transformation-grp-dbs-bank-b7c0e2d50e0b78bef8e80534fc7c81e0,"Job Purpose The data analyst will provide the big data analytic support to the Analytic Center of Excellence. He will partner with business and project leader to discover, analyse and process the data to develop analytic and data science solutions. This position allows those with strong data analytic skill and theoretical understanding of advanced analytic algorithms but lack of hands on experience in advanced analytics to learn and prepare for the role of data scientist - advanced analytics in the future. Responsibilities   Identify, profile, analyze and present the data discovery output for analytic projects Develop data ingestion pipeline and create the analytic data assets for analytic projects Work with data engineer to enhance the analytic data infrastructure and develop enterprise analytic data mart Perform data wrangling and feature engineering for machine learning Create helper functions to automate frequently encountered wrangling and feature engineering tasks ","Requirements Bachelors/Masters in Computer Science, Statistics, Mathematics and other highly quantitative fields such as bio-informatics Minimum 3 years of industry experience in data analytics working in a big data environment, preferably in financial services industry Highly proficient with data wrangling, analytic, transformation and feature engineering using programming tools such as Spark, Python or R. Excellent knowledge of SQL. Excellent visualization and communication skills. "
/job/data-scientist-redmart-3fb28139930ac4848c84ddd669eb070e,"As one of the fastest growing e-commerce and logistics companies in Asia, RedMart is a part of Alibaba-backed Lazada, Southeast Asia’s leading online shopping and selling platform, and we offer an unparalleled scaling a startup experience. We’re focused on always improving our customer experience and achieving our mission: To save our customers time and money for the important things in life!   We are looking for a Data Scientist/Search Engineer who cares deeply about customers and users to help develop the next generation of search and personalization at RedMart. You will build data mining systems to tackle hard problems in understanding and predicting consumer behavior to offer items to customers which are most relevant to them.   You will work with engineers, product managers and designers to develop innovative new technologies and data driven features and products. You will also work closely with other Data Scientists to collaborate on projects and share techniques and learnings. If you enjoy working with data to build products and solve hard problems in surprisingly creative ways, this is the role for you.    ","RequirementsQualifications:  Deep expertise in search, preferably in e-commerce. Excellent knowledge on improving search incrementally as well as making step-changes such as applying NLP, text mining, etc. Proven track record building robust search systems and achieving strong results Expertise in personalization and recommender systems Able to guide a team of engineers to identify and break down necessary architecture and services to support search and personalization services Able to guide and work well with a team of engineers to implement Machine Learning algorithms and models, as well as implementing necessary software Solid understanding of search metrics and implementing tracking to measure performance Solid understanding of search engines and utilizing features effectively. Familiarity with ElasticSearch is a plus Hands-on experience developing and implementing Machine Learning algorithms and models. Background in Machine Learning,Statistics & Information Retrieval Design, implement, test robust technical solutions that our high traffic site/apps can rely on Write clean code that’s testable, maintainable, solves the right problem and does it well. Code you can be proud of. Phd, Masters, or equivalent experience in a quantitative field (computer science, physics, mathematics, bioinformatics, etc.) a plus, but by no means a must Experience programming in functional languages (Scala,Golang,Haskell, Clojure etc.) a plus but not a must Knowledge of scripting languages like  Python/R, familiarity with web frameworks a plus Experience with Java and/or Scala and microservices is a plus Understanding of A/B testing      Desired Skills:  Able to be a key influencer in the team’s strategy and contribute significantly to team planning, showing good judgement making technical trade-offs between the team’s short term and long term business needs, and the needs of the company as a whole Strong team player: Superb communication skills, thrives in a collaborative environment and be committed to the success of the team as a whole. Critical thinking: ability to track down complex data and engineering issues, evaluate different algorithmic approaches, and analyze data to solve problems Creativity: you can conceive of new data driven products, features, and technologies Results: you prioritize, focusing on ideas and features that will have significant, measurable impact Planning & estimation: ability to set and meet your own project objectives & milestones Communicate results and progress internally and externally in meetings, presentations, and tech talks Passion for technology. Our developers are always evaluating new tools and technologies that can make us better. What has attracted your interest lately? "
/job/junior-data-scientist-fixed-mobile-5388df9ff18bdbfcd7f9197f4ba65411,"The Data Science & Data Engineering department focuses on the creation of new data science capabilities for the business. It envisions and executes strategies to improve performance by facilitating informed decision making. We are looking for a highly driven and self-motivated individual who is truly excited about creating meaningful impact from data. In this role you will combine a startup mindset with the scale of an industry leader, providing you with hands-on exposure to how data could be used for making key organization decisions. The role is based in the business headquarters in Singapore but is a global role with stakeholders based in 5 continents. Roles and Responsibilities  Drive data-based decision making through the creation of dashboards conveying insight Tailor advanced analytical solutions to complex business problems Support all department heads with their analytical needs, to help the business make data driven decisions by extracting, preparing, analyzing and preparing presentations Work across diverse departments – Sales, Technology, Finance, Marketing etc.  About Us TransferTo operates a leading global digital value services network offering safe, reliable and more accessible mobile value services for emerging markets. Our B2B cross-border network interconnects and provides mobile operators, money transfer operators, retailers, distributors, NGOs and corporates with unparalleled infrastructure and reach to offer solutions that better connect loved ones across borders. For more information, visitwww.transfer-to.com/digitalvalue","RequirementsDesired Skills  Outstanding degree in engineering, information systems, economics or a quantitative field Naturally curious, solution oriented and thrives on quantitative analysis Hands-on technical expertise & a broad business-oriented understanding 1-2 years of experience in data mining Strong grasp of statistics and aptitude for number crunching and data modeling The ability to apply machine learning techniques in a business context An understanding of experimental designs, A/B testing and result interpretation Good SQL knowledge and fluency in R or Python are necessary Excellent data visualization skills Experience with Tableau or other BI platforms is a plus Willingness to continuously learn new tools, models and techniques "
/job/data-scientist-signal-processing-biofourmis-singapore-4f590c6141213789adafc432b1ce1a37,"The candidate uses strong coding skills to help in the development of signal processing and machine learning algorithms to analyze the physiological/biomedical data and derived with meaningful insights, mine existing biomedical signal and healthcare datasets to guide algorithm design and optimization. ","RequirementsMaster Degree in Computer Science, Electrical Engineering, Biomedical Engineering or related program Minimum 1 to 3 years' experience in Python either in work or school projects Proven working experience in writing high-performance Phython code especiallly on machine learning projects. Familiar with bio-signals (ECG, PPG, and other types of biomedical/healthcare data) and experience in data analysis using Matlab is a plus but not necessary"
/job/data-science-consultant-backoffice-associates-asia-863283daf30fe9edb3d9c6959f2299f2,"Primary Responsibilities:  Understand large data sets, build data models to address business problems Undertake data collection, pre-processing and analysis Build predictive models and machine learning algorithms  The role will involve analysis and extensive data crunching with good amount of hands on programming skills. This role requires following skills and experience:  Proven experience (5+Years) as a Data Scientist or Data Analyst Experience in data mining Understanding of machine-learning and operations research Knowledge of R, SQL and Python; familiarity with Scala, Java or C++ is an asset Experience using business intelligence tools (e.g. Tableau) and data frameworks (e.g. Hadoop) Analytical mind and business acumen Strong math skills (e.g. statistics, algebra) Problem-solving aptitude Excellent communication and presentation skills  ","RequirementsCandidate should possess good soft skills as mentioned below:  Should possess excellent problem solving and is able to work effectively in a less structured environment and manage time. Excellent verbal and written communication skills Work closely with onsite and offshore team members Willing to travel to the customers locations on need basis outside of Singapore  Qualification:  Computer Science, Engineering or relevant field; graduate degree in Data Science or another quantitative field is preferred "
/job/data-science-consultant-backoffice-associates-asia-32de68c45c9756377411d997a31402c9,"Primary Responsibilities:  Understand large data sets, build data models to address business problems Undertake data collection, pre-processing and analysis Build predictive models and machine learning algorithms  The role will involve analysis and extensive data crunching with good amount of hands on programming skills. This role requires following skills and experience:  Proven experience (5+Years) as a Data Scientist or Data Analyst Experience in data mining Understanding of machine-learning and operations research Knowledge of R, SQL and Python; familiarity with Scala, Java or C++ is an asset Experience using business intelligence tools (e.g. Tableau) and data frameworks (e.g. Hadoop) Analytical mind and business acumen Strong math skills (e.g. statistics, algebra) Problem-solving aptitude Excellent communication and presentation skills  ","RequirementsCandidate should possess good soft skills as mentioned below:  Should possess excellent problem solving and is able to work effectively in a less structured environment and manage time. Excellent verbal and written communication skills Work closely with onsite and offshore team members Willing to travel to the customers locations on need basis outside of Singapore  Qualification:  Computer Science, Engineering or relevant field; graduate degree in Data Science or another quantitative field is preferred "
/job/assistant-manager-geoanalytics-singapore-land-authority-c6b86014497574442a0ee9efd61c227c,"Assistant Manager, GeoAnalytics
Job Scope:

Proliferate the use of GIS and data within whole of Government.
Provide consultative support to stakeholders to make sense of data.
Work with developers, contractors and vendors to collaborate on the application exploration and development so as to achieve the department’s work objectives.
Review Big Data, Machine Learning frameworks.

 
Requirements:

Degree, preferably in the areas of Geospatial/Computer Science/Engineering or similar area of study.
At least 3 - 5 years of working experience in geospatial information science, analytics platforms, system analysis and design.
Excellent communication and presentation skills. Able to relate technical information to all levels of the organisation.
Experience with GIS and Business Intelligence software (e.g. Qlikview, Tableau).
Good knowledge of Hadoop (Cloudera/Hortonworks) Infrastructure, R, Python and ability to code (python functional programming, java).

 ",Not Available
/job/senior-data-scientist-resmed-asia-a8366ea0122ebe5fc1fde22d0ae6703b,"Senior Data Scientist The Senior Data Scientist will undertake applied research and development in the areas of data science and biomedical informatics, using the latest technologies in machine learning and distributed computing. The platform and algorithms developed may be used in a range of diagnostic and therapeutic applications, such as sleep disorder breathing, chronic obstructive pulmonary disorder, and other respiratory disorders, as well as co-morbidities such as congestive heart failure and diabetes and chronic disease management Let’s talk about this position: The Advanced Analytics team is headquartered in the United States and is focused on developing analytics solutions that will enable a data-driven approach to addressing business questions. This role will be a part of the Advanced Analytics team in Singapore, and collaborate with the global Advanced Analytics team in support of achieving global and regional business goals. Responsibilities and Accountabilities:  Research, customization, and development of statistical and machine learning algorithms to meet complex project requirements; tasks include defining hypotheses, executing necessary tests and experiments, evaluating, tuning and optimizing algorithms and methods to specific situations. Analysis of big data for data-driven solution validation, evaluation and technology innovation.  Optimize data analysis processes and systems for better efficiency and maintainability. Leading sub-functional and small project teams. Mentoring and training more junior team members and serving as a best-practice resource for statistics and machine learning. Writing of documents that clearly explain how algorithms should be implemented, verified and validated. Writing documents for use in the preparation of intellectual property and technical publications. Monitoring the literature of interest and industrial development trends, broadly in the areas of data analysis and machine learning. Understanding regulatory requirements, such as those mandated by the FDA. Working within the ResMed Quality system, standards and maintaining training requirements. Being ever mindful of the requirements of the wider market and ResMed stakeholders. Promoting safe working environment within OH&S guidelines ","RequirementsLet’s talk about you: To really get us excited, you will have a degree in Computer Science, Engineering, Statistics, Applied Mathmatics, or related fields with minimal 6 years’ industry or academic experience in data science. Post-graduaded research experience (Masters or PhD) in a field encompassing Data Science, Applied Statistics, or Biomedical Informatics and relevant industry experience would be favourably considered. For this role, you should have skills and knowledge such as:  Expert in statistical analysis methods, including analysis of variance, regression, time series analysis, survival analysis, etc. Extensive knowledge in machine learning fundamental theories and data mining technologies. Leadership and hands on experience with development of data analytics systems, including data exploration/crawling, feature engineering, model building, performance evaluation, and online deployment of models. Proficient with server side programming in Python/Java. Hands on experience in handling large and distributed datasets on Hadoop, Spark, Hive, Pig or Storm, etc. Strong database skills and experience, including experience with SQL programming. Knowledge in big data technologies including cloud computing/distributed computing, data fusion, and data visualization. Experience in R programming. A background in or exposure to biomedical engineering, medical science or physiology. Good technical writing and presentation skills. Optimisation of algorithm complexity vs. accuracy vs. implementation cost. Implementing robust software for use in research programs with a minimum of review and other formal process  OK, so what next?  At ResMed, we believe in supporting, inspiring and developing our people. So we recruit the best and then give them the tools to make a real difference in the lives of our patients. We believe that fresh thinking inspires innovation – and our shared success. If this sounds like a place you would like to work and you have the drive to transform and enhance the lives of millions of patients through your contribution at work, then today is your day! Apply now!"
/job/data-scientist-resmed-asia-2f0c26cd85b0964482421f8d9f7ec3bd,"Data Scientist We are currently seeking applications from an experienced Data Scientist to join our Healthcare Informatics (HI) team based in our Connexis office Singapore.  At ResMed we focus on capability and passion. With your in-depth knowledge and understanding in applied research and development in the areas of data science biomedical informatics, you will use the latest technologies in machine learning and distributed computing. The platform and algorithms developed may be used in a range of diagnostic and therapeutic applications, such as sleep disorder breathing, chronic obstructive pulmonary disorder, and other respiratory disorders, as well as co-morbidities such as congestive heart failure and diabetes and chronic disease management. The candidate we are seeking will specialise in the following areas and be capable of the following responsibilities: • Research, customization, and development of statistical and machine learning algorithms to meet project requirements; tasks include defining hypotheses, executing necessary tests and experiments, evaluating, tuning and optimizing algorithms and methods to specific situations. • Analysis of big data for data-driven solution validation, evaluation and technology innovation.   • Optimize data analysis processes and systems for better efficiency and maintainability.   • Writing of documents that clearly explain how algorithms should be implemented, verified and validated. • Writing documents for use in the preparation of intellectual property and technical publications. • Monitoring the literature of interest and industrial development trends, broadly in the areas of data analysis and machine learning. • Understanding regulatory requirements, such as those mandated by the FDA. • Working within the ResMed Quality system, standards and maintaining training requirements.","RequirementsLet’s talk about you: To really get us excited, you will have extensive working knowledge of machine learning fundamental theories and data mining technologies with proficiency in statistical analysis methods, including analysis of variance, regression, time series analysis, survival analysis, etc. In addition, you will have strong database skills and experience, including experience with SQL programming. You will also have a Post-graduate research experience (Masters or PhD) Degree in a field encompassing Data Science, Applied Statistics, or Biomedical Informatics or related discipline with experience in relevant data science industry. Experience in a medical device company would also be advantageous. Let’s talk about the team: Big ideas and big goals reign at ResMed Singapore. Within this growing HI team, you’ll thrive in an environment filled with self-starters who possess the drive to make a difference. You’ll be encouraged within a people-focused culture that motivates and recognises talent, so that together, we can produce the best products and results. OK, so what next? At ResMed, we believe in supporting, inspiring and developing our people. So we recruit the best and then give them the tools to make a real difference in the lives of our patients. We believe that fresh thinking inspires innovation – and our shared success. If this sounds like a place you would like to work and you have the drive to transform and enhance the lives of millions of patients through your contribution at work, then today is your day! Apply now!"
/job/data-scientist-dentsu-aegis-network-hub2050-558ef521adf106695584d1c1592cdeff,"This is an exciting time to join Dentsu Aegis Network (DAN) as we focus on becoming a 100% digital economy business by 2020 through content, media and commerce. We are well placed to build capability, scale and sustainable growth as a high performance business. Our strategy is driven by our unique culture with one vision (to innovate the way brands are built), one set of values and a unique operating model which drives collaboration, client focus and attention.  Dentsu Aegis Network believes that everybody should be treated equitably. We are committed to creating an inclusive, diverse and collaborative environment that enables our people to do what they do best – innovating the way brands are built. This is regardless of age, race, disability, sexual orientation, gender, marital, civil partnership or parental status, religion or belief. As a global organisation, we offer fair employment and advancement opportunities for our employees to succeed and advance within their profession, both in Singapore and around the world.   BACKGROUND: About Dentsu Aegis Network Dentsu Aegis Network helps clients build consumer relationships by communicating their products and brands effectively. Our distinctive and innovative range of products and services include marketing and communications strategies through digital marketing and creative execution, media planning and buying, creative services, technology applications, SEO, content creation, brand tracking and marketing analytics. Find out more about us at https://www.dentsuaegisnetwork.com/   About Dentsu Aegis Network’s Global Data Innovation Centre As the world of data continues to grow exponentially in the advent of connected devices, IoT, industrialised digitization of the economy and the way people move through digitized networks, Dentsu Aegis seeks to harness the power of data and transform this into intelligent applications, products and platforms. The Dentsu Aegis Network Global Data Innovation Centre, hubbed in Singapore, is a strategic initiative to ensure that the Group harnesses this power effectively and at scale. This set up builds from the data innovation practice that was launched in 2012 and is now designed to deliver on global initiatives from Singapore.   KEY ACCOUNTABILITIES: As a Data Scientist, you will be a key member of the Centre. You will play a leading role in developing analytics solutions and data capabilities that will enable us to be thought leaders in the practice of data and analytics. You will work in a team of 4 – 5 talented Data Scientists and behavioural analysts. On a day-to-day basis, your responsibilities can comprise of:  Being an effective bridge between the Centre, IT and our Global Big Data Infrastructure platform to ensure that the data work streams are effectively collected, organized and processed Make data actionable by designing and building effective application programming interfaces -- APIs -- and services that allow the data to flow into any system that can make use of the information in real-time. Technical expertise for design, development, implementation of information storage and retrieval, data flow and analysis and provide effective recommendations based on trades among data volumes, number of users, logical and physical distribution, response times, retention rules, security and domain controls. Develops relational and/or Object-Oriented databases, database parser software and database leading software.   Maintains and updates for new development a set of records for, but not limited to, creating or recreating ad hoc queries, scripts, codes, and macros.   ","RequirementsPERSON SPECIFICATION: We invite people passionate about data, intelligence and application of same in the market place to join a growing team. You have to be a self-starter, motivated and yet collaborative. You can think on your feet, connect disparate dots, imagine connections and importantly, craft approaches to turn ideas and imagination into real capabilities, inspired by data. You are excited by your work going live in the market with clients and teams around the world.  PhD/Masters in Computer Science or Computer Engineering, with specialisation in deep learning or similar Proven working experience in machine and deep learning projects, especially in using deep learning ​Experience handling imbalanced data classes Able to generate relevant outputs that are not always seen in training data ​ Embedded knowledge  Experience handling large search spaces effectively and efficiently  Familiar with Python, Tensorflow, Keras Experience in dealing with large unstructured data sets Good understanding of big data architectures and solutions Good leadership skills Capable in leading a young team of data science analysts Proactive, customer-oriented and results-oriented Excellent track record in being part of a team that has deployed industrial-scaled, cutting-edge and commercial initiatives "
/job/data-scientist-ee6d544e704fdda821970b416b5eda87,"The Data Scientist should have a graduate degree in Computer Science, Statistics, Deep Learning or Machine Learning and a strong background in statistical methods such as Bayesian statistics, time series forecasting, and feature engineering. Candidates with an undergraduate degree and a demonstrable track record in these domains are encouraged to apply.   Responsibilities  Implement state-of-the-art deep learning and machine learning models  Conduct original research on our large repository of data, both proprietary and open-source Write production-level code linking new and existing data pipelines with scripts for feature engineering, machine learning predictive models and visualization Write tests to check for integrity of our data, models and predictions ","Requirements Comfortable with core machine learning algorithms implementation and theory Advanced in scripting languages (Python, R and UNIX Shell), Git project management, deep learning frameworks (PyTorch /Keras / TensorFlow..), and programming skills (Java or C++) Can communicate clearly and cogently on concepts, processes and algorithms used Ability to work in time-sensitive environments and to approach problems from different angles Deep learning experience "
/job/data-scientist-hilti-asia-pacific-3663eea2ba100b73f57cea1dd23f865f,"In this role you design experiments, test hypotheses, develop and program models. You are coding in R or Python and you are using SQL to manipulate data. We work in agile, iterative processes. You lead discovery processes to identify the right business questions and develop business scenarios which affect critical decisions and business processes. You identify what relevant data is available, using internal and external data sources, structured and unstructured data, leveraging new data collection processes such as connected tool information. You collaborate with global subject matter experts to select the relevant sources of information. You make strategic recommendations on data collection, integration and retention requirements incorporating business requirements and knowledge of best practices. ","Requirements PhD in physics, statistics, computer science or related field. Deep knowledge of statistical techniques and experience using machine learning algorithms. Experience using Big Data frameworks such as Hadoop, MapReduce and others. Strong programming skills in R, Python and Java. "
/job/data-scientist-analytics-worldwide-sales-airbnb-singapore-751beb3c340b577339b4374994b816de,"Airbnb is a global platform that connects travelers and hosts from over 81,000 cities. Our mission is to enable a world where anyone can belong anywhere. Using data to help ensure a world class experience for our users is critical to our mission. The Sales Data Science team empowers our global sales teams by delivering high-quality data, analytics tools, and insights to drive strategy and decision-making for sales and B2B marketing at Airbnb. You will lead the development of analytical models, reporting, and insights to amplify the performance of our Sales and B2B marketing organization. Projects you own may relate to lead prioritization, sales cycle optimization, sales experimentation, forecasting, or a variety of other domains supporting sales teams across multiple business segments. Responsibilities:  Define key sales performance metrics and build ROI models Develop sales experimentation and attribution frameworks Surface insights on the sales conversion pipeline, customer segmentation, and customer success Collaborate with engineering to establish data pipelines and data hygiene Create dashboards and reports that provide ongoing insight to business stakeholders Develop advanced and predictive models such as lead prioritization, churn prediction and assist sales ops teams in using these models Partner with sales ops and regional directors to develop regional supply acquisition strategy Design and implement data-driven systems that increase sales agent success   ","RequirementsQualities:  6+ years analytics experience required; Master/PhD degree in a quantitative field is a plus 3+ years experience in Sales analytics: experience using data and reporting capabilities of Marketo, Salesforce.com and Google Analytics preferred Extensive project management experience, with proven ability to succeed in both collaborative and independent work environments Experience with statistical analysis and modeling Ability to translate quantitative data into actionable recommendations and communicate to sales and marketing partners Strong written and verbal communication Fluency in the core toolkit of Data Science:     Advanced SQL/Hive R/Python Manipulating large-scale data sets Descriptive and predictive modeling Implementing visualizations, dashboards, and reports     "
/job/senior-ai-data-scientist-unscrambl-singapore-56b499a2c7687564cefe00167a410c3d,"You will be working with our product development team to incorporate new statistical, machine learning and other analytic models in our platform. Examples of models are customer segmentation models, purchase propensity models, recommendation models, churn models, anomaly detection models, time-series prediction models, natural language processing, etc.  These would be used for purposes like marketing, customer care, patient prognosis, predictive maintenance, etc. across various industries like telecommunications, banking, healthcare, retail, etc. You’ll also work with our sales and delivery teams to develop and tune models for certain customers, and to help operationalize the models in production settings. Finally, we are looking for creative thinkers to help us innovate as we design and implement new and relevant features in our product.","Requirements  Hands on experience developing Python (primarily version 2.7) applications on Linux   Knowledge of statistical and machine learning packages, especially in Python, and experience using notebooks   Understanding of basic software engineering design and development principles   Good presentation and communication skills, and ability to interact with customers   Deep knowledge of Natural Language Processing techniques and tools     Experience with SQL and NoSQL databases   Experience in working with Big Data and Stream Processing systems (such as Hadoop, Spark, Storm, etc.).   Experience in telecommunications, banking, healthcare or retail domains   Experience in time series analytics   Knowledge of data visualization packages, in Python and outside  "
/job/office-planning-manager-republic-polytechnic-ba6127e745a10ce5155e458624a308bb,Not Available,Not Available
/job/research-scientist-agoda-company-f00237c5878e10b81927de26eaab04fa,"We’re Hiring Senior Data Scientist / Machine Learning Expert! Agoda is a Booking Holdings (BKNG) company, the world’s leading provider of brands that help people book great experiences through technology. We have the dynamism and short chain of command of a startup and the capital to make things happen. What’s stopping you from getting in touch? We move fast – why wait ages to see your ideas go live?  Work on tough challenges, safe in the knowledge that you are surrounded by people as smart as you are (if not smarter!) to help solve them.  And while we’re on the subject, Agoda people come from over 65 countries:  It’s an incredible technical creative melting pot.  Technology is not just what we do – it’s at the heart of who we are.  We put cutting-edge technology in your hands so you can help us change the way people run their lives. We want you to come here so they can get there – and get your career going places, too. Maintaining this growth requires an incredible amount of data, a superior IT infrastructure, and world class talent to bring it all together. Your role is to:  Crack our business problems and come up with deployable machine learning models Interface with business to make sure they are asking the right questions Sift through our data and find us some gems  Be a world-class hands-on deploy master ","RequirementsCharm us with:  An earned stripes in coding, in data handling, in statistics and in machine learning (5 years of experience is a must) A good balance between theory and practice and a strong desire to learn and keep up with the latest technologies (an academic quantitative degree, preferably a PhD, earns more points) A good knowledge of what’s “Under the hood” of statistical methods Coding, coding, coding (R, Python, C#, Java, C++, Scala, …) Some extra points on: SQL, NLP, business acumen, blog writing, good sense of humor "
/job/ai-data-scientist-amarisai-5fcad1410f32a0b2fb8c85c80e258ff2,"We are looking for exceptional Machine Comprehension Data Scientists to embark on our journey to deploy world class deep learning and machine learning algorithms in the investment and portfolio management space ​ The Data Scientist (Machine Comprehension) should have a PhD or Masters in Computer Science, Statistics, Deep Learning or Machine Learning and a strong background in statistical methods such as Bayesian statistics, time series, and feature engineering. ​ If you have a passion for building state-of-the-art deep learning and machine learning models and have an keen interest in Natural Language Processing and semantic AI, this is your opportunity.","Requirements  Implement state-of-the-art deep learning and machine learning models for feature engineering and question/answer/prediction in investment platform   Conduct original research on our large repository of data, both proprietary and open-source   Write production-level code linking new and existing data pipelines with scripts for feature engineering, machine learning predictive models and visualization   Write tests to check for integrity of our data, models and predictions  "
/job/senior-manager-data-engineer-lazada-south-east-asia-45d7ce3b60661f1ec166b06dd04606cc,"Team Introduction Lazada is the number one online shopping & selling destination in Southeast Asia – present in Indonesia, Malaysia, the Philippines, Singapore, Thailand and Vietnam. Lazada helps more than 80,000 local and international sellers as well as 2,500 brands serve the 560 million consumers in the region through its marketplace platform, supported by a wide range of tailored marketing, data, and service solutions. Lazada offers an excellent customer experience through a wide network of logistics partners and its own first- and last-mile delivery arm. Roles & Responsibilities  Implementing working data projects based on given technical specifications Develop real-time and batch data ingesting and processing pipelines to be used for analysis, machine learning, dashboards, alerts and visualizations. Work closely with partner teams to establish the optimal technical solution to business problems Monitor & manage data pipelines, ensuring accuracy and stability ",Requirements Educational background in Computer Science / Electrical Engineering or similar Understanding of database concepts and distributed processing systems Experience with programming and understanding of basic algorithms Strong command of SQL and database concepts Preferred previous knowledge of Hadoop or NOSQL databases Excellent communication & problem solving skills  
/job/data-analyst-ent-vision-5db592052a62b3a5abb4aa282c8b8d14,• Inspect and deep dive into data captured in enterprise systems and IOT devices • Build Machine Learning models and Heuristic algorithms for prescriptive analytics • Integrate Machine Learning models and Heuristic algorithms into backend application • Translate business requirements and raw data into effective visualisation and dashboards,"Requirements• Degree in Mathematics, Computer Science or a related discipline • 2 year statistical modelling, data analysis and machine learning in software environment • Strong skills in R, Python, Scikit and Microsoft SQL • Experience in Microsoft .Net development and visualisation tools • Highly proficient in statistical modelling and good analytical skills • Good communications skills, project planning and time management are pre-requisites • Singaporeans only"
/job/data-scientist-reebonz-8223513a45d754551eb4676165ec2c07,"Reebonz is looking for Data Scientist to join the Product team. The role for a Data Scientist is to build and implement machine learning models to make timely decisions in various departments and work with large amounts of structured and unstructured data to understand how our users are interacting with our brand, and communicate these insights with stakeholders. This is a NEWLY CREATED POSITION. Major roles and responsibilities:  To identify opportunities for leveraging company data to drive business solutions Develop processes and tools to monitor and analyze model performance and data accuracy Measure the effectiveness and accuracy of new data sources and data gathering techniques Mine and analyze data from company database to drive optimization and improvement of product development, marketing techniques and business strategies Use predictive modeling to increase and optimize customer experiences, ad targeting, revenue generation and other business outcomes Develop custom data models and algorithms to apply to data sets Develop company A/B testing framework and test model quality Coordinate with different functional teams to implement models and monitor outcomes ","RequirementsJob Requirements:  Degree in Business, Marketing, Business Analytics, Marketing Analytics or Statistics Familiar using statistical computer languages (R, Python, SLQ) to manipulate data and draw insights from large data sets Strong problem solving skills on product development Familiar working with and creating data architectures Experience in machine learning techniques, advanced statistical techniques and concepts and experience with applications Excellent in verbal and written communication  Interested candidates are welcome to apply with an updated copy of their resume accompanied with their last drawn salary and earliest availability. We regret to inform that only shortlisted candidate will be contacted. "
/job/data-scientist-global-premium-services-google-technical-services-professional-services-singapore-google-asia-pacific-b5abca92461a7ab2ccb873c0f4bb7294,"Company overview: Google is not a conventional company, and we don’t intend to become one. True, we share attributes with the world’s most successful organizations – a focus on innovation and smart business practices comes to mind – but even as we continue to grow, we’re committed to retaining a small-company feel. At Google, we know that every employee has something important to say, and that every employee is integral to our success. We provide individually-tailored compensation packages that can be comprised of competitive salary, bonus, and equity components, along with the opportunity to earn further financial bonuses and rewards. Googlers thrive in small, focused teams and high-energy environments, believe in the ability of technology to change the world, and are as passionate about their lives as they are about their work. For more information, visit www.google.com/careers. The area: gTech (general) Google creates products and services that make the world a better place, and gTech’s role is to help bring them to life. Our teams of solution-oriented trusted advisors support millions of customers globally. Our solutions are rooted in our technical skill, product expertise, and a thorough understanding of our customers’ complex needs. Whether the answer is a bespoke solution to solve a unique problem, or a new tool that can scale across Google, everything we do aims to ensure our customers benefit from the full potential of Google products. To learn more about gTech, check out our video. The role: Data Scientist, Global Premium Services, Google Technical Services Professional Services - Singapore Google Technical Services: Professional Services (gPS) is a team of solution-oriented trusted advisors supporting millions of users worldwide. Our consultative services take our deep technical and product expertise and combine it with our powerful understanding of our customer’s needs and goals to solve their biggest business challenges allowing them to grow and get the most out of Google solutions. Additional Role Description: As a Data Scientist you'll work closely with our clients and produce innovative and actionable quantitative models and analyses to address the challenges of marketing effectiveness, return on investment, and prediction. The Global Premium Services team is a solution-generating force that helps our Sales teams and advertisers. These solutions need to be scalable to support millions of customers worldwide. In addition to troubleshooting on the customer side, we work with Sales, Product and Engineering teams within Google to develop better tools and services to improve our products based on the evolving needs of our users. As a cross-functional and global team, it's our job to help keep the lights on and the ads relevant. Responsibilities: - Lead analytics aspects of client engagements in the area of marketing effectiveness and marketing portfolio management (with deep knowledge of modeling). - Effectively work with clients to align Google Analytics 360 suite attribution and analytic solutions with key organizational challenges and develop value-based roadmaps to solve client business challenges on a continuous and repeatable basis. - Collaborate with clients to build an end-to-end Machine Learning framework. Engage various stakeholders, assess data readiness. Be able to scale a proof of concept to a larger solution. - Work with client and internal teams to translate data and model results into tactical and strategic insights that are clear, complete, accurate, relevant, understandable and applicable to decision making and needs for varying client audiences. Co-present to and work with clients to integrate recommendations into business processes. - Collaborate with Product/Engineering teams to increase and optimize capabilities, employing methods which create opportunities for scale, proactively helping to drive innovation.","RequirementsMinimum qualifications: - Master's degree in Statistics, Mathematics, Economics, Engineering or an Applied Science, or equivalent practical experience. - 5 years of quantitative analytics experience with a focus on marketing analytics, statistical modeling, Machine Learning, digital attribution, forecasting, optimization and/or predictive analytics. - Knowledge of media (e.g. paid, owned and earned). - Programming experience in Python and/or R. Preferred qualifications: - SQL and big data experience. - Experience in delivering bespoke analytics to stakeholders (e.g. problem scoping/definition, modeling, interpretation, presentation). - Experience in using and/or deploying digital analytics and measurement solutions. - Knowledge of statistical programming languages (R/Python/Tensorflow). - Ability to visualize models and results. Ability to debug and troubleshoot code and models."
/job/tech-lead-equatorial-marine-fuel-management-services-5ebbbf87e838b59a128a0756a62b105d,"The technology lead is responsible for the overall planning, organizing, leading and executing all tech initiatives with the team. This includes directing all tech related operations to meet business and customer requirements as well as the support and maintain existing applications and develop new solutions. You will work closely with our product team to understand business and customer requirements to design, create and improve system, data architecture, application, network and security architectures. Responsibilities:  The technical problem solver. Serve as the primary subject matter advisor on tech related matters and provide guidance to developers. To work closely with Design, Product, Business Managers, Data Scientist to define the scope of product requirements. Establish and implement key best practices in coding, application development, tech architecture design and technical documentation. Ensure documentation for development codes, application design, user testing scenarios, tech architecture and system deployment guide is carried out. Review and improve technical processes to enhance work productivity. Custodian for system architecture, codes and test plans. Participates on all hardware and software evaluations. Lead the developers together with the Product Manager in AGILE methodology. Hands on coding is required. ","RequirementsJob Requirements:   Bachelor’s degree in computer science or related field. Minimum of five (5) years of experience within relevant management, development and planning areas of tech development. Full stack developer with working experience in web and mobile application development. Experience in developing and working with REST API. Experience in network & system design, application design, data architecture design. Core language competencies are Python, Django, Node.js, React, GraphQL and PostgresQL. Bonus language competencies are R, Spark, Scalar, ReactNative and MySQL. Knowledge in setting up cloud infrastructure. Knowledge in setting up data architecture. Knowledge in setting up and/or working with analytics architecture.    Please include your portfolios of work, last drawn pay and reason(s) for leaving your last employment in your CV. Please send your resume to hr@emf.com.sg"
/job/business-data-analyst-varian-medical-systems-pacific-bfbda766a0a4f2c9ae036074a1e0c730,Not Available,Not Available
/job/data-analyst-trakomatic-2e2330b3dc2fd781c8b31fefcf12cb3a,"The Retail Data Analyst will lead and perform complex analysis in an evolving data environment. In addition to very strong technical skills, this position requires superb business process analysis and interpersonal skills. The ability to extract and analyze shopper behaviour related data (footfall, demographic, crowd density, shelves engagement and sales transaction data), patterns, and related trends is needed, with the subsequent ability to synthesize the data into information consumable by different department from marketing, senior business decision-makers, operation team and leasing department.  Retail business analyst job entails conducting quantitative and qualitative analyses including customer behaviour, retail trends, etc. The role involves presenting the shopper Analytics insights and educating the usage of the data to clients.    Responsibilities:     Complete projects that require data mining, analysis, and presentation.   Focus on solutions, dive into projects, quickly identify drivers in the data.   Identify relevant trends, do follow-up analysis, prepare visualizations.   Develop dashboards to track remediation of issues.    While the focus of this role is the extraction and interpretation of data, it also requires the capacity to identify, explore, interpret and present key trends, ideas and concepts   Analysis: Data analysts work with large amounts of data: facts, figures, and number crunching. You will need to see through the data and analyse it to find conclusions.   Communication: Data analysts are often called to present their findings or translate the data into an understandable document. You will need to write and speak clearly, easily communicating complex ideas.   Critical Thinking: Data analysts must look at the numbers, trends, and data and come to new conclusions based on the findings.   Attention to Detail: Data is precise. Data analysts have to make sure they are vigilant in their analysis to come to correct conclusions.    ","RequirementsRequirements:     A bachelor’s degree in math, computer science, business, analytics, or a related field is required. Strong math and analysis skills are needed.   Effective communication, computer, analytical, customer service, and project management skills are also important.   The ideal candidates should have experience working in a business/data analysis role in the retail business processes and retail systems experience.   Math Skills: Data analysts need math skills to estimate numerical data.   Working familiarity with tools like Power BI, Qlikview, Tableau, Hadoop, Excel.   Self-starter – must be productive with minimal direction.   Ability to work in a fast-paced, technical, cross-functional environment.   Excellent visual design sense regarding clear and accurate presentation of data.   Basic SQL skills desirable.  "
/job/data-analyst-gumi-asia-c773036141babed8aecb5c926c1b2837," Perform evaluations and problem investigation for Marketing Data Work within the Business Innovations department to identify data related problems and provide solutions Conduct research and collect data which will help in continual product development that meet department requirements Ensure high quality data are collected and integrity of the data Process data to develop reports specifically required by the department Analyse information using various statistical methods, trying to see patterns in data Create reports and presentations ","Requirements Minimum Diploma/ Degree in Statistics/Computer Science Minimum 2 year's experience in Data Management, Consolidation and Analysis Preferred High proficiency in Microsoft Excel is required Previous experiences with R and MySQL will be highly valued. Possess excellent problem solving, presentation, organizational and project management Good communication skill and interpersonal skill "
/job/business-data-analyst-rgf-talent-solutions-singapore-e227798c1e276d3890ba130217f4e94a," Support the global marketing team Work with large sets of data, perform detail analyses and turn them into actionable insights Present the findings to senior stakeholders and provide recommendations ","Requirements  Degree holder, with at least 4 - 5 years of professional experience in data analytics  Strong in SQL, Basic R/Python and Excel  Understanding of causal inference methods  Basic experience in econometrics or statistics is an added advantage  Strong project management & stakeholder management "
/job/business-data-analyst-rubicor-group-215ead5ce0ae6665513f458dca7de5ff,"Xpand is looking to hire a Business Data Analyst who will be working on one of our technology client's projects. In this role, you will work closely with the Global Marketing Analytics team and key stakeholders on data analytics that inform campaign success and provide thought leadership and learnings to refine operations using data insights. This is a 6 months contract based in Singapore. What you will do: The ideal candidate has strong experience working with all different stages of data analysis: data querying, building reporting pipelines, running statistical analysis, building dashboards, and presenting insights. You should be a self-starter that can ""crunch the numbers"", identify trends that connect to the big picture, partner with senior stakeholders, and communicate effectively with senior executives to drive significant strategic initiatives.  ","RequirementsWhat you will need:  BA/BS degree in Business/Data Analytics, related field or equivalent practical experience with 4 years work experience In-depth experience analyzing data and creating reports with strong spreadsheet, database query experience (e.g. SQL), statistical, quantitative modeling and forecasting skills. Previous experience in the tech industry Ability to understand the implications of data analysis and build a strategic story from this data Strong communication and presentation skills to deliver findings of analysis. Demonstrable organizational and project management skills, with the ability to manage multiple projects with competing priorities.  Interested candidates can send their CVs to Koeschnake Maceda at koesch@xpand.sg. CEI No: R1548053 | Licence No: 07C3147"
/job/executive-sky-premium-international-cc0d50d8a4b022d32d053bc37e929e20,"Sky Premium International is looking for IT Executives to be part of an dynamic team to plan, develope, execute and deliver compelling and innovative data-driven solutions and reports to imporve our business operations and facilitate decision-making. Responsibilites :  - To mine, analyse and report data from the company-owned systems and databases, to support and drive decision making in terms of product development and product marketing. - To design, develop, build, execute, train, test, validate and implement data and machine learning models, for production, testing, proof-of-concepts (POCs) as well as demonstration purposes. - To design, develop, test, validate and implement static reports as well as dynamic dashboards, for production and testing. - To collect, consolidate, clean-up, structure and/or process data from various disparate structured, unstructured and/or incomplete data sets and data sources. - To write complex queries and/or scripts to perform data aggregation, extraction, transformation and load (ETL). - To verify deliverables against the agreed qualities and standards as per the approved specifications. - To arrange, coordinate and conduct user acceptance testing (UATs) and user training sessions, with involved stakeholders and end-users, and follow-up on reported data models, dashboards and/or reports related issues closely. - To create, update and maintain proper specifications, such as functional, technical, report and/or database specifications.","RequirementsRequirements & Pre-Requisite : - Minimum a Degree in IT or Computer Science, or equivalent. - At least 3-5 years of experience working with MS Excel, SQL Server, MYSQL and/or NOSQL databases and database visualization tools (e.g. Tableau), is a must. - At least 3-5 years of programming experience in C#, Python and/or, with TSQL is a must. Experience with AWS and/or AZURE is required. - Good understanding of both relational database as well as non-relation database designs and concepts. - Able to communicate effectively, analytical with good time management, problem-solving and documentation skills.      "
/job/data-analyst-futurex-technologies-7007d5409cdf7c35b60fd75badff954b,"The successful candidate will be responsible for Global Banking(GB) and Commercial Banking(CB) Analytics, which will include data sourcing, data transformation, predictive modelling and creating Tableau dashboards. Create strong blending data capabilities within team so that we can come up with useful client information from data very quickly Engage with business stakeholders cross countries and gather requirement and liaise with ETL team to get the required data preparation. Promote analytics driven decision making processes across multiple segments/product portfolios Engage and execute the dashboards on Tableau or similar visualization tools Explore statistical and automation tools like R, SAS, Python for predictive and prescriptive analytics Engage relevant technology teams to embed advanced statistical tools Prepare and/or contribute to regular updates for various committees and governance forums Provide insights to senior management and the network based on MIS and analytics Highlight any perceived risks and early alerts to the management based on data analytics Perform data validation and dashboard performance optimization","RequirementsA proven track record with 4 years or more of relevant analytics work experience and demonstrated career progression/increase in responsibilities Strong academic record: Degree in Finance, Statistics, Computer Science or related field Knowledge of either SAS, R or Python Strong understanding of Hadoop Database Strong Knowledge of Tableau or similar visualization tools Proficient in excel and SQL Knowledge of statistical modelling and machine learning will be an added plus Understanding of the ETL process Highly effective verbal and written English communication skills Good presentation, time management, negotiation and influencing skills Ability to influence without authority Strong analytical and problem solving skills Experience in project management from business requirement definition, solution validation, user testing, technical documentation and production roll out Ability to manage multiple work streams with strong problem solving and analytical skills Strong communication and presentation skills to varying levels of management  "
/job/senior-data-analyst-rgf-talent-solutions-singapore-7e0d7177b1bcabba606d73b4c57f65c1,"You will be responsible for building operational data visualizations and performing statistical analysis. This includes Quality Control of Data queries or dashboards and support all specializations. You will  work with the Product Support, Operations Management and other stakeholders to improve their models and user experience.    ",RequirementsDegree holder with 7 years of experience  Past experience in creating data models is a plus. Background in payments / payment fraud with experience in SQL (Superset or PrestoDB).  Strong communication skills and strong team player with ability to work with large sets of data and generate actionable insights
/job/senior-manager-irisnation-singapore-eedf3e4ed9b4a1109dede573c065e4c7,"We’re Iris Concise (www.Iris-concise.com) – a global growth consultancy with offices across Asia, the US and Europe. We help our clients develop more valuable relationships with their customers. We are entrepreneurs ourselves and believe in offering clients new perspectives. We get to the point. Our business operates across 6 communities of practice – collaborative teams spanning our global offices in which we publish content, deliver projects and develop products. In Singapore we focus on 3 communities – commercial strategy, marketing effectiveness and digital transformation. Data underpins everything we do, and data science makes up our fundamental final community. Concise is part of Iris Worldwide, the global creative innovation network (www.Iris-worldwide.com). We drive business growth with many of the world’s household names –Samsung, Intercontinental Hotels Group, Phillips, Starbucks, Shell and others. Is this You? We’re looking for a strong data analyst, capable of turning a wealth of data into insights that can be used to increase the business impact of CRM, both through retention of existing customers and acquisition from competitors. The right candidate will be a self-motivated individual, capable of both working independently and leading workstreams, as well as collaborating as part of a team. You’ll be working as part of a cross-agency team (data, strategy, creative, production, operations) which is pioneering data-driven marketing for one of the biggest electronics brands in the world.","RequirementsWhat are we looking for ? For this role you must have:   Strong, hands-on experience in advanced analytics using SQL or similar   Experience in designing, developing, and applying advanced analytics solutions to commercial and marketing challenges   Experience owning the design and development of analytical projects   The ability to describe analytics and its outputs in a manner which is clearly understood by those without a working knowledge of data   Be capable of presenting data outputs to senior clients   A Bachelors / Masters degree (likely to be in the Economics, Mathematics, or other numerate fields) with 3-5 years of work experience For this role, ideally, you’d have:     An understanding of the broader context of analytics as one pillar of data-driven marketing   Experience working on CRM focussed projects   Experience working with Qlik to build automated dashboards What you’ll do   Work as part of a 10-person core team operating our client’s regional data-driven marketing program (1 x program lead, 4 x analysts, 5 x execution specialists)   Lead the delivery of regular insight deliverables (with the support and guidance of a Senior Data Scientist), producing exploratory analysis which informs business / marketing strategy and campaigns   Measure the effectiveness and business impact of marketing activities, and provide recommendations as to how activities should be optimised   Be responsible for consistently and proactively producing interesting and unexpected insights to our clients, positioning Iris Concise as a leader in data-driven marketing   Likely be 80% - 100% focussed on a single client for the first 6 months of your role    "
/job/senior-manager-irisnation-singapore-6e14524c2a61703ef7a0d12144f5474e,"We’re Iris Concise (www.Iris-concise.com) – a global growth consultancy with offices across Asia, the US and Europe. We help our clients develop more valuable relationships with their customers. We are entrepreneurs ourselves and believe in offering clients new perspectives. We get to the point. Our business operates across 6 communities of practice – collaborative teams spanning our global offices in which we publish content, deliver projects and develop products. In Singapore we focus on 3 communities – commercial strategy, marketing effectiveness and digital transformation. Data underpins everything we do, and data science makes up our fundamental final community. Concise is part of Iris Worldwide, the global creative innovation network (www.Iris-worldwide.com). We drive business growth with many of the world’s household names –Samsung, Intercontinental Hotels Group, Phillips, Starbucks, Shell and others. Is this you? We’re looking for a strong data analyst, capable of turning a wealth of data into insights that can be used to increase the business impact of CRM, both through retention of existing customers and acquisition from competitors. The right candidate will be a self-motivated individual, capable of both working independently and leading workstreams, as well as collaborating as part of a team. You’ll be working as part of a cross-agency team (data, strategy, creative, production, operations) which is pioneering data-driven marketing for one of the biggest electronics brands in the world.","RequirementsWhat we’re looking for... For this role as Senior Manager,  you must have:   Strong, hands-on experience in advanced analytics using SQL or similar   Experience in designing, developing, and applying advanced analytics solutions to commercial and marketing challenges   Experience owning the design and development of analytical projects   The ability to describe analytics and its outputs in a manner which is clearly understood by those without a working knowledge of data   Be capable of presenting data outputs to senior clients   A Bachelors / Masters degree (likely to be in the Economics, Mathematics, or other numerate fields) with 3-5 years of work experience For this role, ideally, you’d have:     An understanding of the broader context of analytics as one pillar of data-driven marketing   Experience working on CRM focussed projects   Experience working with Qlik to build automated dashboards What you’ll do   Work as part of a 10-person core team operating our client’s regional data-driven marketing program (1 x program lead, 4 x analysts, 5 x execution specialists)   Lead the delivery of regular insight deliverables (with the support and guidance of a Senior Data Scientist), producing exploratory analysis which informs business / marketing strategy and campaigns   Measure the effectiveness and business impact of marketing activities, and provide recommendations as to how activities should be optimised   Be responsible for consistently and proactively producing interesting and unexpected insights to our clients, positioning Iris Concise as a leader in data-driven marketing   Likely be 80% - 100% focussed on a single client for the first 6 months of your role    "
/job/risk-data-analyst-cac40e8808a6a0c4112864a0633e3778,Great opportunity to work with one of the leading banks in Singapore and be a part of Risk Data Mart team for performing daily operational data checks.,"RequirementsMandatory Skill-set  Degree or Diploma in Computer Science, Business Studies or other related disciplines; Experienced in data extraction through SQL queries; Has a strong aptitude for numbers and comfortable handling large volumes of data; Meticulous in organizing, reconciling and investigating data and keeping track of progress with minimal supervision; Ability to independently perform and monitor Business As Usual runs, raise and resolve issues; Possess excellent  interpersonal and communication skills.  Desired Skill-set  Work experience in a Bank or financial institution.  Responsibilities  Perform completeness and reconciliation checks of data in Data Mart; Conduct follow-up with respective technology partner for any breaks and variances that are not within thresholds; Communicate and keep the stakeholders inform of any potential delay in BAU run; Build various checks and control mechanisms to ensure the data integrity and completeness; Perform ad hoc data analysis and profiling to support users and data related requests.  Should you be interested in this opportunity, please send your updated resume to apply@sciente.com at the earliest.  Confidentiality is assured, and only shortlisted candidates will be notified.  EA License: 07C5639  "
/job/data-analyst-sbs-transit-80bfa22b3640dd3083526ddc05ad28d3," Examine data set to uncover pattern, trend, customer preferences/other useful information, and communicate insights derived and provide recommendation to top management Manage cross functional team to keep track of market trends and changes Work with internal stakeholders in planning, formulating and implementing business polices Deliver daily, weekly and monthly operation reports to top management and regulatory bodies Ad-hoc duties and projects ","Requirements Minimum Degree/Diploma in Business Administration, Statistics, Analytics or related field Strong attention to details Working knowledge of Oracle SQL, Tableu and Python is required Strong Microsoft Excel skills such as Excel formulas, PowerPivot tables Knowledge in ISO Quality Management System will be an added advantage Ability to work independently and in a team-oriented environment "
/job/quality-data-analyst-adecco-personnel-34f4175aa229b0e405a44ef9f88ff16c,The Job  Analysing and grading large sets of data relevant to specific markets Investigating and providing feedback on issues reported Validating and correcting data from external sources ,RequirementsThe Talent  Min degree/diploma in any discipline. Strong web analytical and problem solving skills Hands on experience on quantitative analysis are required. Outstanding relationship building and problem solving skills. Required to have good geographical knowledge and the written local language of Korea 
/job/data-analyst-adecco-personnel-53aa81b4703a7168cfd3288ad3625e7b,"Experience in analysing large data sets and generating reports that identify patterns. Description  Accountable for the day-to-day evaluations for the Japanese Market and ensuring projects are completed on time.  Oversee the quality of ratings, collaborate and provide feedback Create high quality reports analyzing the issues and patterns  and provide insights to the backend team Able to train and lead fellow Analysts. Explore new relevance algorithms and features by rating pages and providing feedback to the backend team for improvement. Use metrics and query logs to uncover relevance and data issues and suggest chain     ","Requirements This role supports the Japan market and need to be proficient in Japanese language and cultural Works well with multi-functional teams, Engineers/Data Scientists who build complex algorithms. Ability to work effectively in a team environment with strong interpersonal skills. Strong quantitative skills, including analytical abilities and math proficiency. Strong analytical and problem-solving skills. Excellent verbal and written communication skills. Ability to work successfully with teams on multiple projects under tight deadlines. High attention to detail. Enthusiastic in bringing new, innovative ideas Proficient in Excel and sensitive to numbers "
/job/market-analyst-grabtaxi-holdings-962b6b110b66841082656a7f6fc8c7eb,"Get to Know Our Team: The team dubbed the “cool kids” is unconventional, exciting, and mysterious. We embrace teamwork, diversity, creativity, humor, and diligence.   Get to Know the Role: The team takes on some of the most challenging and fascinating market research in the fields of transport, food delivery, payments, and platform services. We apply both traditional and offbeat techniques to form key analytical perspectives of the ever-changing market. We promote a culture where we enjoy raising the bar constantly for ourselves and others, and that strongly supports the freedom to explore and innovate.   The day-to-day activities:   Use quantitative tools to provide uncover strategic and operational insights on various business verticals, regional markets, competitors, and any aspect of the external environment to help shape key stakeholders' perspectives.   Explore, analyze and aggregate data sets to provide actionable information. Create intuitive visualizations to convey broader these results to key stakeholders. Gather, analyze and disseminate insights.   Explore and create new data sources from time to time to further the team’s information-gathering capabilities.   Market Analyst (Data) is not characterized by the following:   Specializing in ETL, pipelining and other data infrastructure tasks. Though it is common to build and maintain some pipelines, we have a dedicated Data Engineering team for this.   Building, training and deploying machine learning models to production in support of our App. Most production models related to our App are managed by our Engineering and Data Science teams.   Taking an academic approach to Grab’s data. That is handled by our core Data Science team.   Responding to ad-hoc data requests from business teams. Most of the operational dashboards are maintained by our Data Analytics team.  ","RequirementsThe Must-haves:  A Bachelor's degree in any field. Strong foundation in data query/wrangling using SQL, python/R/Scala and data visualisation using tools like Tableau. An attitude of self-motivation, effective time management, and the ability to operate in a dynamic and fast-paced working environment. Experience in business, strategy and/or tech consulting would be an advantage. "
/job/digital-data-analyst-kerry-consulting-7b9dca9acb10200b5152f48c6e23d25d,"- Global Consumer Brand - Aggressive and high growth business - Excellent developmental opportunities across the region  Our Client is a Global Consumer Leader and is looking to hire a Regional Digital Data Analyst for the Asia Pacific region. Reporting to the Head of Digital Experience, you will play an instrumental role in building the Firm’s digital and data platforms and capabilities to provide market and consumer insights for respective countries. Support the business on the usage and application of digital and data. Design and manage an integrated analytics dashboard which delivers effective insights to meet the strategic requirements.  Assist and champion the implementation of a customer-led culture, working with the Regional Functions to help better define and understand our customers.  ","RequirementsThe ideal candidate has at least 5 years in digital roles within eCommerce. Experience in data management capacity is mandatory. The ideal candidate brings with him/her strong interpersonal and influencing skills. This is a high frequency travel role across Asia Pacific region. To apply, please submit your resume (in MS Word format) to Alicia Chew, Registration No: R1435541 Licence No: 16S8060 at ai@kerryconsulting.com, quoting job title and reference number AI15104.  We regret only shortlisted candidates will be notified."
/job/data-analyst-transformation-project-chandler-macleod-group-24926b459347ba55308cd4fa6b57d7b5," 23 Months Contract Global bank, based in CBD Up to $5,500 monthly  An established commercial bank is currently undergoing a business transformation process therefore we are recruiting an experience Data Analyst to support the team in ensuring smooth transition. The ideal candidate should come with a few years of experience in leveraging data, empowering business pain points and helping the team to uncover growth opportunities. In return, you will be working for a global brand and be responsible for the success of this huge transformation process. Responsibilities:  You will play a lead role in business transformation process in migrating cards portfolio and acquisitions Collaborate with various in-country team in assessing the transformation journey End to end project planning and management which include documentation, milestone tracking and providing results Understanding the breath and extent of project migration and provide necessary back up plan should there be any ","RequirementsRequirements:  Bachelor Degree with 3+ years experience in data/business analyst, project migration or business transformation role ideally within banking and financial industry Excellent project management capability and ability to work with in a cross-functional settings Analytical-thinking, meticulous with strong partnership experience Keen to commit for 23-months contract  Interested parties please click ""Apply Now""    Chandler Macleod Group Pte Ltd, EA Licence: 11C3837 Reference Number: 18697_154814877202267 Contact Details: JJuzailah Khatmin (EA Reg. No. R1110441)"
/job/commercial-data-analyst-gmp-recruitment-services-791c9b319e8fc26ee88a691f7f4867c9," A well-established FMCG.  Responsibilities:​​​ To provide financial, commercial and strategic support to the Regional and Commercial Directors and providing valuable insights that drives commercial results.   Key Responsibilities: Planning and Performance Monitoring  Highlight future risks and opportunities through data mining of internal and external data. Provide commentary to be included in the monthly business reviews. Analyzing and explaining current and historic performance, providing effective commercial business challenge to ensure key commercial targets are achieved or beaten.  Provide meaningful analysis and collaborate to produce insight  Understand the drivers of current performance. Use internal and external information to extrapolate future performance based on scenario planning. Work with business partners to turn analysis into value adding insight. Produce actionable insight that the enables the commercial team to improve commercial performance.  Manage strategic objectives  Work with business partner to produce the strategic plan using insightful analysis. Turn the strategic plan into strategic objectives. Support the production of commercially viable business cases to deliver the strategic initiatives. Turn strategic initiatives into budget deliverables. Monitor and track the delivery of strategic initiatives.  Projects  Analysis of business investments such as performing risk assessments and profitability analysis to support management in strategic decision-making.   ","RequirementsRequirements:  Degree in Business Administration, Economics, Mathematics, Finance or Accountancy; from recognized University. At least 5 years of relevant experience in handling big data, perform data mining role on a daily basis and present findings/recommendations to Senior Management. Excellent analytical skills, with proven track record in identifying issues and delivering solutions. Commercially focused professional with a pro-active outlook. Strong communication skills including the ability to translate numbers into a business story. Strong stakeholder management and ability to communicate with all levels of the business. Previous experience in a Finance Business Partnering role is an advantage. Advanced Microsoft Excel skills is required. Experience with a BI tool i.e. Tableau, Alteryx is desirable. Knowledge in SQL. Strong bias towards action - output driven.  ​​Other Information:​  Working Location: Tampines. Working Hours: Mondays to Fridays, 8.30am to 5.30pm.  To apply, please visit www.gmprecruit.com and search for Job Reference: 13862. To learn more about this opportunity, please contact Novita Tan at novita.adisutanto@gmprecruit.com We regret that only shortlisted candidates will be notified. GMP Recruitment Services (S) Pte Ltd | EA License: 09C3051 | EA Personnel: Novita Tan | Registration No: R1220374"
/job/senior-data-analyst-99-a17b2cb30afd62ddc9d73df3948816a8,"99.co is looking for a Senior Data Analyst to join our diverse team of people who are passionate about taking the real estate industry properly into the age of technology through innovation and a desire to solve its multitude of challenges. A numbers person, a communicator and a storyteller all in one, the analyst would partner closely with the product team to identify new opportunities and translate data to useful and actionable insights; steering and guiding the company in making effective product and business decisions. What you'll do:  Take ownership in delivering prompt, accurate and reliable data analysis in your area of ownership Partner closely with product and business teams on strategic deep dives, plan data metrics, and ad-hoc data requests Identify, analyse, and interpret trends or patterns in complex data sets Source and analyse consumer and agent behaviour data to help us improve existing algorithms Partner with business leads to understand, predict and provide solutions for the respective teams' data needs Locate and define new process improvement opportunities Taking lead on projects, as needed. ","RequirementsWhat you are/have/will be:  4-6 years of working experience in an analytics role is preferred Familiarity with Python and SQL, R is a bonus Able to embrace both the charms of individuality and teamwork Strong critical thinking with the ability to organise and prioritise data requirements and needs from business stakeholders in a logical manner Detail oriented and be able to work efficiently in a fast-paced team environment Always excited in learning new technologies and translating data into business solutions Detail-oriented or someone who reads everything and will paste an html peace character somewhere in your application ;) "
/job/data-analyst-optimum-solutions-d8fc06c411925aea9449ce92e0e77cc1,"Optimum Solutions (Company Registration Number: 199700895N), is a full spectrum Software Solutions and Services Company. Software services from Optimum are designed to deliver Enterprise Client-Server/ Multi-tier and Web based solutions across the entire value chain, spanning on-site consulting services to turnkey software projects. We started our operations in March 1997. Role : Data Analyst (SAS, R or Python)","RequirementsEssential Technical Skills:  §  Degree in Finance, Statistics, Computer Science or related field §  Knowledge of either SAS, R or Python §  Good understanding of Hadoop Database §  Strong Knowledge of Tableau or similar visualization tools §  Proficient in excel and SQL §  Knowledge of statistical modelling and machine learning will be an added plus §  Understanding of the ETL process  Engage and execute the dashboards on Tableau or similar visualization tools Explore statistical and automation tools like R, SAS, Python for predictive and prescriptive analytics  Engage relevant technology teams to embed advanced statistical tools"
/job/data-analyst-database-analyst-groupm-asia-pacific-holdings-631ebc36a74a85ee710dd711480e199d,"This role acts as a specialist to agency teams in all areas concerning the data platform and analytics services. You will be looked upon to provide designing, building and managing of data from various data platforms, as well as building efficient campaign analysis solutions to meet specific clients’ requirements. 3 best things about the job:  A role where you like to see yourself providing creative ideas to analyze post-campaign analysis and you have a liking for numbers! A role where you not only participate in day to day operational work but will be looked upon to generate ideas and initiatives proactively to drive client business needs A fantastic chance to build on regional exposure across multiple markets across APAC and develop strong project management skills with global teams   Measures of success – In three months:  Be familiar with multiple data and analytics platforms across multi markets to be able to support Regional team with collation and analysis of marketing performance.  In six months:  Own the build of various data sources (e.g. Datarama / Datamart) to support local markets with creative dashboard builds to help their reporting needs Be familiar in Adobe Analytics, AdWords, Facebook, Twitter, DCM to help deliver best practice in campaign set up Support trading team and client team with topline performance insights  In twelve months:  Able to manage builds for larger and more complex data management with minimal guidance. Also, you would be confident in discussing requirements from agency and client teams, driving data and analytics solutions to build credibility based on your business knowledge and experience gained. You, along with data manager, will be the go to people to provide oversight of performance marketing channels impact on business goals and help to drive optimization strategies based on your extensive understanding of campaign performance You will be able to recommend solutions and ideas to get the most out of data, support in data partnership conversations and be able to distill those ideas in to how they will support business goals   Responsibilities of the role:  Support Engagement/Business Lead to plan and design efficient online/offline campaign reporting solutions to meet agency and local market requirements Support agency teams in campaign insights demonstrations (internal and external) with creative dashboards Understanding of SQL/Python scripting to manage data and documenting instructions for everyone’s knowledge Comfortable with communicating and working with multiple WPP agency teams Understanding of marketing dimensions and metrics for campaign analysis and ad effectiveness and being able to effectively communicate and recommend where uplifts to performance can be delivered   What you will need:  Background in data management and analysis with a keen interest in leveraging data and technology to provide insights and analysis for advertisers and media agencies Experience with database concepts and big data platforms Experience with key data visualization tools including Datorama, Tableau, Power BI and Qlikview will be highly valued Ability to work collaboratively with multi-cultural business partners and stakeholders, work effectively within cross-functional teams Strong written and oral communication skills, ability to communicate effectively with business users from various teams   About Mindshare Mindshare, the global media agency network, and part of WPP, the largest marketing communications network in the world, has more than 7,000 employees, in 116 offices across 86 countries. Mindshare APAC has won over 300 awards in 2014/2015 and was the most awarded agency at the 2015 Campaign Asia Awards Festival. Mindshare was also recognised as the SMARTIES™ APAC ‘Agency Network of the Year 2015’ for the third consecutive year. Mindshare is also home to The 2015 Festival of Media Asia Pacific Rising Star – Jason Maggs. To learn more about Mindshare and our philosophy of Original Thinking, visit us at www.mindshareworld.com About Singapore GroupM Singapore operates in one of the most dynamic and exciting environments in the world. Although it is a small domestic market, there is a vibrant media industry which is undergoing rapid evolution as digital technology reshapes the way marketing supports advertisers’ needs. Being at the crossroads of Asia means that aside from the local clients and media owners, we also have a high proportion of multi-national clients and media owners. As the largest media investment management company in Singapore with over 41% market share (Recma) and over 650 employees, GroupM Singapore is the premiere organisation to join and develop a career in. GroupM APAC is committed to fostering a culture of diversity and inclusion. Our people are our strength so we respect and nurture their individual talent and potential.      ","RequirementsWhat you will need:  Background in data management and analysis with a keen interest in leveraging data and technology to provide insights and analysis for advertisers and media agencies Experience with database concepts and big data platforms Experience with key data visualization tools including Datorama, Tableau, Power BI and Qlikview will be highly valued Ability to work collaboratively with multi-cultural business partners and stakeholders, work effectively within cross-functional teams Strong written and oral communication skills, ability to communicate effectively with business users from various teams "
/job/data-analyst-mindtree-f03f4f6fe41d6939bbd04f73c94c7f1f,"1)    Around 6+ years of IT experience across varied development and support projects. 2)    Deep understanding and experience of working in Data and Analytics projects. 3)    Experience in working as Data Analyst – understanding data inputs and outputs and interfaces with various systems 4)    Experience in working as Business Analyst – understanding Business requirements and mapping the data elements to it and facilitating discussions with business and IT teams 5)    Experience on various ETL, reporting and analytical tools like SAS, Tableau etc. 6)    Project Task Tracking and Status Reporting. 7)    Excellent communication and problem-solving skills. 8)    Strong time management and client management skills.",RequirementsSame as Job Description
/job/senior-data-analyst-u3-infotech-94bd5065c37588a6d6e1f4d8d022fa18," Design and implement key components for highly scalable, distributed data collection and analysis system built for handling petabytes of data in the cloud. Move architecture and implementation through the development pipeline, from research to deployment Work with architects from other divisions at Happy Marketer and clients to contribute to analytics initiatives Analyse source data and data flows, working with structured and unstructured data Ensure team develops well designed, efficient and testable code Establish quality standards using automated unit testing and performance/load testing Perform proof-of-concepts (POCs) on new technologies and approaches Conduct evaluation and analysis of new and emerging technologies/tools as required Support continuous improvement by investigating alternatives and technologies and presenting these for architectural review Drive the design and architecture of the software assets to ensure that it is most up-to-date, leveraging the latest best practices Involve in sprint planning and performs code reviews as required Collaborate with other team members and stakeholders, while working with exciting projects with Web and Marketing Analytics ","Requirements Bachelor's degree in a technical or engineering field or equivalent practical experience. Experience reading software code in one or more server-side languages such as Python or Java Experience in architecting, developing and/or maintaining production-grade systems Experience in virtualization, multi-tenant cloud infrastructures, storage systems and content delivery networks Deep understanding of the current state infrastructure automation, continuous integration/deployment, SQL/NoSQL, containers, security, networking and cloud-based delivery models The ability to work with loosely defined requirements and exercise your analytical skills to clarify questions, share your approach and build/test elegant solutions in weekly sprint/release cycles. Must have worked in major transformation programs and have a strong ability to drive execution and consensus Excellent presentation and communication skills, with the ability to translate business requirements into technology solution Proactive and able to work under pressure, strong problem-solving skills and positive ""can do"" attitude "
/job/data-analyst-u3-infotech-6d6ba35c5b89399f784425eebc16df61," Lead and own the analysis of highly complex data sources, identifying trends and patterns in data and make recommendations based on analysis results. Perform root cause analysis on complex data anomalies and working closely data stewards to define best practice. Analyse data and generate insights in form of revenue/growth prediction, trends and anomalies, customer segmentation, DAU/MAU reports, conversion optimization, monthly reports etc. Facilitate review sessions with management, business users and other team members. Work closely with the account management to drive delivery and engagement. ","Requirements Bachelor’s degree in Computer Science, Information Systems or Data Analytics 1-2 years of experience working with SQL Hands-on experience managing large data sets Working experience with scripting languages like R, Python, etc Good communication and analytical skills "
/job/data-analyst-hydrogen-consulting-solutions-d71c348ca2407b61bf80ab1839c8840e,"·         Min. 2 years’ experience in banking industry preferably in Risk, AML/ KYC and data analysis ·         Proficient in SQL, good level of complex database data extraction skill is a must. ·         Proficient in Microsoft Excel is a must ·         Proficient in Tableau and Alteryx is preferred ·         Ability to collaborate effectively with a wide range of stakeholders ·         Highly independent and self-motivated; can progress on objectives with minimal supervision ·         Highly organized & meticulous; good eye for detail and accuracy ·         Capability to progress multiple tasks / projects simultaneously; strong ownership of tasks assigned ·         Effective verbal and written English communication skills ·         Ability to think laterally and outside the box ·         Degree or diploma qualified with a preference in a Business or Technology discipline",Requirements·         Engaging stakeholder in Understanding the request requirement ·         Extracting correct data field as per the request. ·         Validation extracted data against the front-end system. ·         Produce and present analysis to the Project Working Group to facilitate decision making. ·         Complete administrative ownership in terms of project related updates/paper submission.
/job/industrial-data-analyst-ic-pro-og-technologies-54f97212692a7eb2121719d4cf958a5e," Data Analysist for Analytical Solutions. Collect, organize and interpret statistical information to make it useful by problem solving and process improvements to our Industrial customers. Create Application and Industry based differentiation messaging and value propositions for Product, Service and Solutions. Collaborate with Process / Factory engineers to base models of outcomes (such as yield and energy use) on defined inputs and can use expert knowledge to solve problems throughout the process.  ","Requirements~ Determine implicit customer requirements through close interaction with customers to develop advance IT solutions. ~ Gather information on reputable sources and partners of latest technology trends. ~ Implement customised IT solutions to meet customer needs.  Degree/relevant qualifications in computer science with 3-5 years of experience in process control industry and analytical solutions Experience in analyzing the data structured by time, batch, combination of time and batch as well as cleaned to identify and visualize outliers and missing data. Experience in use of analytics tools to help determine the critical parameters and improve process by better understanding of the drivers of greater efficiency and cost savings Analytical Skills: Work with large amounts of data: facts, figures, and number crunching. You will need to see through the data and analyze it to find conclusions. Knowledge in AI technlogies and implementations Results-oriented "
/job/business-data-analyst-rgf-talent-solutions-singapore-1c39d70cd0ee3b916a6c6e812e9ea051," Primarily support the global Marketing team Work with large sets of data, perform detail analyses and turn them into actionable insights Present the findings to senior stakeholders and provide recommendations ","Requirements Degree holder, with at least 4 years of professional experience in data analytics Strong in SQL, Basic R/Python Understanding of causal inference methods Basic experience in econometrics or statistics is an added advantage Strong project management & stakeholder management "
/job/data-analyst-8192e95c174699cdc34b4409185f70a4," Develop and implement data collection, data analytics and other strategies to analyze statistical efficiency and guide decision-making Work with data scientists and other functions to deep dive on core issues and prioritize business and information needs Measure and analyze algorithm and model performance, uncover insights and/or identify targeted areas for improvements Design experiments and A/B tests, and operationalize them Monitor performance metrics to identify issues, new process or feature improvement and business growth opportunities Effectively conceptualize analysis to various stakeholders Design and implement reports and performance measurement dashboards ","Requirements A Bachelor's/Master’s degree, preferably in Analytics, Statistics, Mathematics, Economics or Engineering Minimum 2+ years relevant work experience in an analytics or insights related role. Technical expertise regarding data models, data mining and segmentation techniques. Strong foundation in data query/manipulation using SQL and data visualization using tools like Tableau Strong programming languages like R, Python, SPSS, Matlab or other tools for statistical analysis Strong analytical skills with the ability to collect, organize and analyze significant amount of information with attention to detail and accuracy Adept at queries, report writing and presenting findings Self-motivated and independent learner who is willing to share knowledge with the team Detail-oriented and efficient time manager who thrives in a dynamic and dynamic working environment "
/job/data-analyst-371c128516edd09c115dd8d60f55681f," Develop and implement data collection, data analytics and other strategies to analyze statistical efficiency and guide decision-making Work with data scientists and other functions to deep dive on core issues and prioritize business and information needs Measure and analyze algorithm and model performance, uncover insights and/or identify targeted areas for improvements Design experiments and A/B tests, and operationalize them Monitor performance metrics to identify issues, new process or feature improvement and business growth opportunities Effectively conceptualize analysis to various stakeholders Design and implement reports and performance measurement dashboards ","Requirements A Bachelor's/Master’s degree, preferably in Analytics, Statistics, Mathematics, Economics or Engineering Minimum 2+ years relevant work experience in an analytics or insights related role. Technical expertise regarding data models, data mining and segmentation techniques. Strong foundation in data query/manipulation using SQL and data visualization using tools like Tableau Strong programming languages like R, Python, SPSS, Matlab or other tools for statistical analysis Strong analytical skills with the ability to collect, organize and analyze significant amount of information with attention to detail and accuracy Adept at queries, report writing and presenting findings Self-motivated and independent learner who is willing to share knowledge with the team Detail-oriented and efficient time manager who thrives in a dynamic and dynamic working environment "
/job/talend-etl-developer-0336b06c32382e123bcb09896c9bff67,A challenging work environment where the selected candidate will perform Talend /Informatica development in a Big data ecosystem.,"Requirements5+ Years of Architecture and hands-on development of Enterprise Data Warehouse environment with focus on Data Integration (ETL) using any data Integration tool –  Talend, Pentaho  and Informatica · 2+ Years hands-on experience with Talend Big Data Integration version i.e. Design, develop ETL scripts, creating and deploying end to end Talend Data Big data Integration solution.   · Expert in ETL concepts of data integration, data migrations, data flow, data enrichment, data synchronization, change data capture and transformations.   · Expert level understanding of ETL frameworks – Developing Audit, Balance, Control; Validation architecture, Reconciliation etc. · Collaborate across multiple teams to research, architect, engineer and configure complex Data Integration solutions to specified requirements in support of global, business critical systems · Coordinate and oversee the assignments, delivery, and quality of deliverables. · Working experience with Hadoop ecosystem technologies (Hive, Pig, Spark), Distributed scalable data stores (HBase, Redshift), relational and NoSQL databases (Mongo DB, Cassandra etc ), Business intelligence tools and platforms/data quality tools would be advantage. · Working experience with Cloud Technologies AWS, Azure, Google cloud, Snowflake etc would be a big plus. · Experience in Agile. · Excellent communication, presentation & documentation skills. · Must be a team player with knowledge sharing capability."
/job/data-analyst-digital-service-tuv-sud-asia-pacific-44a3df99cbbb2c24439e5990aa61eb94,"  Position Summary   The candidate will be expected to work closely with the business and technical team members, as well as internal and external partners, in order to develop, apply and recommend Data Analytics solutions in the field of Smart Lifts and Smart City sectors. A sound knowledge of Data Analytics and corresponding software packages, as well as application specific expertise enable the candidate to efficiently implement and run context dependent data based solutions.        Key Responsibilities   §  Cooperate with subject matter experts and customers to develop application specific data based solutions   §  Perform data mining from various data sources collect, store and model real-time and offline data for specific applications    §  Implement and develop real-time analytics and business intelligence platform   §  Review and provide recommendations on data analytics platform implementation and algorithms during the implementation of IOT projects   §  Generate, maintain and provide statistical information for the specific applications on real-time basis   §  Review the data collection platform to ensure accuracy and reliability for analytics   §  Develop and lead data analytics activities in Singapore through strong interaction with other TUV SUD legal entities   §  Prepare reports, presentations and information to management, business development and partners  ","RequirementsKey Requirements §  Degree in Statistics, Mathematics, Computer Sciences, or equivalent studies with at least 4 years of data analyst experience in the technological field §  Knowledge of data modeling, statistical methodologies, data mining techniques and testing §  Good knowledge and understanding of local digital landscape, technology, business trends, business intelligence and smart technology applications §  Expert in real-time analytics, scripting languages and adept with Java, MapReduce and Hadoop, SQL databases §  Able to learn and deploy new systems and applications §  Able to articulate complex data and information effectively and clearly §  An independent, confident and proactive team player with work experiences in a multi-cultural, cross-divisional and inter-disciplinary culture "
/job/data-mis-business-analyst-helius-technologies-caa066696d6f252f39ab60ea1d90973a," Defining functional and data requirements around ongoing as well as upcoming Digi bank product features to deliver analytics MIS and dash boards   Develop and manage MIS reports and Qlikview Dashboards based on the requirements provided by business users. Develop efficient data models/data marts required to facilitate efficient usage of data for analytics and decision management. Define business analytics requirements clearly and engage in discussions and solutions around them to get them successfully implemented Work in tandem with IT to develop frameworks around data exploration, and report generation with Qlikview for management reporting. Efficient project management to ensure the delivery of analytics requirements are on time and with utmost quality Owning the end to end delivery of analytics requirements from requirements to testing and production deployment Manage day to day adhoc analysis requirements ","Requirements B.S. or master’s or equivalent degree in Statistics, Analytics, Applied Mathematics, Engineering or equivalent quantitative, Data management fields preferred. At least 8 years’ experience in industry (consumer banking, telecoms, retail) analytics and reporting using various analytical tools Strong programming skills using analytics tools, programming experience in Teradata SQL, SAS, Pyhton Experience of developing MIS dashboards and knowledge of Qlikview / development. Experience of data analysis, translating business requirements into source system data attribute identification, logical data model solution development and mapping the data attributes. Sound understanding of data models and knowledge of various data warehouse technologies Good understanding of technology tools especially those related to analytics, data & reporting business MIS Good written and oral communication skills  Technical Competencies  Teradata SQL /SAS/Python/ Teradata Data base and Big Data stack Cloud database architecture Hadoop framework tools Business Analysis/ Data analysis Qlik View/Tableau "
/job/project-manager-business-analyst-data-processes-antaes-asia-e0566ece2fcddd2c37fca036f10c6ddb,"- Contribute to IT projects in the banking industry for Antaes clients, especially in the Business Processes, Data and Data Lake areas - Perform Business Analysis for projects and IT tools evolutions (requirements gathering, general functional specifications, UAT coordination, change management, deployment plan) - Perform standard project management tasks (planning, budget, risks, Steering Committees preparation and running) - Work with all teams working on the same projects (Organisation, IT and business) - Drive and challenge business units assumptions - Work with functional users and ensure business readiness - Collaborate with developers and subject matter experts to establish the technical vision and make proper choices - Contribute to the promotion of Antaes services on top of assistance provided to clients","Requirements- Consultant profile - Experienced profile (more than 3 years of experience) - Solid exposure to Private Banking / Wealth Management business processes and activities. Good understanding of flows and Data used. - Knowledge of statistical programming language(s) is a plus - Good understanding and experience with project management best practices/ methodologies/ project lifecycle - Ability to manage relationship with other teams (Business and IT) - Strong analytical skills required to interpret customer business needs, challenge them and translate them into application and operational requirements - Excellent verbal and written communication skills - Very good English proficiency. Strong business language proficiency in French is a plus."
/job/crm-campaign-data-analyst-aspire-global-network-a5d88b15abfdd3c681d9a0cf4c5b8c8b,"A well-established British recruitment company is looking for a CRM Campaign Data Analyst, Asia Pacific to be based in Singapore. Having been in the industry for over 40 years, they have greatly expanded to include operations in various continents such as Asia Pacific, Africa, America and more. Some of their key industries include Financial Services, Healthcare, FMCG and Professional Services. Being part of the Group Services: Marketing team, you will report to the Senior CRM Manager, Asia Pacific. You will support the business in their data analytics requirements, propose methods to acquire and retain customers as well as be involved in growth campaigns across the APAC region. You will have the opportunity to implement improvements to their CRM processes and can expect to be promoted to a Manager in your next appraisal review, upon exceptional performance. If this is something you are looking for, apply now! Responsibilities:  Inform stakeholders and the business on upcoming methods involving data management Analyse data to inform business development and campaigns Work with IT to manage CRM system and data warehousing Be involved in CRM initiatives and oversee execution of campaigns Maintain and improve data management processes and accuracy Recommend and manage end-to-end marketing campaigns based on analysis of customer and client data Act as a liaison between the IT and CRM team to identify consumer segments to be targeted for campaigns Propose and implement database segmentation Carry out surveys to obtain feedback on how to improve business processes Provide advise and recommendations where necessary for business growth ","RequirementsRequirements:  At least 5 years of data analysis, coding and reporting experience in a SQL Server environment Experience in SQL data extraction, overseeing and driving campaigns and projects Analytical, data-driven, well-versed with Excel SQL experience is a must Ability to build strong relations with internal and external parties Experience working with several SDLC methodologies such as Waterfall and Agile Experience in PowerBI, Exact Target, Salesforce Marketing Cloud, Pardot or Marketo is preferred Experience managing campaigns, projects, proposals and presentations to senior management is preferred Exposure working with various teams across several regions is preferred Experience with Crystal Reports or other reporting package is advantageous  Interested? Apply away! Sophia Holmans - EA License: 11C4388 Registration: R1872027"
/job/crm-campaign-data-analyst-aspire-global-network-11b202ae623b7e0052e25a3adae7bc57,"A well-established British recruitment company is looking for a CRM Campaign Data Analyst, Asia Pacific to be based in Singapore. Having been in the industry for over 40 years, they have greatly expanded to include operations in various continents such as Asia Pacific, Africa, America and more. Some of their key industries include Financial Services, Healthcare, FMCG and Professional Services. Being part of the Group Services: Marketing team, you will report to the Senior CRM Manager, Asia Pacific. You will support the business in their data analytics requirements, propose methods to acquire and retain customers as well as be involved in growth campaigns across the APAC region. You will have the opportunity to implement improvements to their CRM processes and can expect to be promoted to a Manager in your next appraisal review, upon exceptional performance. If this is something you are looking for, apply now! Responsibilities:  Inform stakeholders and the business on upcoming methods involving data management Analyse data to inform business development and campaigns Work with IT to manage CRM system and data warehousing Be involved in CRM initiatives and oversee execution of campaigns Maintain and improve data management processes and accuracy Recommend and manage end-to-end marketing campaigns based on analysis of customer and client data Act as a liaison between the IT and CRM team to identify consumer segments to be targeted for campaigns Propose and implement database segmentation Carry out surveys to obtain feedback on how to improve business processes Provide advise and recommendations where necessary for business growth ","RequirementsRequirements:  At least 5 years of data analysis, coding and reporting experience in a SQL Server environment Experience in SQL data extraction, overseeing and driving campaigns and projects Analytical, data-driven, well-versed with Excel SQL experience is a must Ability to build strong relations with internal and external parties Experience working with several SDLC methodologies such as Waterfall and Agile Experience in PowerBI, Exact Target, Salesforce Marketing Cloud, Pardot or Marketo is preferred Experience managing campaigns, projects, proposals and presentations to senior management is preferred Exposure working with various teams across several regions is preferred Experience with Crystal Reports or other reporting package is advantageous  Interested? Apply away! Sophia Holmans - EA License: 11C4388 Registration: R1872027"
/job/wealth-management-%E2%80%93-senior-data-analyst-client-analytics-associate-deutsche-bank-aktiengesellschaft-18457b38a0ba02f6a566296e50ea6274,"Private & Commercial Bank Deutsche Bank's newly established Private & Commercial Bank (PCB) corporate division combines the bank's expertise in private and commercial banking with Postbank in Germany and Wealth Management in one corporate division. Both in our home market of Germany and internationally, PCB offers our clients high-quality advice and a wide range of financial services from a single source. These range from comprehensive services for retail clients, to solutions for demanding clients in Private Banking and Wealth Management, to business and commercial client coverage. The distinct brands of Postbank and Wealth Management, together with Deutsche Bank’s private and business clients business, make for a strong pillar at Deutsche Bank: a modern advisory bank distinguished by its capital markets and financing expertise, its strong global network and cutting-edge digital services. Job Description Details:    Join the Wealth Management Client Intelligence team – best talents required! Wealth Management is establishing a new Client Intelligence team with the mandate to employ analytical approaches to promote business growth. Employing advanced analytics and data capabilities has become critical to the success of any wealth management enterprise. A wide spectrum of tools can be used to create personalized client experiences that reflect the clients’ individual needs, preferences, contexts and behaviours. We like you to contribute your ideas! The Client Intelligence team provides client-facing staff with state-of-the-art information for client prospecting, servicing and retention. As a key success factor, the team closely interacts with sales and product teams to identify and realise business opportunities. Collaboration within Deutsche Bank as well as with external partners further fosters idea generation. Joining the WM Client Intelligence team offers a unique opportunity to work within one of WM's strategic investment areas and within a truly global, dynamic and agile environment. It exposes you to a variety of exciting internal and external stakeholders, and it allows you to have a sizable impact on WM’s business.   Responsibilities will include:   Advanced mining and analysis of business / client data in order to generate new insights and enable informed actions Work with sales and product teams to identify, quantify and review new business opportunities and support day-to-day requests Continuous development and application of innovative, state-of-the-art approaches to enhance data and results quality Internal knowledge building, coherent presentation and positioning of analytics practices and trends, leverage of cross-functional developments       ","RequirementsRequirements   Educated to degree level (master or equivalent), incl. mathematical / statistical background Outstanding analytical skills and passion in exploring data Ability and experience with analysing large data sets, selecting an adequate approach and delivering innovative, high-quality end products Comprehensive Excel and Power Point know-how, ideally experience with QlivView / QlikSense Solid knowledge of data science and machine learning models / algorithms, combined with Python / SQL skills Good understanding of international financial services industry and capital markets; understanding of the relevant trends Ability to effectively work with internal partners and communicate persuasively Experience in working in a challenging, fast-paced, international environment Willingness to work in international locations if required for particular project phases Ability to deal with complex and ambiguous situations with limited guidance Good sense for prioritization and 'getting things done' mentality Strong team player with highest personal drive and a high degree of intrinsic motivation  Deutsche Bank offers a challenging and rewarding career where your contribution is valued and rewarded. We have an inclusive and friendly working environment coupled with excellent facilities and benefits. Deutsche Bank is an equal opportunity employer who seeks to recruit and appoint the best available person for a job regardless of marital status, sex (including pregnancy), age, religion, belief, race, nationality and ethnic or national origin, colour, sexual orientation or disability. Deutsche Bank does not accept unsolicited curriculum vitae from third party vendors. To apply for this role, please go to  https://dbcareers.db.com/psp/PRHCM91/EMPLOYEE/HRMS/c/HRS_HRAM.HRS_CE.GBL?Page=HRS_CE_JOB_DTL&Action=A&SiteId=3001&JobOpeningId=3185227&PostingSeq=1"
/job/associate-advisory-data-analytics-ernst-young-advisory-206ebc52e95674b6107a3f28f109848f,"Powered by big data and advanced technologies, insights from analytics are disrupting everything from how companies create competitive advantage to day-to-day business processes. But companies don’t have analytics problems; they have business problems that analytics can address.  Our view is that the human element is just as critical as technology and data to realizing true value from analytics.  This involves individual and organizational considerations that become the bridge from data to insights to action.      The opportunity  As a Senior Consultant, you will deliver value-added services to our clients and you are required to be a specialist in managing both structured and unstructured enterprise data and deliver analytics-related solutions to Ernst & Young clients across Asean.  In addition, you are required to communicate effectively with the project manager & team members in the region regarding the progress of the project and be a role model to the team members in exhibiting the Ernst & Young best practices.  At Ernst & Young, the true value lies in embedding analytics deeply into business processes at the point of where decisions are made – by human beings.   Your key responsibility:   This is a role where no two days are the same – so you’ll find yourself taking on plenty of new responsibilities as you go. You’ll work alongside clients and colleagues, balancing your time between developing security strategies, advising stakeholders, providing workshops and supporting business development. If you’re flexible and ready to adapt to a constantly changing environment, there’s no better place to develop your skills. Since you’ll be working directly with clients, some travel will be required.  Skills and attributes for success  Analytical and problem-solving skills combined with experience in leveraging data analytics to drive insights and business decisions.  Analyze client’s business and supply chain requirements Develop supply chain optimization models and statistical analysis using packaged as well as custom optimization software tools (e.g. LLamasoft Supply Chain Guru, LLamasoft Transportation Guru, SAS, R, Python, GAMS)  Analyze and interpret optimization results and derive insights  Communicate technical insight from analytics and modeling to senior executives in a business-oriented and pragmatic way  Provide critical thinking and subject-matter expertise to quantitative and qualitative aspects of client engagements Strong attention to details and ability to multi-task. A strong work ethic. A willingness to travel to meet client needs; travel is estimated at 20%. ","RequirementsTo qualify for the role you must have  BS in Engineering or Computer Sciences 1 - 3 years of working experience in consulting, analytics software-as-a-service or technology industry. Strong experience in solving supply chain planning and design problems using quantitative approaches Working knowledge of commercial network design tools such LLamasoft SCG, IBM LNP or similar  Advanced data analysis and processing skills in MS Access, Excel, and SQL Familiarity with custom optimization engines such as GAMS, LINDO, CPLEX Working knowledge on a statistical package such as SAS, SPSS, R or Python  Working knowledge of visualization tools like Tableau, QlikView or any other BI solution. Strong understanding of supply chain design levers and metrics Understanding of supply chain planning at strategic, tactical and operational level  Fundamental understanding of science behind optimization Articulate, with excellent oral and written communication skills. Adaptable, able to interact and build strong relationships with people from a diverse range of backgrounds. Intellectually rigorous, with strong analytical skills and a passion for data. Sound logical reasoning and deep thinking ability. Ability to work accurately to a high level of detail.  Ideally, you’ll also have  MS in Operations Research, Industrial Engineering, Decision Sciences, Engineering or Computer Sciences (preferred) Supply Chain certifications such as CSCP / CPIM are a plus  We offer a competitive compensation package where you’ll be rewarded based on your performance and recognized for the value you bring to our business. In addition, our Total Rewards package includes medical and dental coverage, and a range of programs and benefits designed to support your physical, financial and social wellbeing. Plus, we offer:    What working at EY offers We’re interested in flexible professionals with excellent problem-solving skills and the ability to prioritise shifting workloads in a rapidly changing industry. You’ll also need the confidence to give professional advice and guidance to colleagues and clients from a diverse range of cultures, often with limited information – both verbally and in writing. If you’re a fast learner, with strong influencing skills and a genuine passion for information system security, this role is for you.   What we look for  Support and coaching from some of the most engaging colleagues around. Opportunities to develop new skills and progress your career. The freedom and flexibility to handle your role in a way that’s right for you.    About us   EY is a global professional services organisation providing advisory, assurance, tax and transaction services. We are committed to doing our part in building a better working world for our people, our clients and our communities. And we are united by our shared values and a dedication to delivering exceptional client service.   Want to get to know us better?  Visit www.ey.com/SG/careers  Become a fan on Facebook: http://www.facebook.com/EYSGcareers  Connect with us on Linked In: http://bit.ly/EYLinked_Careers  Watch us on YouTube: http://www.youtube.com/ernstandyoungglobal    We regret that only shortlisted candidates will be notified.  © 2017 Ernst & Young Advisory Pte. Ltd. All Rights Reserved."
/job/associate-advisory-data-analytics-ernst-young-advisory-a39cbc759f5dcf234b4d8b3dfb45fe9f,"Powered by big data and advanced technologies, insights from analytics are disrupting everything from how companies create competitive advantage to day-to-day business processes. But companies don’t have analytics problems; they have business problems that analytics can address.  Our view is that the human element is just as critical as technology and data to realizing true value from analytics.  This involves individual and organizational considerations that become the bridge from data to insights to action.      The opportunity  As a Senior Consultant, you will deliver value-added services to our clients and you are required to be a specialist in managing both structured and unstructured enterprise data and deliver analytics-related solutions to Ernst & Young clients across Asean.  In addition, you are required to communicate effectively with the project manager & team members in the region regarding the progress of the project and be a role model to the team members in exhibiting the Ernst & Young best practices.  At Ernst & Young, the true value lies in embedding analytics deeply into business processes at the point of where decisions are made – by human beings.   Your key responsibility:   This is a role where no two days are the same – so you’ll find yourself taking on plenty of new responsibilities as you go. You’ll work alongside clients and colleagues, balancing your time between developing security strategies, advising stakeholders, providing workshops and supporting business development. If you’re flexible and ready to adapt to a constantly changing environment, there’s no better place to develop your skills. Since you’ll be working directly with clients, some travel will be required.  Skills and attributes for success  Analytical and problem-solving skills combined with experience in leveraging data analytics to drive insights and business decisions.  Analyze client’s business and supply chain requirements Develop supply chain optimization models and statistical analysis using packaged as well as custom optimization software tools (e.g. LLamasoft Supply Chain Guru, LLamasoft Transportation Guru, SAS, R, Python, GAMS)  Analyze and interpret optimization results and derive insights  Communicate technical insight from analytics and modeling to senior executives in a business-oriented and pragmatic way  Provide critical thinking and subject-matter expertise to quantitative and qualitative aspects of client engagements Strong attention to details and ability to multi-task. A strong work ethic. A willingness to travel to meet client needs; travel is estimated at 20%. ","RequirementsTo qualify for the role you must have  BS in Engineering or Computer Sciences 1 - 3 years of working experience in consulting, analytics software-as-a-service or technology industry. Strong experience in solving supply chain planning and design problems using quantitative approaches Working knowledge of commercial network design tools such LLamasoft SCG, IBM LNP or similar  Advanced data analysis and processing skills in MS Access, Excel, and SQL Familiarity with custom optimization engines such as GAMS, LINDO, CPLEX Working knowledge on a statistical package such as SAS, SPSS, R or Python  Working knowledge of visualization tools like Tableau, QlikView or any other BI solution. Strong understanding of supply chain design levers and metrics Understanding of supply chain planning at strategic, tactical and operational level  Fundamental understanding of science behind optimization Articulate, with excellent oral and written communication skills. Adaptable, able to interact and build strong relationships with people from a diverse range of backgrounds. Intellectually rigorous, with strong analytical skills and a passion for data. Sound logical reasoning and deep thinking ability. Ability to work accurately to a high level of detail.  Ideally, you’ll also have  MS in Operations Research, Industrial Engineering, Decision Sciences, Engineering or Computer Sciences (preferred) Supply Chain certifications such as CSCP / CPIM are a plus  We offer a competitive compensation package where you’ll be rewarded based on your performance and recognized for the value you bring to our business. In addition, our Total Rewards package includes medical and dental coverage, and a range of programs and benefits designed to support your physical, financial and social wellbeing. Plus, we offer:    What working at EY offers We’re interested in flexible professionals with excellent problem-solving skills and the ability to prioritise shifting workloads in a rapidly changing industry. You’ll also need the confidence to give professional advice and guidance to colleagues and clients from a diverse range of cultures, often with limited information – both verbally and in writing. If you’re a fast learner, with strong influencing skills and a genuine passion for information system security, this role is for you.   What we look for  Support and coaching from some of the most engaging colleagues around. Opportunities to develop new skills and progress your career. The freedom and flexibility to handle your role in a way that’s right for you.    About us   EY is a global professional services organisation providing advisory, assurance, tax and transaction services. We are committed to doing our part in building a better working world for our people, our clients and our communities. And we are united by our shared values and a dedication to delivering exceptional client service.   Want to get to know us better?  Visit www.ey.com/SG/careers  Become a fan on Facebook: http://www.facebook.com/EYSGcareers  Connect with us on Linked In: http://bit.ly/EYLinked_Careers  Watch us on YouTube: http://www.youtube.com/ernstandyoungglobal    We regret that only shortlisted candidates will be notified.  © 2017 Ernst & Young Advisory Pte. Ltd. All Rights Reserved."
/job/quality-admin-wanco-manpower-a2232ed8c5bbf04db47752023bff618c,"Quality Admin/Office based/6 to 9 months contract/West Area Basic salary SGD1800 – SGD3000 Working hours: 8:30am to 5:30pm, Mon to Fri Location: near Joo Koon MRT - Assist Quality Department in compile Quality Data - Meticulous and organised - Computer Literacy - Other admin duties as assigned","Requirements- Admin experience in manufacturing and marine industry would have advantage - Candidates with past admin experience are also welcome - Education level: NITEC or equivalent, Diploma in Engineering is a plus - prefers candidate who are able to start work immediately. Interested candidates please kindly drop me your resume and indicate ""Quality Admin"" at apply@wanco-manpower.com Only shortlisted candidates will be notified."
/job/data-analyst-55a4389d9650934c9aa5c542134ccd92, Identify valuable data sources and automate collection processes Undertake preprocessing of structured and unstructured data Analyze large amounts of information to discover trends and patterns Build predictive models and machine-learning algorithms Propose solutions and strategies to business challenges Present information using data visualization techniques Collaborate with engineering and product development teams ,"Requirements Proven experience as a Data Scientist or Data Analyst Experience in data mining Understanding of machine-learning and operations research Experience using business intelligence tools and data frameworks Analytical mind with strong business acumen and problem-solving skills Excellent communication and presentation skills BSc/BA in Computer Science, Engineering or relevant field; graduate degree in Data Science or other quantitative field is preferred   "
/job/data-analyst-enterprise-metadata-standard-chartered-bank-f056ffef0c28d5ba33a47fe0766c49a5,"About Standard Chartered  We are a leading international bank focused on helping people and companies prosper across Asia, Africa and the Middle East.   To us, good performance is about much more than turning a profit.  It's about showing how you embody our valued behaviours - do the right thing, better together and never settle - as well as our brand promise, Here for good.  We're committed to promoting equality in the workplace and creating an inclusive and flexible culture - one where everyone can realise their full potential and make a positive contribution to our organisation. This in turn helps us to provide better support to our broad client base. The Role Responsibilities The Metadata team is part of the Data Governance team within the Chief Data Office, and plays a critical role in partnership with the business & relevant technology teams in drawing up a list of data elements for all identified data domains in the bank. The data elements documentation captures,  The business term and description The golden source of the identified data element The technical table/field for that data element in the golden source Any known data standards  The purpose of this role is support the Data Governance team in its objective to document the data elements and the associated data as detailed above and to play a second line role in the governance of the data.  Key Responsibilities: 1.     Identify and document the data elements/business concepts & descriptions for each of the identified domains in the bank by leveraging the existing data dictionaries and the data available in the banks data management platform. 2.     Record and maintain the information on the golden sources of the identified data elements 3.     Work with the relevant business partners and technology teams to document the technical table/fields for the data elements in the golden source. 4.     Assist the business teams in documenting the data standards 5.     Own and drive the ownership process of the documented data with the business and ITO owners 6.     Work on the exceptions/gaps identified through discussions with the relevant stakeholders and obtain sign-off from Business / CIO reps 7.     Assist in the implementation and governance of the metadata management tool. Key Stakeholders 1.     Business, CIO and Functions Teams 2.     All teams within the Chief Data Officer function including Enterprise Data Management (EDM) team","RequirementsOur Ideal Candidate Qualifications  Degree in Computer Science or Data Management specializing in Information Management, or equivalent Relevant industry and professional certification in Data or Metadata Management will be advantageous  Domain knowledge  5-10 years of work experience in Banking domain involving one or more of the following: Core Banking, Trade & lending products, Treasury products (Foreign exchange, Money market, Bonds etc), Client on boarding or Due diligence, Regulatory or Internal reporting, sanctions/ anti-money-laundering, Risk Management (Market, Credit or Operational), Data Governance, OR 5-7 years’ experience on data management including managing data operations, handling metadata, implementation of sourcing data from transaction processing systems for metadata projects, experience implementing data quality management processes and workflows, experience dealing with internal and external stakeholders on remediation of data quality issues for metadata, experienced rolling out education and training programs for metadata programs and projects, etc  Technical skills All members of the Metadata team must be very comfortable with MS Excel (critical to data analysis work). In addition, any combination of the following skills will also advantage (though not mandatory)  Knowledge of Logical data modelling concepts including practical experience in implementing the same Experience of working with any of the major transaction processing systems (e.g., Imex, Murex, ACBS) or data warehouses (Teradata, Hadoop, etc) used in SCB Experience of working in tools like Tableau, Microstrategy etc.  Intrinsic traits  Attention to detail Curiosity High degree of responsibility Self-motivated, requiring minimal supervision Structure and discipline Good written communication skills Able to challenge/ question   Apply now to join the Bank for those with big career ambitions.  How to Apply Click here ( https://scb.taleo.net/careersection/jobdetail.ftl?job=1900000094&lang=en ) to apply now and take the next step in fulfilling your potential You can search and view current opportunities across our organization and apply immediately by visiting www.standardchartered.com and selecting Careers. To help speed up your application, please note the following:  You will need to log in (or register if you are visiting our careers site for the first time) before you can apply for a specific role Some roles may require you to undertake an online talent assessment in addition to completing the application form (to facilitate this process it is preferable that you provide us with an email address as part of your contact information) We will ask you about your education, career history and skills and experience, it may be helpful to have this information at hand when completing your application  It usually takes 15 - 20 minutes to complete the application form; you can save your application at any time and return to complete it at your convenience."
/job/crm-executive-bizhub-asia-06fc20e9b9860744903fec432b3152e4," Assist the team in leads management planning, coordination and execution of CRM campaigns/ activities that align and optimise company’s objectives. System updates on customers’ particulars, generating reports and leads/ prospects tracking management. Assist in the planning and execution of CRM programs to acquire and retain customers through Sales, Marketing and Aftersales initiatives. Initiate regular initiatives and CRM loyalty activities towards enhancing customer experiences. Any duties assigned by the manager. ","Requirements Minimum Diploma in Marketing/ CRM/ Business Administration. Minimum 2 years of Marketing/ CRM-related experience (preferably in the motor industry). Well-versed with knowledge of database management and CRM principles.    Qualified or interested candidate, Kindly click apply below or email us a copy of your resume in MS Word format to: jobs.bizhub@gmail.com Kindly indicate the following details in your resume: 1. Current and Expected salary 2. Reason for leaving for current and previous employment 3. Earlier availability date 4. Position that you are applying for We regret that only shortlisted candidates will be notified. However, rest assured that all applications will be updated to our resume bank for future opportunities/references."
/job/dlp-analyst-international-application-solutions-d6623e4af17d1e8de0773b498d7d1c8b,"·    Support to execute DLP strategy and initiatives according to the DLP roadmap including regional rollout planning. ·    Monitoring of DLP system (Email, Web, Endpoint, Network) to ensure:          Incidents are investigated and escalated in accordance to the DLP Incident response and handling procedures, All escalated incidents are tracked and followed up timely from beginning to closure and support business users to resolve DLP issues and closure of DLP incidents. False positive incidents are effectively and accurately filtered/ fine tune, Assist to handle Change Request for DLP Ruleset Policy.  ·    Support to review DLP Policy, maintain and ensure DLP standard operating policies and procedures are kept updated. ·    Support management reporting of DLP incidents and statistics in the DLP Change Control Committee (CCC). ·    Coordinate the DLP audit work; respond to questions or reporting requirements from local authorities as required. ·    Maintain good working knowledge of industry trends, products, relevant laws and regulation. ·    Manage the Information Security Awareness training for DLP related items.",Requirements-       Experience with administration and operation of Data Loss Prevention tools are preferred -       Experience in development and fine tuning of DLP policy/ rules are preferred -       Good Analytical skills -       Knowledge of banking processes are preferred -       Team player with good communication and interpersonal skills and be able to collaborate and interact effectively with Business Units -       Self-starter who is able to work independently
/job/data-engineer-alpha-z-analytics-singapore-e9ea9493274dd95bbe64877c715113cf,"Responsibilities This role’s primary job responsibility is defining the framework and process for preparing data for analytical uses.   The Data Engineer will support data analysts and data scientists on data initiatives and will ensure optimal data delivery architecture is consistent throughout ongoing projects.  This person should have extensive experience in: ·       building data pipelines to pull together information from different source systems;  ·       optimizing the flow, collection, integration, consolidation and cleansing of data;  ·       structuring data for use in individual analytics application;  ·       data preparation and building data structures in relational and NoSQL environment/databases; ·       deploying / configuring analytic tools, optimizing computing environment for analytic projects; and ·       deploying analytic projects to production:  deploying data science product via either API or batch job, automating the refresh of machine learning models, deploying real time models.   The right candidate will be excited by the prospect of designing data engineering solutions from ground up. ·       Create and maintain optimal data pipeline architecture; ·       Assemble large, complex data sets that meet functional / non-functional business requirements; ·       Identify, design, and implement internal process improvements: automating manual processes, optimizing data delivery, designing infrastructure for greater scalability, etc. ·       Build the infrastructure required for optimal extraction, transformation, and loading of data from a wide variety of data sources using ‘big data’ technologies; ·       Work with stakeholders (data analysts, data scientists, technology support team) to assist with data-related technical issues and support data infrastructure needs; ·       Build processes supporting data transformation, data structures, dependency and workload management","Requirements·        Degree in computer science with at least 3 years data engineering work experience in big data analytics environment. ·        Excellent data engineering skills with open source big data stack ·        Experience building and optimizing ‘big data’ data pipelines, architectures and data sets. ·        Strong analytic skills related to working with unstructured datasets.  ·        Experience with big data tools: Hadoop, Spark, Kafka, etc. ·        Experience with relational SQL and NoSQL databases ·        Experience with object-oriented/object function scripting languages: Python, Scala, etc. ·        Familiar with deployment and optimization of open source big data analytic stack on distributed environment. ·        Familiar with compiling, deploying and configuring open source data science tools including Python, R, Spark, etc. ·        Familiar with deploying analytic projects and data science products to production ·        Excellent programming skills"
/job/business-analyst-project-manager-data-science-2fe50cb7a17176b9cfb57102153837de,"Who We Are:  We NS Solutions Asia Pacific (NSAP), together with NS Solutions Japan, provides IT consulting and professional services primarily to financial industry. Distinguishing ourselves from a conventional IT company, we have long standing of relationship with major banking customers with strong track record of in-depth industry knowledge and rich experience of implementing large-scale enterprise systems. NSAP strengthens financial IT services through Project Planning and Promotion, consulting and implementation in Financial Regulation and IFRS arena, and financial data analysis as pivotal pillars of our business growth. To expand data analysis business NSAP forms a partnership with DataRobot, a leader of automated machine learning solution. (Link to press release: https://global.nssol.nssmc.com/sg/201901.html) As expanding the professional services to financial customers beyond Singapore, we are looking for talented, energetic and versatile staff to accelerate our business. Check our corporate web site for more information: https://global.nssol.nssmc.com/sg/ NS Solutions, the parent company, is one of the largest information technology company in Japan, with more than 6,000 professional staffs serving IT consulting and system development for a wide range of customers: manufacturing, finance, retail, telecom, and government sector.  Key Responsibilities:  Interact with business, technology and senior management stakeholders to define business issues, identify necessary data from internal/external sources to be analysed. Identify and collect structured and unstructured data from multiple data sources to analyse and generate meaningful insights. Analyze large amounts of data to discover trends and patterns. Fine-tune solution by working with business stakeholders including documentation of the data attributes, definitions and associated metadata. Perform data mapping, cleansing, data quality checks and verification of data integrity to ensure the data set is properly and accurately sorted out to address business issues. Responsible for running Proof of Concept (PoC) project to analyse data by using Machine Learning Software and techniques.  Clearly communicate complex analysis findings through presentation and documentations to technical and non-technical stakeholders. ","RequirementsJob Requirements:  Minimum 3+ years of experience in data management applications such as business intelligence, management information systems as Data Scientist or Data Analyst. Experience of working with large data set using Machine Learning Algorithms, Traditional or Deep Learning, Data Mining, Advance Analytics and Data Visualisation. Knowledge of advanced machine learning algorithms and statistics: regression, simulation, scenario analysis, predictive modelling, correlations, pattern analysis etc. Deep knowledge of data science best practices to explain proposed data model strength and weaknesses. Ability to conceptualise business problems and solving them through data analysis.[津田1]  Having industry expertise background from one of the followings is preferable: Financial (bank, insurance, leasing), Manufacturing, Telecommunications and Retail. Traveling within ASEAN region may be required.  Skills and Competencies:  Bachelor/Master degree with major and/or specialisation in Statistics, Mathematics, Computer Science, or Information Management is preferred. Visualisation: QlikView, Tableau, Cognos, SAP Business Objects. (regarded as an advantage) Programming Language: R, Python, SAS, and SPSS. (regarded as an advantage) Experience of SQL languages for data orchestration, manipulation and optimization is preferable. Strong attention to detail with clear verbal and written communication skills. "
/job/global-cds-operations-onetouch-data-analyst-bcd-travel-asia-pacific-833075bdb02a130f90002b8c39ac0810,"Where will YOUR career take you?          We’re not just a travel company. We help clients  travel smart and  achieve more. The department Global Client Data Solutions delivers Business Intelligence through the collection of our customers travel data globally and provides this to our consolidated & local customers in a meaningful end product. The information we provide supports our customer in general making decisions in their travel policies as it relates to compliance, spend management and negotiation of global contracts. For Global CDS we are currently looking for a:   Global CDS Operations OneTouch Data Analyst In this role you will be the first point of contact for all support queries related to our client reporting tools. You will work on a wide range of different tasks on a daily basis, from troubleshooting data, reports and tool issues to providing training, support and access to the tools. You will work with internal and external customers and coordinate with our internal technical teams. Client Data Solutions is a global team, so the Data Analysts will build close relationships with others from around the globe to support our day to day business.   Your responsibilities:  Carry out data investigations and study the issues to deduce origin and potential corrections. Troubleshoot data and tool issues/errors; analyse the return to make an informed deduction to be communicated to requesters. Provide training to internal and external clients on tools usage, processes and best practices. Keep current on all processes Seek opportunity for continued education on various functions/skills utilized. Troubleshoot report queries by reviewing report calculations, parameters and underlying data, and explaining what the reporting fields are returning and the report’s purpose. Set up 3rd Party exports/imports, and ensuring that there are necessary Data Release Authorisation in place. Create and maintain internal/external user access to the supported tools such as DecisionSource, FileMover, BCD API, etc. Provide assistance with system issues and maintenance. Consult on workarounds for system issues and work with internal departments to ensure larger issues are documented and in process of correction. Create new department processes with accompanying documentation as directed and approved by supervisor or manager. Provide business support for country reporting and internal data processes. Produce reports on an adhoc basis and investigate scheduled tasks. Support adhoc reports related to 3rd party data provisioning and data processing. ","RequirementsWe're looking for you if your profile matches the following:  Bachelor degree or equivalent or minimum 2 years Customer Service experience Excellent analytical and problem solving skills Proven ability to support customers and communicate effectively Excellent organization and time management skills Capability to work independently Advanced knowledge of MS Office Suite is preferred Strong command of English, written and verbal, with fluency in other languages SQL and relational database knowledge is advantageous Travel industry knowledge/experience is advantageous    What we offer you: This is an exciting job within an international work environment. You'll be working with a great international team of colleagues. And, we offer you a competitive package, training, career development, flexible hours and a dynamic work environment.   Your work location: Singapore   How to apply: Is this your next career move? Don’t wait any longer. Create a profile in our job portal on our website and upload your CV and cover letter.   Get to know us BCD Travel helps companies make the most of what they spend on travel. For travelers, this means keeping them safe and productive, and equipping them to make good choices on the road. For travel and procurement managers, it means advising them on how to grow the value of their travel program. In short, we help our clients travel smart and achieve more. We make this happen in 109 countries with more than 13,500 creative, committed and experienced people. And it’s how we maintain an industry leading client-retention rate of 95%, with 2017 sales of US$25.7billion. For more information, visit www.bcdtravel.com. This position is not open to third-party recruiting agencies."
/job/commercial-data-analyst-amos-international-19543dc08be6e64ef8800f010946b463,"We are looking for an experienced Commercial Analyst to drive commercial analysis and assistance from the preparation of data combined with reporting to drive business performance.   As a Commercial Analyst, you will report directly to the EVP Sales and Marketing.  You will be part of a team that supports and encourages growth and development – you will initially be focusing on customer product buying patterns, product pricing, stocking and inventory costs, distribution models for product supply, supporting procurement strategies and improving work flow efficiency.  In this role you will have many responsibilities that will cause your days to be varied, challenging and interesting. KEY JOB RESPONSIBILITIES    Managing and designing the reporting environment in collaboration with cross functional teams. Gather market intelligence data on clients, competitors and suppliers and communicate pertinent information to relevant groups and individuals to help identify trends impacting AMOS business. Analysis will include producer and market activity, marine supplies activities maps and movements, macroeconomic developments, market trends and future developments.   Analyze data and produce reports from Sales / Commercial systems to provide Global, Region and Product Line information to drive sales and understanding of the business drivers. Serve as the primary interface between the commercial, procurement, and operations. Assist with preparation and provide analysis to Board level. Compiling, formatting, editing and creating professional quality management reports and presentations Provide reports to Regions, Product Lines and Management from Sales systems as required. Examples include - Opportunity portfolio, Order backlog forecasts; risked revenue and contribution forecasts; indicative capital expenditure forecasts; risked and full values of priced enquiry book; key opportunities and status; bid win rates and analysis; regional and product line trends Assist with preparation of Monthly KPI’s and Sales Report. This report is to be continuously developed and improved by the Analyst to align with business requirements – including Market Share and Size analysis.     ","Requirements Min 5-7 years’ of experience in related industry Min 3 years’ of experience working in highly matrixed organization. Several years’ experience of commercial analysis and the use of the complex business analysis tools/techniques and reporting systems Previous international product supply experience is highly advantageous to hit the ground running Experience working under competing objectives, in a fast paced environment as part of an inclusive team Diploma or bachelor’s degree (ie Economics, Finance, Business Analysis) Advanced Excel skills, e.g. comfortable with Pivots and V-Lookups & accounting "
/job/finance-data-analyst-ntt-data-singapore-06c829770da2898af4c61351844e5fa7," A key member of the data analysis team and be able to breakdown Finance data problems into parts that can be resolved. Identify, analyze, and interpret trends or patterns in complex Finance data sets You will work with a team of analysts, comprising of businesses, business analysts, process subject matter experts, technology leads to deliver current state analysis, process re-engineering, establish and facilitate resolution to data quality issues Leverage technical capabilities to drive the development, evolution, and implementation of data enhancements, that will enable self-service by data consumers Evaluate data management, data quality and data access processes for gaps, inefficiencies and opportunities; provide recommendations for improvement Implement solutions and processes for management and governance across data quality metrics, metadata, lineage, data access rights and business definitions Establish effective and adaptable stakeholder working group Provide support to users and assist business unit controllers in translating finance data requirements into deliverables Ensure technical solutions provided are appropriate and support process changes Ensure successful delivery of resolutions and enhancements from analysis and specification of users' requirements, solutioning, test planning, facilitation of simulation, preparation for implementation, live verification and documentation Maintain a robust communication between all the stakeholders to ensure coordination and delivery of task and activities, proper engagement and drive effective management decision making on relevant issues escalation ","Requirements Degree in Banking, Computer Science or Engineering-related field with relevant experience in Finance and MIS reporting and data analysis in financial services industry Strong analytical skills with the ability to collect, organize, analyze, and disseminate significant amounts of information with attention to detail and accuracy In-depth knowledge of banking products, general ledger, finance processes Strong presentation, analytical and problem solving skills Excellent written and communication skills Delivery focused and results oriented Attention to details and highly organized and able to work under pressure in a time-critical environment Ability to work with complexity and ambiguity and use it to their advantage "
/job/data-analyst-comtel-solutions-c343191e1fb552647ea81ff5f915450d," Define hypotheses and identify the analysis trail for given business problems. Help create new solution approaches for innovative analytics scenarios. Develop proofs of concept and validate results. Implement small and large-scale projects in Advanced Analytics to help derive business insights for measurable success. Advanced working SQL knowledge and experience working with relational databases, query authoring (SQL) as well as working familiarity with a variety of databases. Experience building and optimizing 'big data' pipelines, data architectures and data sets. Knowledge of machine learning techniques and algorithms, such as K-NN, Naive Bayes, SVM, Decision Forests, etc. Expertise in design & development of API's, Web Services (REST, SOAP, etc ..) is needed   ","Requirements 8 – 10 years of development and delivery experience Experience with big data tools: Hadoop, Spark. Experience with object-oriented function scripting languages: Python, C++ Experience with statistical computer languages (Python, SQL, R) to manipulate data and draw insights from large data sets. Experience with common data science toolkits, such as NumPy, Pandas. R, etc.   "
/job/data-management-analyst-manpower-staffing-services-06eb7fb7ab566994f030c56b27a3c384,"We are looking for new members to help us achieve our goals by ensuring security of our clients’ platform and identifying and eliminating fraud. You will have responsibility for achieving your own daily processing targets and will also be responsible for engaging with the team to promote high performance culture and great place to work.   Responsibilities:  Review and Approve or deny connections within a review tool based on client Policy. Review data provided by advertisers and validate it matches the corresponding internal CRM object (e.g. the contact for the advertiser’s company). Review subjective content (e.g. Ads run by the advertiser or the account billing address) and tag it to existing Client Relationship Management listings. Read, understand and make decisions based on policy documents Correspond with internal salespeople regarding any appeals filed. Review non-objectionable content, create tasks, follow-up on open tickets Provide feedback on trends identified in reviews. General data entry related tasks. Provide suggestions to improve the process and workflows Translate content in foreign language from local countries’ counterparts into English for the team ","Requirements Familiar and uses social media accounts/products Excellent work pacing (time management) skills, able to work independently Attention to detail is essential to ensure the quality of work execution Able to work in multiple tools/web browser windows at one time Motivated, takes initiative, high energy Familiar with MS office (mainly excel) for updating progress Candidates should have good search and navigating skills Interpersonal Skills Self-starter, can easily adapt to change (new content, changing policies) Good problem solving Business language proficiency (written and oral) in Hindi/Thai/ Vietnamese/ Bahasa Indonesia/ Japanese/ Korean/ Mandarin to liaise with local countries' counterparts. Interested candidates must substantiate language proficiency with relevant certifications. Must be keen to work in Social Media/Digital environment    ** We regret to inform that only shortlisted candidates will be notified.  We respect your privacy and all communication will be treated with confidentiality.  If you wish to know more about this position or explore other roles, please prepare your updated profile and get in touch with our consultants at 6232 8811 (EA License: 02C3423)  Please note that your response to this advertisement and communications with us pursuant to this advertisement will constitute informed consent to the collection, use and/or disclosure of personal data by Manpower for the purpose of carrying out its business, in compliance with the relevant provisions of the Personal Data Protection Act 2012."
/job/data-analytics-lead-govt-30350906feb2873b728135416dff3262,"The Role: Data and Analytics Lead   GOVT’s growth stage in 2019 and beyond – Expanding to become a fully integrated agency with core capabilities and portfolio in Creative, Strategy and Digital. We are looking for a Senior Data Analyst / Analytics Lead to establish and kick start GOVT’s Data Analytics Practice, and be a key business partner to:  Drive new business opportunities and organic business growth on existing clients/accounts, Set up an independent data analytics function, and Support strategic integration of cross-agency teams and disciplines, with a core focus on data analytics and social listening  Business Growth  Partner with the Digital Lead and Creative Director in new business hunting, pitching and development to expand client portfolio and service offerings (target: 3 – 5 pitches for the year) Identify challenges and opportunities from a data and analytics standpoint, within existing clients/accounts, and be the main driver to unlock potential opportunities into additional scope of work and revenues for the agency/unit Will be appointed as the analytics lead on new business pitching, working alongside with other account/unit and department leads where needed   Set Up of Data and Analytics Unit  Will be put in charge to set up a data and analytics function/unit, which includes the co-development of the team’s vision and roadmap; aligned to the overall business plan. Roadmap should entail:   Service offerings, products and solutions, agency credentials Resources (people + platforms) and investments needed Internal processes and ways of working – across agency functions/units   Responsible to help drive a “data-driven” creative thinking and approach, by:   Offering value-add to clients and internal teams through strategic and innovative thinking and delivery of data/analytics services and solutions Providing guidance and counsel to both clients and internal team members, and be actively involved in the research/planning/insights development process Owning and driving optimisation efforts through the use of data and analytics with the rest of the agency teams Continually evolve the social listening practice in terms of process, tools and methodologies in order to maintain a best in class approach   Identify the talents required to assemble a functional analytics team by H2 2019. Build a team of best-in-class talents depending on the unit’s requirements. To ensure team is supported adequately in terms of mentorship, personal growth plans and other opportunities to ensure talent growth and retention.  Strategic Integration of Agency Team(s)  Supporting the Digital Lead and Creative Director in planning and developing internal training curriculum and modules Actively sharing of digital/social trends and knowledge with the wider agency team, which may include:   Regular trends updates / inspirations – case studies, best practices, or emerging themes and topics, competitor analysis and industry insights Internal trainings/workshops – data and insights 101, how-to’s, etc   Co-drive pilot initiatives and programs (e.g. QuickFire Sessions) – Internal quarterly brainstorm and ideation for clients that can be used for proactive new business/pitching purposes  Your day-to-day responsibilities may include:  Host discovery sessions with internal stakeholders to understand client and business needs Design, conduct and deliver standard and custom reports and analysis (e.g. social listening, competitor analysis, trends and insights, post-campaign) that transform data into a clear story Visualize findings legibly using charts, tables and infographics, and provide concrete recommendations and actionable insights for optimisation Set up tools/platforms and dashboards for tracking and reporting purposes    ","RequirementsOur ideal candidate:  You're well-organised, detail-oriented and digitally savvy Excellent communication skills Strong analytical and problem solving skills with proficiency in social analytics and listening tools and methodologies Able to think strategically and “big picture”, but also operationally sound and willingness to get hands-on Ability to dive deep into data to uncover and translate findings into actionable insights and creative inspirations Strong leadership skills but also a team player working with multiple internal stakeholders and teams "
/job/project-analyst-stakeholder-company-4433f5bb9e1af8214a22823f357e1fbd,"The Data Analyst is central to the development of the volume, accuracy and quality of the company’s core data sets through stakeholder and issue driven research and data collection. Your core tasks will be to: - Collect and evaluate information on stakeholders (individuals and organizations) and relationships - Identify news sources for specific projects, define filter criteria and evaluate relevant news items. Further tasks can be added according to your interests and performance.","Requirements    Excellent problem-solving capabilities and research skills;   An ability to adapt readily and multi-task;   Enthusiasm for elegant, pragmatic solutions;   Motivation, talents, and passion;   Ability to manage a small team and ensure high standards of work;   Strong plus: Technical skills (data analysis, statistics, computer science, engineering background or experience with web technologies, etc.)   Strong plus: track-record in business development or digital marketing    "
/job/senior-executive-data-management-singapore-land-authority-8d8f05a3a05a9318c493d661f784af72,"Senior Executive, Data Management
Job scope:
Collaborate with various stakeholders such as business units, IT teams and vendors to:

define business requirements for the enterprise data warehouse.
identify and implement necessary changes to data, business processes and systems to achieve data harmonisation and consolidation.
develop and deploy the data warehouse solution.
seek visible ways (e.g. data analytics, data visualisation, applications) to apply or leverage data.

Requirements:

Experience in database development, administration and data management technologies.  Practical experience in database design, development and maintenance will be an added advantage.
Degree in Information Technology or Geographic Information Systems (GIS).
Keen interest in working with various types of land data such as land administration, planning, leasing and maintenance.
Team-player with good communication and interpersonal skills, as well as be able to work independently.
Comfortable to work independently in new areas. Pro-active, resourceful and able to suggest solutions.

 ",Not Available
/job/data-analyst-abakus-a781d0fe818de6c6f93707a2c2255137,"To reinvent an industry, you need to build an all-star team. Join Wecash if you want to realise a world of better living through responsible credit, by developing and promoting products that provide businesses with comprehensive and accurate evaluation of consumer credit worthiness as well as underwrite loans between funding sources and consumers. Wecash leverage upon the power of mobile technology, big data and machine learning to prevent fraud and determine consumer credit worthiness. Wecash started in 2014 and has since raised more than US$200 million in financing, acquired over 100 million users and processed more than US$5 billion in loans in 2017 alone. Wecash is creating a platform for financial products for the financially underserved utilizing artificial intelligence, big data and mobile technology. At Wecash, we move quickly, get stuff done, and are constantly iterating. Our innovative data science team of Wecash is looking for team mates who is keen on data analytics to join them in evaluating personal credit and detect financial fraud behaviours. You enjoy working on large data sets in a team with R&D culture. You are a self-starter and motivated to work within a team solving real-world problems and delivering the results. Responsibilities  Find model issues and propose method to improvement of model from evidence Interpret data, analyze results using statistical techniques and provide ongoing reports Develop case study and conduct experiments to identify, analyze, and interpret trends or patterns in complex data sets Process & visualize data and build features of the model Develop model to detect data outlier Identify and incorporate new data source that can benefit our business.   ","Requirements Demonstrated project experience in data science. Some knowledge of common data analytical models. Ability to interpret data and demonstrates the result to the team with critical thinking. Good programming skills in Python and database query. Strong analytical skills with the ability to collect, organize, analyze, and disseminate significant amounts of information with attention to detail and accuracy Adept at queries, report writing and presenting findings Undergraduate or Master’s in Computer Science, Engineering, Statistics, Mathematics or Quantitative Finance. Willing to learn, innovative, good communication skills and team player  Bonus skills  Ability to communicate in Mandarin or Bahasa Indonesia or other Asian language to communicate with counterparts in China, Indonesia and other APAC offices. Relevant working experience in the financial industry. "
/job/senior-consultant-data-analytics-unimas-consulting-solutions-08c8375d6f7ad44caf92e1b9564ff1a3,"BI/Data Analytics / FP&A, Management Reporting, ERP implementation Consultant Job Description Unimas Consulting Solutions, Singapore, is looking for Project Consultants/ managers versed in agile project management that can deliver business value to clients on Consulting and IT Implementation projects. We are currently looking for a Business Intelligence & Analytics Consultant with a functional profile to bridge the gap between Business and IT in order to deliver value-added predictive and descriptive analytics solutions to our clients. And all this across all business domains and industries: Manufacturing, CPG, FMCG, Agriculture, Pharma etc.   Within this role you will be part of our Digital Analytics practice working jointly with Strategy, FICO and Data structure and technology experts in Consulting and implementation projects. Analytics can be defined as the extensive use of data, statistical and quantitative analysis, explanatory and predictive models, and fact-based management decision making though KPIs, reporting and analysis to drive decisions and actions.   Major responsibilities would be   Building and maintaining the client relationship on both IT and business side. Lead/work within the Business / Data Analytics and Reporting Business practice Develop a team of consultants and solution delivery analysts for Data Analytics practice Work on clients projects in the area of Business Intelligence, Management reporting, KPI Dash boarding. Participate in the full lifecycle of an analytics or BI project: from gathering and understanding the end-user needs over creating the functional design, architecting the solution, supervising the detailed technical design and implementation, to preparing and executing the functional and product tests before handover Executing and reviewing assessment activities and maturity diagnostics on the analytics capability of a client (organization and processes, added-value analysis, application adequacy, IT capability) Participate in the development of strategies, operating models roadmaps and business cases for Analytics and BI solutions Contribute to Developing Unimas’s Research and knowledge capital, practice methodologies  Participating in business development efforts to secure new projects at new and existing clients Preferable exposure to Manufacturing and / or Agricultural Industry. Ability to Identify, assesses and solves complex business problems for area of responsibility, where analysis of situations or data requires an in-depth evaluation of variable factors Ability to influence senior management at a client and/or within Unimas on matters where they may need to gain acceptance on an alternate approach.   Provide consistent and clear communication between all project stakeholders, team members, Unimas members, client members Assist the sales department in creating proposals for prospects or existing clients Determine the approach to be used on the project Work with a business analyst to create a business analysis plan Define and document requirements from client stakeholders Prepare and lead Project review meetings Facilitate daily stand-up meetings Lead Process optimization and re-engineering Must be able to drive change management efforts as required by the project Monitor and track projects Prepare project communication plans Prepare and manage risk management plans Prepare and manage quality management plans Manage the project constraints of scope, time, budget, quality, risk, and resources Provide status reports to the executive sponsor or other stakeholders as required  Required Skills & Experience  Strong knowledge of SAP, Excel, Cognos and Hyperion would be preferable Worked / Managed in regional/global ERP implementation projects, with exposure to Top tier ERP softwares Bachelors / Masters degree in IT , Analytics Finance, Business administration, IT Systems Preferable PMP certification, preferred Agile/Scrum Master certification Good presentation and verbal and written communication skills Strong Personal responsibility, Pro-activeness and accountability Strong team facilitation, Time Management and problem solving skills Ability to work in an agile environment and with minimum supervision.  The ability to influence others, analyzing complex issues and delivering appropriate solutions Ability to travel, sometimes on short notice    ","RequirementsBI/Data Analytics / FP&A, Management Reporting, ERP implementation Consultant Job Description Unimas Consulting Solutions, Singapore, is looking for Project Consultants/ managers versed in agile project management that can deliver business value to clients on Consulting and IT Implementation projects. We are currently looking for a Business Intelligence & Analytics Consultant with a functional profile to bridge the gap between Business and IT in order to deliver value-added predictive and descriptive analytics solutions to our clients. And all this across all business domains and industries: Manufacturing, CPG, FMCG, Agriculture, Pharma etc.   Within this role you will be part of our Digital Analytics practice working jointly with Strategy, FICO and Data structure and technology experts in Consulting and implementation projects. Analytics can be defined as the extensive use of data, statistical and quantitative analysis, explanatory and predictive models, and fact-based management decision making though KPIs, reporting and analysis to drive decisions and actions.   Major responsibilities would be   Building and maintaining the client relationship on both IT and business side. Lead/work within the Business / Data Analytics and Reporting Business practice Develop a team of consultants and solution delivery analysts for Data Analytics practice Work on clients projects in the area of Business Intelligence, Management reporting, KPI Dash boarding. Participate in the full lifecycle of an analytics or BI project: from gathering and understanding the end-user needs over creating the functional design, architecting the solution, supervising the detailed technical design and implementation, to preparing and executing the functional and product tests before handover Executing and reviewing assessment activities and maturity diagnostics on the analytics capability of a client (organization and processes, added-value analysis, application adequacy, IT capability) Participate in the development of strategies, operating models roadmaps and business cases for Analytics and BI solutions Contribute to Developing Unimas’s Research and knowledge capital, practice methodologies  Participating in business development efforts to secure new projects at new and existing clients Preferable exposure to Manufacturing and / or Agricultural Industry. Ability to Identify, assesses and solves complex business problems for area of responsibility, where analysis of situations or data requires an in-depth evaluation of variable factors Ability to influence senior management at a client and/or within Unimas on matters where they may need to gain acceptance on an alternate approach.   Provide consistent and clear communication between all project stakeholders, team members, Unimas members, client members Assist the sales department in creating proposals for prospects or existing clients Determine the approach to be used on the project Work with a business analyst to create a business analysis plan Define and document requirements from client stakeholders Prepare and lead Project review meetings Facilitate daily stand-up meetings Lead Process optimization and re-engineering Must be able to drive change management efforts as required by the project Monitor and track projects Prepare project communication plans Prepare and manage risk management plans Prepare and manage quality management plans Manage the project constraints of scope, time, budget, quality, risk, and resources Provide status reports to the executive sponsor or other stakeholders as required  Required Skills & Experience  Strong knowledge of SAP, Excel, Cognos and Hyperion would be preferable Worked / Managed in regional/global ERP implementation projects, with exposure to Top tier ERP softwares Bachelors / Masters degree in IT , Analytics Finance, Business administration, IT Systems Preferable PMP certification, preferred Agile/Scrum Master certification Good presentation and verbal and written communication skills Strong Personal responsibility, Pro-activeness and accountability Strong team facilitation, Time Management and problem solving skills Ability to work in an agile environment and with minimum supervision.  The ability to influence others, analyzing complex issues and delivering appropriate solutions Ability to travel, sometimes on short notice    "
/job/2019-market-data-analyst-bloomberg-singapore-7a7e3a49f59da9e8288ff9b594ef0dd8,"You're the type of person who has a passion for taking raw numbers and turning them into actionable insights. Your friends all know you as someone with a true interest in technology, who likes nothing more than spotting a creative way to improve a process. You have a natural eye for detail, and an interest in the financial markets. You are independent and determined, but thrive as part of a team. You enjoy dealing with people, and you're that person who knows what customer service really means. Our team Bloomberg runs on data, and our Global Data department is responsible for acquiring it and supplying it to our clients. Our Market Data Analysts collect, analyse, process and publish the data which is the backbone of our iconic Bloomberg Terminal- the data which ultimately moves the financial universe. They apply problem-solving skills to identify innovative workflow efficiencies, and they implement technology solutions to improve our systems, products and processes- and all this while providing platinum customer support to our customers. We'll trust you to:   Acquire, update, maintain and process financial data using various internal systems and proprietary company software  Come up with innovative ways to enhance our systems and to make our data-related processes more efficient, accurate and timely  Participate in time-sensitive projects, and collaborate with your global colleagues to deliver new initiatives  Partner closely with internal departments such as Sales, Analytics, News and Engineering  Provide a platinum level of service to Bloomberg customers  What's in it for you?   Comprehensive training giving you a thorough overview of financial concepts, various data sets, and of course our state-of-the-art Bloomberg terminal  Gain in-depth, hands-on experience of one particular market sector (For example: Company Financials)  Opportunity to gain exposure to and interact with key market players in business and finance  Make a true business impact on our products and clients – our data moves markets!  Real potential for exciting and varied career progression ","RequirementsYou'll need to have:   Bachelor's degree or equivalent work experience  Excellent numerical and communication skills  Business fluency in English  A positive attitude with good inter-personal skills  The ability to multi-task, prioritise and work to tight deadlines  Meticulous attention to detail, with an aptitude for working quickly and accurately  Strong project management, problem solving and analytical skills  Proficiency in Microsoft Excel, with some advanced technical knowledge and experience (VBA, SQL, Python, MATLAB, R) Available to start in 2019  We'd love you to have:   Interest in, and knowledge or experience of financial statements and the financial markets  Prior experience of data research or process engineering  Fluency in one or more Asian languages  If this sounds like you: Apply! If we think you're a good match we'll get in touch to let you know the next steps. We are an equal opportunity employer and value diversity at our company. We do not discriminate on the basis of race, religion, color, national origin, gender, sexual orientation, age, marital status, veteran status, or disability status. Bloomberg is a disability inclusive employer. Please let us know if you require any adjustments to be made for the recruitment process by emailing access2@bloomberg.net."
/job/data-analyst-1-year-contract-group-customer-analytics-decisioning-oversea-chinese-banking-corporation-5b120f77eb039c7564c88a45aa75535f,"JOB DESCRIPTION:   Work alongside the Group Customer Analytics team to support development, rollout and ongoing data and insight support for the Stack Loyalty marketplace Build the pipelines to integrate data from Stack with the existing offline OCBC and partner data Apply data and advanced analytics to drive relevance of the offers presented within the Stack Application to end users. Develop dashboards to enable the Stack business development team & external partners to understand how the proposition is being received and identify new portfolio growth opportunities. Support “campaign as a service” for 3rd parties using the Stack platform. Conceptualise other opportunities for monetising the data within Stack – including data products and “analytics as a service” type initiatives. ","RequirementsREQUIREMENTS:  Minimum 2 years hands-on experience working in an analytical marketing team – actively developing dashboards, models, adhoc analysis and/or campaign management activity. Banking industry experience not necessary. Strong hands-on skills in analytical tools like EDW, SQL, Qlikview/Tableau, Unica, SAS. Knowledge of modern infrastructure and tools like Hadoop, Talend, Spark is a plus. Some exposure to model building in tools like SAS or open source (Python/ML) advantageous for offer recommendations – although support will be given. Excellent communication skills with the ability to articulate complex solutions to non-technical users. Energetic personality with an innovative, self-starting spirit. Someone that likes to ask “why?” "
/job/informatica-developer-addstones-sas-f2051b88516ce9d7f9297ea32965a1fd,"GFI Group is an international business and technology solutions provider, currently employing about 18,000 people Worldwide. GFI provides its clients with long-lasting innovative solutions to leverage performance from their information systems. We design and run industrial platforms tailored to the economic and human considerations of our clients.  • Management Consulting | Digital Transformation | Innovation • Operating over 20 countries, • 2017 revenue of over 1,2 billion USD,  • 48 years of existence. In order to support our forthcoming businesses and technological challenges, we seek innovative and agile people sharing our mind set. We are now looking for an Informatica Developer to join our team in Singapore.   Role and responsibilities:   This role requires a strong, technical, hands-on person focusing on Informatica infrastructure. The successful candidate will be a member of a dynamic IT Architecture team and will work with other Singapore, Hong-Kong and regional IT teams.  The Informatica Developer will be:   ·         Working with Business team to understand the requirements. ·         Managing and supporting Informatica in Linux environment. ·         Designing and developing complex Informatica ETL processes that integrate large data sets from multiple sources ·         Loading data warehouse objects including dimensions, hierarchies, fact tables and aggregates ·         Ability to create the metadata layers including physical, semantic and presentation layers ·         Experience with Oracle Data Warehouse Console (DAC) ·         Loading data into an enterprise data warehouse environment ·         Developing and maintaining Informatica PowerCenter solutions ·         Performing systems and data analysis to implement and optimize Informatica mappings and ETL workflows, data flows, shell scripts and stored procedure ·         Ensuring accuracy and integrity of data and applications through analysis, coding, writing clear documentation and problem resolution ·         ETL support experience: monitor, troubleshoot, track and document day-to-day production issues  ","RequirementsQualifications and Profile:   ·         At least 5 years of experience of Informatica development. ·         Experience in setting up ETL using Oracle EBS as the datasource ·         Experience working with a job scheduler application (Autosys) to design and schedule Informatica workflow ·         Experience with RDBMS (Oracle/SQL Server etc) and writing and tuning Oracle SQL and PL/SQL statements ·         Takes initiative and is results driven ·         Strong decision making and analytical skills ·         Act with integrity ·         Ability to manage change and complexity with confidence ·         Strong team player ·         Client focused and commercial thinking ·         Excellent interpersonal and communication skills ·         Self-motivated and genuine interest in Banking and Finance ·         Proficiency in Microsoft office (MS Word, Excel & Power point) ·         Exposure to big data and programming is a plus    "
/job/senior-associate-data-analytics-advisory-ernst-young-advisory-e69441151b61f82e1365e2cbeac67a39,"Powered by big data and advanced technologies, insights from analytics are disrupting everything from how companies create competitive advantage to day-to-day business processes. But companies don’t have analytics problems; they have business problems that analytics can address.  Our view is that the human element is just as critical as technology and data to realizing true value from analytics.  This involves individual and organizational considerations that become the bridge from data to insights to action.      The opportunity  As a Senior Consultant, you will deliver value-added services to our clients and you are required to be a specialist in managing both structured and unstructured enterprise data and deliver analytics-related solutions to Ernst & Young clients across Asean.  In addition, you are required to communicate effectively with the project manager & team members in the region regarding the progress of the project and be a role model to the team members in exhibiting the Ernst & Young best practices.  At Ernst & Young, the true value lies in embedding analytics deeply into business processes at the point of where decisions are made – by human beings.   Your key responsibility:   This is a role where no two days are the same – so you’ll find yourself taking on plenty of new responsibilities as you go. You’ll work alongside clients and colleagues, balancing your time between developing security strategies, advising stakeholders, providing workshops and supporting business development. If you’re flexible and ready to adapt to a constantly changing environment, there’s no better place to develop your skills. Since you’ll be working directly with clients, some travel will be required.  Skills and attributes for success  Analytical and problem-solving skills combined with experience in leveraging data analytics to drive insights and business decisions.  Analyze client’s business and supply chain requirements Develop supply chain optimization models and statistical analysis using packaged as well as custom optimization software tools (e.g. LLamasoft Supply Chain Guru, LLamasoft Transportation Guru, SAS, R, Python, GAMS)  Analyze and interpret optimization results and derive insights  Communicate technical insight from analytics and modeling to senior executives in a business-oriented and pragmatic way  Provide critical thinking and subject-matter expertise to quantitative and qualitative aspects of client engagements Strong attention to details and ability to multi-task. A strong work ethic. A willingness to travel to meet client needs; travel is estimated at 20%. ","RequirementsTo qualify for the role you must have  BS in Engineering or Computer Sciences 3- 7 years of working experience in consulting, analytics software-as-a-service or technology industry. Strong experience in solving supply chain planning and design problems using quantitative approaches Working knowledge of commercial network design tools such LLamasoft SCG, IBM LNP or similar  Advanced data analysis and processing skills in MS Access, Excel, and SQL Familiarity with custom optimization engines such as GAMS, LINDO, CPLEX Working knowledge on a statistical package such as SAS, SPSS, R or Python  Working knowledge of visualization tools like Tableau, QlikView or any other BI solution. Strong understanding of supply chain design levers and metrics Understanding of supply chain planning at strategic, tactical and operational level  Fundamental understanding of science behind optimization Articulate, with excellent oral and written communication skills. Adaptable, able to interact and build strong relationships with people from a diverse range of backgrounds. Intellectually rigorous, with strong analytical skills and a passion for data. Sound logical reasoning and deep thinking ability. Ability to work accurately to a high level of detail.  Ideally, you’ll also have  MS in Operations Research, Industrial Engineering, Decision Sciences, Engineering or Computer Sciences (preferred) Supply Chain certifications such as CSCP / CPIM are a plus  We offer a competitive compensation package where you’ll be rewarded based on your performance and recognized for the value you bring to our business. In addition, our Total Rewards package includes medical and dental coverage, and a range of programs and benefits designed to support your physical, financial and social wellbeing. Plus, we offer:    What working at EY offers We’re interested in flexible professionals with excellent problem-solving skills and the ability to prioritise shifting workloads in a rapidly changing industry. You’ll also need the confidence to give professional advice and guidance to colleagues and clients from a diverse range of cultures, often with limited information – both verbally and in writing. If you’re a fast learner, with strong influencing skills and a genuine passion for information system security, this role is for you.   What we look for  Support and coaching from some of the most engaging colleagues around. Opportunities to develop new skills and progress your career. The freedom and flexibility to handle your role in a way that’s right for you.    About us   EY is a global professional services organisation providing advisory, assurance, tax and transaction services. We are committed to doing our part in building a better working world for our people, our clients and our communities. And we are united by our shared values and a dedication to delivering exceptional client service.   Want to get to know us better?  Visit www.ey.com/SG/careers  Become a fan on Facebook: http://www.facebook.com/EYSGcareers  Connect with us on Linked In: http://bit.ly/EYLinked_Careers  Watch us on YouTube: http://www.youtube.com/ernstandyoungglobal    We regret that only shortlisted candidates will be notified.  © 2017 Ernst & Young Advisory Pte. Ltd. All Rights Reserved."
/job/alteryx-developer-addstones-sas-58be5511f6a66dd31482804c0fe3e01b,"GFI Group is an international business and technology solutions provider, currently employing about 18,000 people Worldwide. GFI provides its clients with long-lasting innovative solutions to leverage performance from their information systems. We design and run industrial platforms tailored to the economic and human considerations of our clients.  • Management Consulting | Digital Transformation | Innovation • Operating over 20 countries, • 2017 revenue of over 1,2 billion USD,  • 48 years of existence. In order to support our forthcoming businesses and technological challenges, we seek innovative and agile people sharing our mind set. We are now looking for an Alteryx Developer to join our team in Singapore.   Role and responsibilities:   Working on Receive Guarantee Module(RGM) - Initialization  focuses on Initialization (prerequisite setup) for rollout of RGM in APAC which will be golden source of received guarantees. The Alteryx Developer will: ·         Develop banking, analytic and reporting projects using Alteryx and other tools. ·         Effectively translate banking and technology issues into business requirements. ·         Ensure that sponsors, stakeholders and project teams are kept apprised of updates, issues, and opportunities for project improvement. ·         Integrate data through workflows that span across multiple Banking and offline systems as well as business processes. ·         Consolidate  all data sources (oracle, sql server, flat files) into excel files. ·         Perform end user education and training.","Requirements·         Experience in the following disciplines is required:  Oracle, data warehousing architecture and data modeling. ·         5 years + of experience with the Alteryx ·         Strong verbal and written communication skills are required. ·         Must be able to communicate with business users in non-technical terms. ·         Analytical approach with a strong ability to uncover and resolve problems. ·         Ability to deliver innovative approaches and solutions.  "
/job/dry-bulk-shipping-data-analyst-ihs-global-947aa61130f1897d106d97a2e481e8d3," Perform tasks and responsibilities as assigned by Manager or Team Lead based on priorities for team in order to meet/exceed requirements.  Meet completion dates and provide input to manager regarding progress. Execute cyclical analysis jobs following existing methodology.  Provide input into enhancement and optimization opportunities. Responsible for a variety of Maritime data extraction, manipulation and analysis tasks Support new business development by performing ad hoc data tasks Conduct original research and data mining to identify interesting, potentially marketable, findings in our data. Document research processes to establish internal standards. Work with Sales teams on analysis of reports and how to communicate appropriate  information to the customer  Relationships/Contacts  Works closely with Principal Analyst in Singapore, plus other analysts around the world, Data Analytics team and Product Management teams. ",RequirementsMinimum Qualifications  Bachelor’s degree with 1 to 3 years experience in the shipping industry Highly skilled in Excel and PowerPoint KNowledge of SQL preferred Ability to prioritize tasks and coordinate with others. Must have the ability to interpret and analyze past reports and what should be included with the new data. Professional communication and presentation skills . Demonstrated knowledge of statistics and an analytical aptitude. 
/job/data-analyst-gumi-asia-93d05ca8e6782363ae323c467d94b1b2," Perform evaluations and problem investigation for Marketing Data Work within the Business Innovations department to identify data related problems and provide solutions Conduct research and collect data which will help in continual product development that meet department requirements Ensure high quality data are collected and integrity of the data Process data to develop reports specifically required by the department Analyse information using various statistical methods, trying to see patterns in data Create reports and presentations ","Requirements Minimum Diploma/ Degree in Statistics/Computer Science Minimum 2 year's experience in Data Management, Consolidation and Analysis Preferred High proficiency in Microsoft Excel is required Previous experiences with R and MySQL will be highly valued. Possess excellent problem solving, presentation, organizational and project management Good communication skill and interpersonal skill "
/job/senior-data-analyst-grabtaxi-holdings-7e08b7a5b79f217e6cac17a953187bad,"Get to know the Role: To design, set up, and maintain series of automated reports and dashboards (SQL and VBA experience applies) for the marketing team (both local and regional) to measure campaign performance and plan marketing budgets. Working closely with various teams within Grab (Marketing, Data, Engineering etc.) to understand data requirements, identify and track key metrics, and provide data-driven insights that are tailored and relevant to marketing evolving needs.  The day-to-day activities:   Understand business requirements and work objectives in order to analyse relevant customer data sets and propose actionable recommendations that would support decision-making and marketing campaign planning process.   Support a broad range of marketing analytics projects related to improving marketing channels effectiveness, customer segmentation, campaign optimization, etc.   Develop reporting, toolkits, and dashboards for marketing teams to optimize campaign performance, across digital and offline channels   Providing support and training marketing team on BI tools and methodologies to other marketing data analysts   Shape the development of Grab’s Marketing BI infrastructure including Data Warehousing, reporting and analytics platforms  ","RequirementsThe must haves:  Bachelors degree in Statistics, Analytics, Economics, Mathematics, Engineering or other quantitative subjects are required.  Knowledge of analytical tools, including database querying (SQL), Excel (VBA, Pivot), Tableau. R/Python and SAS, etc – preferred.   Strong analytical experience and business acumen, preferably in e-commerce or internet industry.   Fundamental understanding of internet advertising technologies (cookies, DSP, SSP, RTB) and the marketing channel attribution model.   Ability to work with complex data sets, and combine data from multiple sources into a single dashboard/reporting system.   Fast learner; ability to acquire new technical skills as needed.   Versatile, self-driven, detail-oriented.   Good communication skills.   Full professional working proficiency in the English language is required.   Programming skills such as Python will be an advantage.   We use technologies like Holistics and Tableau. Any background in these or similar technologies is definitely a plus.  "
/job/informatica-developer-itcan-49a177c846157e29852dac5925ef5e6c," Design and develop solutions for Strategic DAL components Review requirements, prepare/contribute to design decisions & testing strategy Interface with architects, PM Act as a SME for Strategic  ETL/Oracle components Supporting functional testing as well as support Strong technical skills/experience within the CFO domain  ","Requirements Diploma or Degree with 3 years of experience in Informatica Development. Expertise is in Data Warehousing, ETL (Extract/Transform/Load), Data Analysis, Data Conversion/Transformation, Enterprise Data Warehouse Maintenance and Support Design, Develop and Test ETL Mappings, Mapplets, Workflows, Worklets using Informatica Powercenter 9.x & above Experience in SQL Server Database Exposure to Data Modelling techniques. Create UNIX shell scripts for ETL purpose. Understanding to concepts of SDLC methodologies like Waterfall & Agile is desirable. Banking knowledge is desirable. Work in a fast paced environment, under minimal supervision to perform as an Inpidual Contributor. Communicate clearly and concisely verbally and in writing. "
/job/research-data-analyst-ml-consulting-87359afcc475605215ad0e8bfe164e97, Perform the data processing and post-survey data analysis Handle statistical requests using statistical tools   ,"Requirements Degree in Economics/Statistics or equivalent Good knowledge of quantitative research methodologies Good knowledge in using statistical software such as SPSS, STATA, R, Eview Self-starter with strong numerical and analytical skills  Interested candidates, please send your updated resumes to itapp@mlpc.com.sg and ros@mlpc.com.sg "
/job/data-entry-analyst-legal-team-allegis-global-solutions-2a55f081cb4ce45d1e830c1594815108,"Allegis Global Solutions is the exclusive Contingent HR services provider for one of the world’s leading banks. At Allegis Global Solutions we’re proud to be the leader in global talent solutions. We draw upon decades of industry expertise to develop innovative tools, products, processes and strategies focused on outcome. Moreover, we’re incredibly proud to have built a culture that empowers our people to make their mark while making deep connections that will last a lifetime. With our passion and culture for talent, we are truly transforming the way the World acquires talent. Our Client is one of the world's most international banks with over 1,100 branches, offices and outlets in 67 countries. They operate in some of the world's most dynamic markets and have been for over 150 years. More than 90 per cent of their income and profits are derived from Asia, Africa and the Middle East. Their brand promise, Here for good, underlines their distinctive approach.   Key Candidate Responsibilities  Perform data entry of Master Agreement details (e.g. Credit Support Annex, ISDA Master Agreement) into the bank's in-house systems – iCDMS, TCDS. Ensure accuracy of data. Provide ad-hoc support to the country/regional teams on administrative tasks. ","Requirements Ideally have minimum 1 year’s proven experience in Operations. Possess strong communication and inter-personal relationship skills. Fluent in English (Spoken and Written). Excellent PC skills: MS Word, MS Excel, MS Access. Extremely high attention to detail. Desire to learn and grow within the role. Ability to meet tight deadlines. Able to work autonomously, but also be a good team player.  High analytical and problem solving abilities."
/job/senior-data-analyst-streetsine-singapore-3baa45f938b74a6660a619998e4a9852,"We are currently looking for a Senior Data Analyst/Scientist to be part of our Business Intelligence (B.I.) team. Reporting to the Chief Data Officer (CDO), you will work closely with internal teams to:  Initiate studies and implement algorithms and methods to take business advantage of new information and data. Build, test and deploy machine learning models to cater to the market intelligence tools offered by the company Refine the performance and accuracy of existing data models based on feedback Assist in general database administration  Expected Competencies: A fast, adaptive yet meticulous professional having the following qualities: 1. Business Acumen and Communication Skills The candidate has demonstrated experience working with the relevant stakeholders to leverage data science to identify new business opportunities or remedy process inefficiencies. 2. Programming Skills The candidate should have prior experience translating proposed technical solutions using computational methods and data science, while at the same time understanding their respective strengths/weaknesses and potential business trade-offs. 3. Technical Competency The candidate writes code according to best practices while meeting security standards and is able to translate complex datasets into strategic insights.","RequirementsRequirements:  Minimum 2 years of relevant work experience with a degree in any quantitative or computational discipline Proficiency in SQL and Python Excellent communication and interpersonal skills An additional advantage for candidates with proven skills in data visualization, machine learning, or image analytics An additional advantage for candidates with full project life cycle exposure i.e. data collection, aggregation, analysis, visualization, productionization, and monitoring of data Science solutions "
/job/data-analyst-%E2%80%93-12-month-contract-%E2%80%93-singapore-allegis-group-singapore-550ad6d9f9671de6d55908aac107e3c4,"The Business Analyst position will be part of a team that provides the Platforms and Ecosystem Marketing organization with deep data insights and decision support tools. You will work closely with the Global Marketing Analytics team and key stakeholders on data analytics that inform campaign success and provide thought leadership and learnings to refine operations using data insights. The ideal candidate has strong experience working with all different stages of data analysis: data querying, building reporting pipelines, running statistical analysis, building dashboards, and presenting insights. You should be a self-starter that can ""crunch the numbers"", identify trends that connect to the big picture, partner with senior stakeholders, and communicate effectively with senior executives to drive significant strategic initiatives.","RequirementsMandatory:  BA/BS degree in Business/Data Analytics, related field or equivalent practical experience with 3 years work experience In-depth experience analyzing data and creating reports with strong spreadsheet, database query experience (e.g. SQL), statistical, quantitative modeling and forecasting skills.  Desired:  Genuine excitement and passion for developing and analyzing large, complex data sets and converting them into insights that drive business decisions at all levels of the organization. Ability to understand the implications of data analysis and build a strategic story from this data Strong communication and presentation skills to deliver findings of analysis. Demonstrable organizational and project management skills, with the ability to manage multiple projects with competing priorities. "
/job/junior-data-analyst-observational-pragmatic-research-institute-071461b4082e679a0d441248ab242c08,"Observational and Pragmatic Research Institute (OPRI) is a unique academic research institution, working with both the pharmaceutical and academic industry, with the overarching goal to improve the lives of patients through conducting vital global real-world research. OPRI is part of a global network of international companies, with partner companies located in the United Kingdom and Australia. OPRI has been leading the paradigm shift in real-world evidence for the past 12 years, by delivering pragmatic clinical trials, disease registries and database research. We are currently seeking a hard-working and motivated Data Analyst to join our international team. You would be involved in supporting the team developing the first global severe asthma registry ever developed, joining a young and enthusiastic team in supporting a globally-renowned project. Key responsibilities of the role will be to:  Provide support on database querying, population and reporting, using structured query language (SQL). Assist in generate data releases following study protocol requirements and service reports (Tableau). Advise internal team members and external clients on study database(s) content. Engage in building and maintaining data dictionaries and system technical documentation. Undertake quality checks to assure high standards of data and code. Contribute to data analyses as required for research projects. Maintain compliance with information governance and company policies. ","RequirementsQualifications BSc or equivalent qualification with strong technical or scientific component (e.g. Computer Science, Maths, Statistics). Experience  Familiarity with structured query language (SQL) and database processing (ETL, stored procedures, large datasets) Strong ability for data analysis, interpretation and visualization. Experience in at least one data or statistical package (SAS, R, or Stata) Some experience in data dictionaries and advanced documentation systems.  Key skills: data manipulation (SAS, R, or Stata), relational databases (esp. my SQL and SQL Server), clinical or medical research, proactive approach. Desirable: statistical background (models, correlations, hypothesis), general purpose programming languages (e.g. Python), database administration tools (migration, DB administration), experience of working with clinical databases"
/job/junior-data-analyst-observational-pragmatic-research-institute-7a024ac411a5a189f7b9ec59286772d8,"Observational and Pragmatic Research Institute (OPRI) is a unique academic research institution, working with both the pharmaceutical and academic industry, with the overarching goal to improve the lives of patients through conducting vital global real-world research. OPRI is part of a global network of international companies, with partner companies located in the United Kingdom and Australia. OPRI has been leading the paradigm shift in real-world evidence for the past 12 years, by delivering pragmatic clinical trials, disease registries and database research. We are currently seeking a hard-working and motivated Data Analyst to join our international team. You would be involved in supporting the team developing the first global severe asthma registry ever developed, joining a young and enthusiastic team in supporting a globally-renowned project. Key responsibilities of the role will be to:  Provide support on database querying, population and reporting, using structured query language (SQL). Assist in generate data releases following study protocol requirements and service reports (Tableau). Advise internal team members and external clients on study database(s) content. Engage in building and maintaining data dictionaries and system technical documentation. Undertake quality checks to assure high standards of data and code. Contribute to data analyses as required for research projects. Maintain compliance with information governance and company policies. ","RequirementsQualifications BSc or equivalent qualification with strong technical or scientific component (e.g. Computer Science, Maths, Statistics). Experience  Familiarity with structured query language (SQL) and database processing (ETL, stored procedures, large datasets) Strong ability for data analysis, interpretation and visualization. Experience in at least one data or statistical package (SAS, R, or Stata) Some experience in data dictionaries and advanced documentation systems.  Key skills: data manipulation (SAS, R, or Stata), relational databases (esp. my SQL and SQL Server), clinical or medical research, proactive approach. Desirable: statistical background (models, correlations, hypothesis), general purpose programming languages (e.g. Python), database administration tools (migration, DB administration), experience of working with clinical databases"
/job/senior-risk-consultant-linkedin-singapore-ed97623737bc25d7ea5b863a97cb9fec,"LinkedIn was built to help professionals achieve more in their careers, and every day millions of people use our products to make connections, discover opportunities and gain insights. Our global reach means we get to make a direct impact on the world’s workforce in ways no other company can. We’re much more than a digital resume – we transform lives through innovative products and technology. Searching for your dream job? At LinkedIn, we strive to help our employees find passion and purpose. Join us in changing the way the world works. We are looking for a Senior Trust & Safety Content Analyst who will be responsible for processing and investigating terms of service, fraudulent and spam related violations. Report and reconciliation of disputes as well as minimizing risk and loss is essential in this position. The position is expected to complete inquiries in a timely and precise manner. Serving our more than 500 million members worldwide, the Trust & Safety team is the group tasked with keeping LinkedIn a professional and safe platform. Our team members are proactive, motivated, organized, and possess a global perspective - and able to work well in a fast paced, team-oriented environment. The analysts are directly responsible for making the internet safer, protecting free speech and defending our brand. They will have direct exposure to engineering, data science, policy and data analyst stakeholders and will need to help define and implement operational solutions to emerging threats. In addition, they will perform other key Analyst functions including driving improvements in the team's processes, technology and tools. Responsibilities:  Operations 	 Effectively identify problems and issues by performing relevant research using appropriate tools Resolve all issues in a timely manner related to spam, account takeover and terms of service violations Manage internal escalations received for fraud and all other disputes with written correspondence   Project Management 	 Work on Trust and Safety projects from conception to completion Follow project timeline and report on milestones Ensure effective communications during the project Identify gaps and issues and communicate timely with the management   Insights 	 Provide operational feedback to management regarding necessary changes, volume spikes, and member sentiment Provide tooling and product insights and propose product fixes and changes   Analysis 	 Analyze identity theft and misuse reports, identify trends that need to be addressed and communicate findings to the appropriate stakeholders Work closely with Analytics and perform deep dives into region/ global trends   Global Liaison 	 Act as a liaison between Global Risk Management team and local teams Act as contributing liaison for tooling and development with product team in different regions   ","RequirementsBasic Qualifications:  5+ years of experience with content policy or anti-abuse operations  Preferred Qualifications:  Strong written and spoken communications skills in Mandarin Chinese Knowledge of the China market and its legal/political environment Knowledge of identity theft and industry risk trends. Demonstrated capacity for critical thinking and analysis with strong attention to detail Familiarity with Internet policy and regulatory environments. Passion for keeping our users safe while protecting free speech Well-developed sense of urgency and follow through. Excellent project manager and self-starter, with the ability to work independently and on multiple initiatives at the same time. Competency in Excel and SQL skills a plus Experience using Microsoft Office products including: Outlook, and PowerPoint with proficiency in Excel and Word. "
/job/financial-data-analyst-%E2%80%93-commodities-trading-multinational-bluechip-platforms-asia-b9b5afecca9c5dd0c62a4b7c94ba08ef,"• High visibility   • Python, R+, SQL   • Complex and dynamic business model   This is a leading commodities trading multination with diversified businesses around the world. An opportunity has arisen for a Financial Data Analyst to join the structured trade finance team. This will be an individual contributor position.    Job Responsibilities Reporting directly to the Head of Finance, the Analyst will play a key business partnering role and provide timely and accurate financial, risk and management reporting information. Development of performance metrics and tools to improve decision making is an essential part of the job. As the Group is actively involved in structuring, trade finance and paper trading, he/ she will also be focused on analyzing risk portfolio trends of the Group’s balance sheet. Other responsibilities will also include responding to requests from management to undertake data analysis projects for purpose of identifying actions to improve profitability and efficiency.   Requirements/Qualifications The successful candidate will be a degree holder in an economics / mathematics / statistics discipline, with at least 3 years of experience in a risk management and data analytics function.  You will be a logical thinker who delivers under high pressure. You will also be a strong team player who is detailed, highly analytical and have excellent interpersonal and communication skills. You perform well in a complex and non-structured environment. ",Requirements**Apply here** https://www.bluechipcareers-asia.com/jobDetails/4560/financial-data-analyst-commodities-trading-multinational For more Banking and Finance Jobs visit us at: https://www.bluechipcareers-asia.com
/job/senior-level-data-analyst-traveloka-services-32f09a915860f3b9648f4393ab03b741,"Data Analyst at Traveloka is at the forefront of using data for building value by discovering insights about businesses, product conversions, market behaviors, and others. You will be defining, collecting, processing, analyzing data across divisions and work with teams for driving the company, its products, and its operation forward through data.  ","RequirementsWe are looking for someone with:  Passion in data analysis, mathematics, statistics, modeling, or pattern recognition Strong business acumen, able to translate data to business insights Knowledge in data structures and algorithms for processing large data 8+ years of experience in data modeling Strong analytical, mathematical, and communication skills Critical thinking and strong attention to details Bachelor's degree in technical major is preferred "
/job/mid-senior-level-data-analyst-traveloka-services-e724cfc928479c576d5b2a469a146066,"Data Analyst at Traveloka is at the forefront of using data for building value by discovering insights about businesses, product conversions, market behaviors, and others. You will be defining, collecting, processing, analyzing data across divisions and work with teams for driving the company, its products, and its operation forward through data.  ","RequirementsWe are looking for someone with:  Passion in data analysis, mathematics, statistics, modeling, or pattern recognition Strong business acumen, able to translate data to business insights Knowledge in data structures and algorithms for processing large data 6+ years of experience in data modeling Strong analytical, mathematical, and communication skills Critical thinking and strong attention to details Bachelor's degree in technical major is preferred "
/job/mid-level-data-analyst-traveloka-services-d68e6cca2bd03f98ec3c5bcd51b0b376,"Data Analyst at Traveloka is at the forefront of using data for building value by discovering insights about businesses, product conversions, market behaviors, and others. You will be defining, collecting, processing, analyzing data across divisions and work with teams for driving the company, its products, and its operation forward through data.  ","RequirementsWe are looking for someone with:  Passion in data analysis, mathematics, statistics, modeling, or pattern recognition Strong business acumen, able to translate data to business insights Knowledge in data structures and algorithms for processing large data 3+ years of experience in data modeling Strong analytical, mathematical, and communication skills Critical thinking and strong attention to details Bachelor's degree in technical major is preferred 	  "
/job/junior-mid-level-data-analyst-traveloka-services-3c75a2eb4e25e7d053d53de15f926719,"Data Analyst at Traveloka is at the forefront of using data for building value by discovering insights about businesses, product conversions, market behaviors, and others. You will be defining, collecting, processing, analyzing data across divisions and work with teams for driving the company, its products, and its operation forward through data.  ","RequirementsWe are looking for someone with:  Passion in data analysis, mathematics, statistics, modeling, or pattern recognition Strong business acumen, able to translate data to business insights Knowledge in data structures and algorithms for processing large data Fresh graduate with internship experience - 3+ years of experience in data modeling Strong analytical, mathematical, and communication skills Critical thinking and strong attention to details Bachelor's degree in technical major is preferred 	  "
/job/data-science-analyst-ent-vision-043917ee6e36e1118a98ed45f92f10e6,"• Cleanse, prepare and perform Exploratory Data Analysis on enterprise and IOT data • Perform advanced analytics and statistical modelling on structured and unstructured data • Feature engineering, build ML data models and Heuristic algorithms for prescriptive analytics • Integrate ML data models and Heuristic algorithms into web and server application • Translate business requirements to reporting dashboard and analytics","Requirements• Degree in Mathematics, Statistics or a related discipline • 3 year working experience in statistical modelling, data visualisation and machine learning • Completed several work-related ML projects using R, Python, Scikit and Microsoft .Net • Extensive experience in MS SQL database design, queries, views and stored procedures • Highly proficient in data visualisation tools and good analytical skills • Experience with REST-Based Web Service using JSON, XML • Good communications skills, project planning and time management are pre-requisites"
/job/assistant-manager-manager-data-technology-resorts-world-sentosa-47580777bc5c26f358b51af21afd9f33," Gather, analyze and assess business requirements and processes, and evaluate the viability and feasibility of implementation Conduct system functionality testing and work with users on user acceptance testing Manage project issues and risks to ensure deliverables are on track Assist in developing acceptance testing and user training plans to ensure the quality of product and smooth implementation Propose alternative solutions and technologies to improve and bring about high quality system solutions Assess impact of business requirements on integration of all relevant systems and work with relevant teams on appropriate integration solution Design and develop systems which comply with the relevant IT security policies and standards Perform security testing and reviews at various phases of system development ","Requirements Degree in Computer Science, Engineering, Information Systems or related disciplines At least 5 years of working experience in delivering and supporting IT applications Strong analytical, problem solving skills and attention to detail Strong written and verbal communication with emphasis in technical writing skills "
/job/data-analyst-07bea28e23a890681f743e2c00e01f2d,"Company Description This company, with a global workforce of 100,000, is a leading green brand and world leader for corporate action on climate change.     The company has an annual turnover of US$25bn, arriving from its innovative healthcare technology, consumer lifestyle and lighting solutions.    Duties and Responsibilities   Reporting to the manager, you will take responsibility for managing our master data set, developing reports, and troubleshooting data issues. To do well in this role you need a very fine eye for detail, experience as a data analyst, and deep understanding of the popular data analysis tools and databases. The responsibilities are as follows -     Design and develop data models to aid reporting and forecasting   Helping develop new reports, enhance existing reports and analysis.   Managing master data, including creation, updates, and deletion.   Managing security configuration, defining users and user roles.   Processing confidential data and information according to guidelines.   Managing and designing the reporting environment, including data sources, security, and metadata.   Supporting the data warehouse in identifying and revising reporting requirements.   Supporting initiatives for data integrity and normalization.   Assessing tests and implementing new or upgraded software and assisting with strategic decisions on new systems.   Generating reports from single or multiple systems.   Troubleshooting the reporting database environment and reports.   Evaluating changes and updates to source production systems.   Training end users on new reports and dashboards, including documenting work instruction and user guide.   Providing technical expertise on data storage structures, data mining, and data cleansing.    ","RequirementsRequirements:     Bachelor’s degree or diploma from an accredited university or college in computer science with 2-4 years of experience as data analyst.   Ability to work with stakeholders to assess potential risks.   Ability to analyze existing tools and databases and provide software solution recommendations.   High-level experience in methodologies and processes for managing large scale databases.   Start-up mentality   High-level written and verbal communication skills.   Technical platforms - Required – Excellent knowledge in Excel and Excel datamodel & Preferred – experience in Power BI or Qlikview / Qliksense         On top of a competitive base salary, the company offers excellent career and training opportunity, attractive benefits and bonus schemes.   Interested parties, please click on APPLY button.   EA License: 94C3609 / R1655737  "
/job/people-data-centre-social-analyst-unilever-asia-137ed378201544f9a679d72495e0df92,"The PDC Insights Analyst will be part of the Global Beauty & Personal Care PDC team looking after brands including Dove, Lux or Lifebuoy. They will be responsible for analysing a wide range of data to help inform marketing, brand and business strategies. They will ensure that internal briefs are translated into analytical projects and will be responsible for ensuring the analysis is relevant for the specific brand and market. They will be comfortable using a wide range of analytical tools to help with the analysis and be familiar with both digital data such as social and search right through to traditional business data such as penetration and brand equity. The individual will be responsible for providing quantitative and qualitative analysis and insight on projects, whilst working alongside specialist analysts where required. As such the person needs to be comfortable working on their own analytics projects and also be able to work with specialist experts on larger, more complex briefs.   Key Accountabilities:    Primary Responsibilities  Work closely with the PDC Insights Manager to translate internal briefs into analytical projects (to include refining the initial brief and asking the ‘right questions’, working through potential hypotheses and storyboarding the output) Provide qualitative and quantitative analysis and insight to inform business strategy, marketing and brand strategies, digital marketing content and strategy, communications and new product development Conduct analysis using in-house analytics tools, and be comfortable analysing a range of social and business data Query building & data extraction from digital data tools (e.g. Brandwatch, Clarabridge, etc.) Building and maintaining dashboards for internal customers using internal visualisation tools Synthesising data and analysis into impactful, action-orientated reports for the Beauty & Personal Care teams Able to communicate the key findings and insight to senior stakeholders and peers both conversationally and in formal presentation style Monitor progress of deliverables and actively work with other analysts where required on complex briefs   Secondary Responsibilities  Perform translations as required Identify candidates for new services or ways-of-working improvements and feed this into a global centre of excellence to drive service improvement   ","RequirementsSkills/ Experience/ Qualifications:  Essentials   4 - 6 years Experience in an analytical role and providing insight and recommendation based on analysis Experience in using analytical tools, including social analytics / NLP tools and website analytics tools Experience in “storytelling” in a corporate context, and crafting clear, compelling messaging Passion for the digital world and its implications for business Candidate with proficiency (Spoken and written) in Indonesian Bahasa       Desirable  Eager to grow within Unilever and move around the business (career path likely to be within wider analytical pool) Appetite to learn the ‘art of the possible’ and then capitalise on this in next role Self-starter able to ‘muck in’ as required and pick up ways of working quickly Likely recent graduate or higher apprentice Experience of digital data tools (social listening tools, channel analytics, etc.)   "
/job/analyst-data-loss-prevention-mufg-bank-singapore-branch-0e549ecb0d929f89a33b10f68bbb42ce,"MUFG Bank, Ltd, a member of Mitsubishi UFJ Financial Group Inc (MUFG), is Japan’s premier bank, with a global network spanning more than 40 countries. Outside of Japan, MUFG offers an extensive scope of commercial and investment banking products and services to businesses, governments and individuals worldwide. In the Asia and Oceania region, MUFG has presence in 13 key markets with 32 offices and closed to 4,500 employees serving largely corporate and institutional clients. Singapore has served as the regional headquarters for South Asia, South-east Asia and the Oceania region since July 2013. While the regional headquarters for the East Asia region remains in Japan. MUFG is one of the world’s leading financial groups with total assets of JPY 258.1 trillion by the end of March 2014. MUFG’s services include commercial banking, trust banking, securities, credit cards, consumer finance, asset management, and leasing. The Group’s operating companies include MUFG, Mitsubishi UFJ Trust and Banking Corporation (Japan’s leading trust bank), and Mitsubishi UFJ Securities Holdings Co., Ltd., one of Japan’s largest securities firms. MUFG’s shares are traded on the Tokyo, Nagoya, and New York (NYSE: MTU) stock exchanges respectively. Job responsibilities include:  Support to execute DLP strategy and initiatives according to the DLP roadmap including regional rollout planning. Work with relevant stakeholders to continuously implement DLP measures, build DLP awareness and provide advisory. Monitoring of DLP system (Email, Endpoint, Network) to ensure:                Incidents are investigated and escalated in accordance to the DLP Incident response and handling procedures, All escalated incidents are tracked and followed up from beginning to closure, False positive incidents are effectively and accurately filtered/ fine tune, Assist to handle Change Request for DLP Policy.   Support to review DLP Policy, maintain and ensure DLP standard operating policies and procedures are kept updated. Support management reporting of DLP incidents and statistics in the DLP Change Control Committee (CCC). Coordinate the DLP audit work; respond to questions or reporting requirements from local authorities as required. Maintain good working knowledge of industry trends, products, relevant laws and regulation. Manage the Information Security Awareness training for DLP related items. ",RequirementsJob requirements include:  Experience with administration and operation of Data Loss Prevention tools. Candidates who are proficient or have experience in Websense DLP technology will be preferred Candidates who had experience in development and fine tuning of DLP policy/ rules are preferred Good Analytical skills Knowledge of banking processes preferred Team player with good communication and interpersonal skills and be able to collaborate and interact effectively with Business Units Self-starter who is able to work independently Possession of professional certifications / qualifications such as CRISC or ITIL will be advantageous  Recruiter Name: Natalie Tan EA License No: 12C5536 EA Registration No: R1106672   We regret to inform that only shortlisted applicants will be notified.
/job/data-quality-specialist-nes-global-0f1a573045839cd52825d883fbd10fa5, LCI Coordination including final documentation (DFO) Working procedure and method development Information logistics Coordination users and IT/IS department System training and coordination Data quality surveillance Database design and administration System specification and design Programming ,Requirements NORSOK project experience More than 25 years of relevant experience in Oil & Gas industry 
/job/datawarehouse-consultant-infogain-solutions-e91fa08601456cf678b3aec4c5fd479d," Provide application support to various business users.  Attend to business queries and business requests promptly. Follow through the business requests to a proper closure Work on timely resolution for reported incidents so as to meet service level targets. Incidents include failures & queries reported by business users and technical staff; event alerts automatically detected and reported by event monitoring tool Perform root cause analysis to identify permanent solution so as to prevent recurring incidents and to minimize the impact of incidents that cannot be prevented Ensure all incidents and problems are proactively managed – Prioritizing numerous issues of varying severity and escalate issues as appropriate to necessary teams and management Collaborate with the development team in identifying resolutions and transitioning of releases into production environment Participate in  BCM activities or infrastructure related upgrade Responsible of capacity management.  To monitor &analyze current performance and capacity data and forecast the capacity required by the applications ahead Aside from day-to-day support duties, there will be requirements to undertake other responsibilities such as management reporting & other centrally driven project initiatives as needed ","Requirements Degree in computer science/engineering or related disciplines. Min 5 years of experience in application development and support environment in business intelligence Min 2 years experiences in Big Data using Cloudera (CDH 5.8 or above), Hive, Impala, HDFS, YARN, pig ,Sqoop, Oozie, Hbase, kafka, Map Reduce/Spark. Excellent communication, interpersonal and analytical skills Excellent & proven Incident/Problem Management and organization skills a must Individual must have working experience in ETL, Data warehouse, Big Data and various business intelligence tools on Unix/Windows platforms. Mandatory Technical skills : Teradata, Informatica, Cloudera Hadoop, Oracle, Qliksense, Unix/Linux, AS400, Control-M and Shell scripting Other skills for ETL, Datawarehouse, BI, and Big Data skills are good advantages "
/job/data-analyst-smartkarma-innovations-f507df91f8aaa04f9949d5837d0fe60f,"Important: Please complete the Smartkarma Data Analyst Job Application Form: https://goo.gl/forms/6UdYhA9RuOgkq7TJ2  Smartkarma is a Sequoia-backed global fintech headquartered out of Singapore with global offices and a top-notch clientbase. This is your chance to join a world class team, and take on our challenge to  reinvent the world of investment research.   About the Role We are looking for someone who can prove themselves on a full-time internship for 3 months, and then scale into a full-time role.  You will work closely with the CEO, as well as Senior members of the Technology, Sales and Finance teams and be involved in:   Coalescing data from various internal and external sources    Building real-time dashboards   Drawing insights from data   Crafting reports and presentations  ","Requirements Demonstrable ability and passion to work with data  Writing SQL queries   Python or similar language   Javascript or similar scripting language   Google Data Studios, Tableau or equivalent visualisation tools   Handling APIs   Interest in financial services and technology   Entrepreneurial spirit & an eagerness to work with the best, and be the best     Overall   Detail-oriented, with strong organizational skills    Strong technical grounding   Ability to communicate concisely and clearly     What You Will Get in Return This is a very exciting role as it allows you the ability to learn from every aspect of a high-growth fintech company and be involved in shaping executive decision making.  Working with a fun-crew, who’re tackling a multi-billion dollar industry head-on.  Infinite leave policy, flexible work hours, and an excellent exposure to both the finance and technology sectors. "
/job/ediscovery-data-collections-analyst-ubs-ag-24b0b5484b4aea0d1575fb30ec50717c,"Are you eager to apply your technical talents and service flair in one of the world's leading eDiscovery organizations? Are you excited about working with multiple stakeholders such as eDiscovery Case Management, eDiscovery Data Processing Services and Technology to provide an efficient and high-quality Data Collections and Preservations service using innovative and defensible eDiscovery Technology solutions of the future? As an eDiscovery Data Collections and Preservations Senior Analyst you will oversee a large portfolio of eDiscovery collection, preservation, and research request for various electronic structured and unstructured stored information (ESI) data types such as electronic communications, voice and relevant data in-line with defined and established processes  • Collaborate with other regional eDiscovery teams to ensure alignment of processes and that deliver a consistent and sustainable catalogue of eDiscovery services  • Deliver flawless service execution in line with the eDTS service model whilst maintaining an eye out for opportunities • Proactively propose and recommend options for the cost-effective delivery of eDiscovery services as they relate to the preservation, collection, and delivery of data for Legal and Compliance matters. • Support Regional and Global service line leads in the development and implementation of initiatives to meet existing and future demands • Proactively communicate with other EDTS Data Collections & Case Managers , and IT Support Teams about the status of requests, IT and service incidents  • Support and lead the development of strategic objectives with respect to people, process and tools  • Maintain documented procedures and assist with the development of process documentation, share best practices and information updates on initiatives led • Act as an eDiscovery Subject Matter Expert and consult on Service Change projects • Oversee a team of Collection Managers and Data Collection SME's, providing them with support and guidance in line with documented Standard Operating Procedures   You will be working in the eDiscovery Technology Services (eDTS) organization in Singapore as a Data Collections and Preservations Senior Analyst. eDiscovery Technology Services is a specialized unit within UBS Group Technology, supporting complex civil litigation, investigations, and regulatory inquiries by collecting, preserving and processing electronically stored information. The Data Collections and Preservations Service Line is responsible for defensible Collection and Preservation of electronically stored information and providing Data Source analysis & retrieval support. You may also apply directly via our career website using below link: https://jobs.ubs.com/TGWebHost/jobdetails.aspx?partnerid=25008&siteid=5012&AReq=181332BR To learn more about UBS and other opportunities, please visit www.ubs.com/careers  ","RequirementsYou have: • IT professional experience in a global environment with a focus on information management, storage management, operational, and resource management • Strong knowledge of eDiscovery practices and the interrelation with other disciplines, including Information Governance, Data Privacy, Data Security, IT, Compliance.  • Experience of any of the following technologies are an advantage – Compliance Now, Exchange 2010, Windows Server Infrastructure, Netbackup or Commvault Simpana backup technologies, NICE / NTR Voice Recording systems • Deep subject matter expertise in eDiscovery, particularly in the areas of data preservation, collection, and processing, and document review  You are: • Analytical, self-motivated, and collaborative • Client focused and service-oriented,  • A strong team player who can effectively multi-task yet maintain a high level of attention to detail"
/job/business-analyst-government-technology-agency-9e6bb89686d7ae65bd6554890fd0ea0d,"BAF (Data Analytics) We are looking for Business Analysts (Data Analytics) who's interested in using data to help the government design solutions that address its policy and business problems, and stay close to the needs of the general public.  The applicant will be responsible for demonstrating how better use of data can help recommend new policies, streamline operations or bring more customised solutions for citizens. He/she should have some training and working experiences on data analytics, and should be comfortable with hands-on data manipulation, data modelling and data visualisation.   What to Expect:  Provide data analytics consulting services to the government agencies, including data analytics planning and strategy – perform data analytics visioning and road-mapping, business case development, implementation planning, organisational planning, budget and risk management planning Work closely with stakeholders to understand their needs/pain points, scope the problem and develop business case on how to turn data into critical information and knowledge that can be used for policy making, streamlining operations or developing solutions for citizens.   Advise stakeholders on the key ICT trends and best practices in data analytics, assess applicability for adoption and recommend solution that best fits stakeholders’ needs Perform data cleaning, pre-processing and feature engineering that facilitate meaningful analysis Work closely with data scientists to mine insights from structured and unstructured data and to resolve complex statistical modelling problems to answer pertinent business questions.  Design dashboards and interactive visualization as tools for data exploration as well as for storytelling.  Present analytics insights to business users and stakeholders Work with stakeholders to ensure smooth deployment and adoption of new solution  How to Succeed:  Degree/Master in any discipline; Diploma graduates with relevant experience will also be considered. Minimum 3 years of relevant working experience Ability to take a broad, strategic perspective as well as drill deep to understand business needs and challenges Understand key concepts, techniques and considerations in Machine learning and Data analytics Training and relevant experience in one or more of the following areas:   Statistical modelling tools such as: R, Python, RapidMiner, Knime, SAS, Matlab or SPSS Data manipulation using scripting languages like Python or using ETL tools Visual analytics technologies like Tableau, Qlikview or D3.js End-to-end analytics architecture, preferably with some working knowledge of big data stack   Excellent communication skills, both oral and written, with ability to pitch ideas and influence stakeholders Strong analytical, conceptualisation and problem solving skills Team player with strong organization and people handling skills Passion for the use of analytics and data to improve public service ",Not Available
/job/data-engineer-intellect-minds-2a8b2d06e28c95bc8d5778e70e6a5b75,"Company Overview Intellect Minds is a Singapore-based company since 2008, specializing in talent acquisition, application development, and training. We serve BIG MNCs and well-known clients in talent acquisition, application development, and training needs for Singapore, Malaysia, Brunei, Vietnam and Thailand. Our client is an establish company a, leader within their industry, is now looking for a Data Engineer to join their esteemed organization. Job Descriptions: Responsibilities • Create and maintain optimal data pipeline architecture. • Assemble large, complex data sets that meet functional / non-functional business requirements. • Build the infrastructure required for optimal extraction, transformation, and loading of data from a wide variety of data sources using SQL, Cassandra, Hadoop and other Big Data Technologies. • Build data pipeline on premise and on Google Cloud Platform. • Build analytics tools that utilize the data pipeline to provide actionable insights into customer acquisition, operational efficiency and other key business performance metrics. • Work with stakeholders including the Product, Data and Design teams to assist with data-related technical issues and support their data infrastructure needs. • Work with data and analytics experts to strive for greater functionality in our data systems.","RequirementsQualifications • Advanced working SQL knowledge and experience working with relational databases, query authoring (SQL) as well as working familiarity with a variety of databases. • Experience building and optimizing ‘big data’ data pipelines, architectures and data sets. • Experience performing root cause analysis on internal and external data and processes to answer specific business questions and identify opportunities for improvement. • Strong analytic skills related to working with unstructured datasets. • Build processes supporting data transformation, data structures, metadata, dependency and workload management. • A successful history of manipulating, processing and extracting value from large disconnected datasets. • Working knowledge of message queuing, stream processing, and highly scalable ‘big data’ data stores. • Experience supporting and working with cross-functional teams in a dynamic environment. • We are looking for a candidate with 5+ years of experience in a Data Engineer role, who has attained a Graduate degree in Computer Science, Statistics, Informatics, Information Systems or another quantitative field. They should also have experience using the following software/tools: • Experience with big data tools: Hadoop, Spark, Kafka, etc. • Experience with Google Cloud Platform esp. Google Pub-Sub, Big Query, Data Proc, Data Flow, Cloud Storage. • Experience with IoT & Time series data. • Experience with relational SQL and NoSQL databases, including Postgres and Cassandra. • Experience with stream-processing systems: Storm, Spark-Streaming, etc. • Experience with object-oriented/object function scripting languages: Python, Java, C++, Scala, etc. All successful candidates can expect a very competitive remuneration package and a comprehensive range of benefits. Interested Candidates please submit your detailed resume online. To your success! The Recruitment Team Intellect Minds Pte Ltd (Singapore)"
/job/high-performance-data-engineer-niometrics-af05e08c9f5a51a65c5213bde728c60f,"WHAT WE DO We invite you to be part of our ambitious, close-knit team creating systems for large customers who need to crunch through Tbps of data in real-time. Our approach is relentless performance-oriented software engineering vs. server sprawl in our customers' datacentres. You will use the latest high-end hardware and continuously devise ways to push the envelope of software performance. We build in-house systems if we must. We had to for indexing 1M 60-column rows/s, for aggregating high throughput event streams over hundreds of combinations of dimensions, and for pattern matching 5M patterns at 100Gb/s per 2RU. We use these to solve real customer problems. You will experiment wildly. For example we implemented network monitoring using a GPU, and we tested 4-socket machines with 2T RAM. Our current favourite platform is a 2-socket system with E5-2699v4 CPUs (88 lcores in total), 4x40Gbps NICs and 1T RAM, which we use to process 160Gbps. You will help us build a successful software platform for the long run. We invest a lot in flexibility, such as with our extensible rule engine and declarative aggregation system that empowers our analysts and helps us minimise the C code we have to write for supporting disparate use-cases. We know the devil is in the details. You will improve performance through better memory allocation systems and better data structures, all while ensuring that they are integrated with Address Sanitizer and fully tested using unit tests and end-to-end regression tests. We work end-to-end. You will implement data engineering solutions that are both efficient and secure for handling events from 500 million users, and to extract insight without leaking individual information. We want to show off. To attract the best programmers we plan to showcase our technology. You can be part of our effort to open-source interesting pieces of our technology stack.   YOUR ROLE AS HIGH-PERFORMANCE DATA ENGINEER As a High-Performance Data Engineer, you will create and maintain tools, mainly in C, for crunching large amounts of data in files or streams. You will have to think both big, in terms of overall architecture, and small, in terms of low-level optimisations, to deliver solutions that are reusable, and match the performance of the best hardware. Every capability you add directly translates to new offerings made possible. Every percent of performance improvement directly translates to large cost savings. At the same time, the correctness and reliability of your work will be the cornerstone to our customers’ trust.",RequirementsWHAT WE VALUE  Bachelor’s or Higher Degree in Computer Science or equivalent Software craftsmanship Attention to reliability and successful delivery Experience with large C code bases and high-performance C programming Familiarity with shared memory data structures and parallel algorithms Proficiency with Linux system & development tools 
/job/data-engineer-woodpecker-asia-tech-3a652fb39c0fb93f18173e29da6682b1,"About GoBear GoBear is Asia’s first transparent online personal finance marketplace. We don’t sell directly to our users – we’re the tool people use to find and compare banking and insurance products in 6 countries. Our free, easy-to-use platform offers the widest selection of products to make shopping for financial products transparent, easy and simple. We will help our users to have access to better products and higher approval rates. Through our data-driven technology we are empowering users and providers to build more meaningful relationships. GoBear’s strategy to evolve from a metasearch engine to an online marketplace will transform the Southeast Asia digital ecosystem for users and financial service providers. GoBear is one of the leading FinTech companies in the region and is featured frequently in the media and on stage.   The Job: Our Data Engineer (in the analytics team) is the person responsible for enhancing our analytics and performance management framework. You’ll be building our data infrastructure - like databases and large-scale data processing tools -  on the Google Cloud Platform.  You’ll be a perfect fit in this role if you’re an eager learner, have prior experience in quantitative domains, and if you’re keen to be a team player in a dynamic start-up.   You’ll get to:  Design, construct, install, test and maintain highly scalable data management systems Employ a variety scripting languages and tools to marry systems together Make sure our systems meet business requirements and industry practices Research opportunities for data acquisition and new uses for existing data Develop data set processes for data modelling, mining and production Integrate new data management technologies and software engineering tools into existing structures Create custom software components and analytics applications Install and update disaster recovery procedures Recommend ways to improve data reliability, efficiency and quality Collaborate with data architects, modelers and IT team members on project goals Build high-performance algorithms, prototypes, predictive models and proof of concepts ","RequirementsSkills:  2-3 years of working experience as a Data Engineering or as a developer Bachelor’s or Master’s degree in Computer Science Proficient in Java and in one of the scripting languages such as Python, JavaScript, Ruby or PHP Proficient with No-SQL databases like HBase or MongoDB Proficient in ETL processes and programming models on Apache Beam Proficient in cloud computing systems management services such as Stackdriver Familiar with cloud services such as MS Azure, Google Cloud Platform or AWS Familiarity with Machine Learning and Statistical techniques for data mining will be beneficial Familiarity with Google Analytics and Google Tag Manager will be an advantage Proficient in oral and written communication in English, as well as effective interpersonal skills "
/job/data-engineer-jewel-paymentech-ab98de328007a20fc1f5ad9a4cd3e160,"As a Data Engineer you will get to work on a wide range of problems using the cutting-edge technologies in Big Data and Data Science. You are required to translate Data Science and Machine learning based solutions into scalable code, and to develop innovative solutions to collect/cleanse/store/process data. In case you are very passionate about building high throughput, low latency, fault tolerant software then this position is for you. To be successful in this role, you will need to:  Analyze requirements and deliver solutions that meet requirements. Write code by using best software development practices. Produce code that meets security standards. Estimate timelines and deliver solutions within agreed timeline. Write clear & concise documentation for solutions/code. Contribute ideas within team to build better code. Continuously improve knowledge on new technologies. Excellent in English, both written and spoken. ","Requirements B.Sc., Masters, or equivalent experience in a quantitative field (Computer Science, Mathematics, Engineering, Artificial Intelligence, etc.). Knowledge in the use and application of Python to develop complex software. General machine learning techniques and technologies (e.g., Bayesian classifiers, regression techniques, graphical models, working with unbalanced data-sets) as well as applications (e.g., predictive analytics). NoSQL Database Programming/Development. Manipulation of various types of data; data cleaning, filtering, and pre-processing for example with text/images. Knowledge and experience in the use of cloud computing platforms (AWS/Azure/GCP/etc). SQL familiarity and database technologies (e.g., row versus column stores, in-memory DB, DB clustering, HA for DB). Familiarity and experience with Linux environments. Understanding batch (e.g., Apache Hadoop / Map Reduce) and stream processing approaches / frameworks (e.g., Apache Spark).    You’re a perfect fit us if you are  A master problem solver, and able to use own initiative to develop suitable solutions. A strong communicator with the ability to convey information to others in a simple and unambiguous way. An innovative, original thinker approach to job responsibilities, methods and processes. An energetic person who can be trusted to get a job done. "
/job/big-data-engineer-ernst-young-advisory-52a9c40c842ec8393282fdc31a1af874,"We are the only professional services organisation who has a separate business dedicated exclusively to the financial services marketplace. Join Financial Services (FSO) and you will work with multi-disciplinary teams from around the world to deliver a global perspective. Aligned to key industry groups including asset management, banking and capital markets, insurance and private equity, we provide integrated advisory, assurance, tax, and transaction services.   The opportunity  As part of our Data and Analytics team of Financial Services Advisory practice you will work with multi-disciplinary teams to support clients in a wide range of big data initiatives aiming to generate and present new, useful and actionable insights. You will have the opportunity to work and take responsibilities in challenging engagements, gaining exposure to clients in various sectors both in Singapore and in the APAC region.    Your key responsibilities  Participation in large-scale client engagements. Contribution towards, or even leading, the delivery of innovative and engaging big data solutions. Understanding of business and technical requirements, provision of subject matter expertise, and implementation of big data engineering techniques. Conducting of data discovery activities, performing root cause analysis, and making recommendations for the remediation of data quality issues. Putting into practice good organizational and time management skills, with the ability to prioritize and complete multiple complex projects under tight deadlines. ","RequirementsSkills and attributes for success  Leverage technology to continually learn, improve service delivery and maintain our leading edge best practices Strong presentation skills and proficiency in the use of PowerPoint, Word and Excel Good understanding of financial services industry    To qualify for the role you must have  Understanding or even practical experience of handling and manipulating semi-structured and unstructured data. Deep understanding of big data technology, concepts, tools, features, functions and benefits of different approaches available. Ability to deploy, manage, and administer Hadoop-based components. Ability to design, build, install, configure and support Hadoop-based applications. Experience with one of Java, C# or C++. Hands-on experience with HiveQL. Familiarity with data ingestion tools such as Kafka, Flume and Sqoop. Knowledge of hadoop related workflow/scheduling tools such as Oozie. Understanding of data modeling (ER models) techniques. Experience with investigating and handling data quality issues. Minimum 8 years hands-on experience in two (2) or more of the above areas. A Bachelor or Masters degree in Computer Science, Engineering, or other related fields.   Ideally, you’ll also have  Design and implementation experience of data models in physical form in one (or more) of the leading RDBMS platforms such as SQL Server, Oracle, IBM DB2/Netezza, Teradata, etc. Experience with Business Intelligence or statistical analysis tools and techniques. Strong communication and business relationship skills to effectively explain analysis, both verbally and in writing, to others and translate analysis into a clear business plan. Strong time management and organizational skills to gather and make use of data (both internal and external).   What we look for Highly motivated individuals with excellent problem-solving skills and the ability to prioritize shifting workloads in a rapidly changing industry. An effective communicator, you’ll be a confident team player that collaborates with people from various teams while looking to develop your career in a dynamic organization.   What working at EY offers We offer a competitive compensation package where you’ll be rewarded based on your performance and recognized for the value you bring to our business. We also offer you:  Support, coaching and feedback from some of the most engaging colleagues around Opportunities to develop new skills and progress your career The freedom and flexibility to handle your role in a way that’s right for you    About EY As a global leader in assurance, tax, transaction and advisory services, we’re using the finance products, expertise and systems we’ve developed to build a better working world. That starts with a culture that believes in giving you the training, opportunities and creative freedom to make things better. Whenever you join, however long you stay, the exceptional EY experience lasts a lifetime. And with a commitment to hiring and developing the most passionate people, we’ll make our ambition to be the best employer by 2020 a reality.   If you can confidently demonstrate that you meet the criteria above, please contact us as soon as possible. Join us in building a better working world. Apply now.  "
/job/data-centre-support-engineer-creative-infrastructure-solutions-5debf6c4120e2ba7be4bb2f83d24bf98,"The  Data  Centre  Support  Engineer  is  required  to  deliver  a  Moves,  Adds  and  Changes  service   within  a  client  data  center.  The  position  is  very  Customer  Oriented  and  requires  a  strong  focus  on   customer  requirements.  The  commitment  to  providing  a  High  Quality  service  to  meet  the  demands   of  a  strict  process  driven  environment  is  essential. The Data Center support engineer is responsible for network cable installation and removals and network cabling diagnostic.","Requirements1. Associate's degree/  diploma / trade school certification, or other verifiable training in a relevant technical field 2. Knowledge of telco technologies, systems, and circuits. 3. Connect communication copper and fiber cables between installed IT equipment and ensure that all links and communication cables have been tested, labeled, connected, and documented according to client standards.  4. Knowledge in Microsoft Excel and Word 5. Ability to work independently 6. Ability to communicate intelligently and effectively 7. Schedule flexibility to complete assigned migrations/projects. 8. Works may on occasion include after hours or weekend works depending on project needs. 9. Fresh grads are welcome to apply. "
/job/senior-engineer-engineer-data-centre-facilities-management-starhub-4e0d066faaec184fde6053448841ea60,"Oversee security, access control, process streamlining, audits and certification of our data centres; assess utility needs, and other general facility management matters.   Responsibilities  Assist in day-to-day operation and maintenance of all the various facilities systems in StarHub Data Centres and Central Offices, involving systems such as Generators, Uninterruptible Power Supply (UPS), DC Rectifier System, Static Transfer Switch (STS), Fire Protection System, Building Management System, HT/LT electrical system, all ACMV systems, etc Ensure the routine maintenance of the facilities systems being carried out according to planned schedule and contracted scope of work Plan, call for and evaluate tender specifications; project manage any expansion projects to cater for users’ requirements Ensure enforcement of security at StarHub sites by managing physical security and security systems such as the card access, CCTV surveillance, visitor tracking, etc. Perform 24 x 7 standby for fault & maintenance activation Execute FM customers’ related work orders within/by the customers’ requested Ready for Service (RFS) Dates Update and maintain all records relating to M&E, security, and building/ schematic drawings of the facilities Conduct regular checks of the premises for potential safety hazards and unsafe conditions; initiate corrective measures to maintain a safe and healthy work environment, in compliance with prevailing legislative and regulatory requirements Conduct risk assessment and management ","RequirementsQualifications  Bachelor degree or Diploma in Engineering At least 2 years of relevant experiences, preferably in an M&E and DC environment  We regret that only shortlisted candidates will be notified."
/job/data-technical-support-engineer-talent-trader-group-d6b37d54d9b37d2ff9688ff0d05a7da6," 1st level support on transmission, VoIP services and switching equipment  Manage ticket queue and responsibility for the issues Provide technical support through emails, tickets and phone Manage the network and systems for internal issues Responsible for support and maintenance for tracking, documentation and verification Arrange the roster shift for the team members ","Requirements Hands-on experience in network concepts Comfortable to work in Data Centre environment Independent, self-motivated and dynamic personality Experience in Data Centre NOC    Interested candidates who wish to apply for the advertised position, please email us an updated copy of your resume to; Email Address: it@talenttradergroup.com   EA License No.: 13C6305 Registration ID: R1333012   For candidate who applied for the advertised position is deemed to have consented to us that we may collect, use or disclosed your personal information for purpose in connection with the services provided by us.  "
/job/mct-big-data-engineer-165e3137bfd84a80aa511eb2574a2e44,"Do you have a broad theoretical and practical understanding of data engineering and data science? Can you wrangle large scale multidimensional data effectively? Are you always curious to learn something new? Do you love to solve engineering puzzles and optimize complex systems? Can you translate an idea in to an algorithm and make it into a product with quality and scalability in mind? Are you looking for window to the world ?   If so, you may be a great candidate for an Manufacturing Central Team (MCT) Data Engineer position at company, a global, Fortune 500 leader in the semiconductor industry. This position will be based in Singapore.   As an MCT Data Engineer at company, you will:   * Work with an international team of data scientists, data engineers, software engineers, process and equipment engineers, process integration engineers, yield enhancement engineers, R&D, etc. in a collaborative manner to develop new data science solutions that improve quality, improve yield, reduce deviations, improve manufacturing cycle time, reduce cost, extend manufacturing capabilities, etc. * Draw from a broad background of data-mining techniques in mathematics, statistics, information technology, machine learning, data engineering, design of experiments (DOE), visualization, etc. to discover insightful patterns in semiconductor manufacturing data * Work on projects and develop solutions that would be of high impact to various areas at all manufacturing fabs * Deliver polished presentations of data acquisition, data flow, data preparation and data presentation layer to internal customers and leaders to inform business strategy, streamline operations, and execute to revenue goals * In short, be a full-stack data engineer who can take an idea, access and prepare necessary data, work with data scientists to create machine learning models, develop it to an application with intuitive user interface, integrate with any pre-existing systems, demonstrate successful use cases and wins, etc.   Responsibilities and Tasks include, but not limited to:   * Understanding business needs and strategy to develop data science solutions * Collaborating with other data engineers and business process experts to access existing data in data warehouse and big data environments * Developing new or enhancing prior data acquisition and ETL pipelines from various sources into big data ecosystem. * Preparing data for machine learning using appropriate steps and methods, which may include data cleaning, transformation, augmentation, enrichment, sampling, etc. * Working with various scientific data such as equipment sensor data and logs, image and various types of signals, manufacturing process data, etc. to extract meaningful information for analytics * Creating intuitive user interface for interactive data visualization to explain insights from data * Preparing and delivering powerful presentations with rich data visualizations and meaningful business conclusions * Documenting the train of thoughts used to design and implement solutions along with managed source code * Traveling and participating in various internal forums for strategy building and to build solutions in collaboration with various manufacturing sites","RequirementsQualifications and Experience: * B.S degree or M.S. degree with 2 years’ experience in Computer Engineering, Industrial Engineering, or any other discipline with extensive programming or machine learning work  * Minimum 2 years of experience working in big data and data science projects and teams * Extensive experience with Java, Scala, Python in Hadoop ecosystem (Spark, Hive, HBase, etc.) is a must * Extensive experience with at least one relational databases (MS SQL, Oracle, MySQL, Teradata, etc.) is a must * Experience with building analytical web applications and data visualization technologies (Django, Javascript, Bootstrap, D3, etc.) is a plus * Good grasp of statistical and scientific programming packages in Python, R, etc. * Good grasp of data science concepts with emphasis on machine learning techniques is a plus * Experience with image processing (OpenCV, Python PIL, scikit-image, etc.) is a plus * Proficiency with collaborative source code management and documentation tools. (GIT, JIRA, Confluence, etc.) * Strong communication skills (written, verbal and presentation) * Willing to do international travel"
/job/mct-big-data-senior-engineer-d811457c351ebac1d6c04c22a4681965,"Do you have a broad theoretical and practical understanding of data engineering and data science? Can you wrangle large scale multidimensional data effectively? Are you always curious to learn something new? Do you love to solve engineering puzzles and optimize complex systems? Can you translate an idea in to an algorithm and make it into a product with quality and scalability in mind? Are you looking for window to the world ?   If so, you may be a great candidate for an Manufacturing Central Team (MCT) Data Engineer position at company, a global, Fortune 500 leader in the semiconductor industry. This position will be based in Singapore.   As an MCT Data Engineer at company, you will:   * Work with an international team of data scientists, data engineers, software engineers, process and equipment engineers, process integration engineers, yield enhancement engineers, R&D, etc. in a collaborative manner to develop new data science solutions that improve quality, improve yield, reduce deviations, improve manufacturing cycle time, reduce cost, extend manufacturing capabilities, etc. * Draw from a broad background of data-mining techniques in mathematics, statistics, information technology, machine learning, data engineering, design of experiments (DOE), visualization, etc. to discover insightful patterns in semiconductor manufacturing data * Work on projects and develop solutions that would be of high impact to various areas at all manufacturing fabs * Deliver polished presentations of data acquisition, data flow, data preparation and data presentation layer to internal customers and leaders to inform business strategy, streamline operations, and execute to revenue goals * In short, be a full-stack data engineer who can take an idea, access and prepare necessary data, work with data scientists to create machine learning models, develop it to an application with intuitive user interface, integrate with any pre-existing systems, demonstrate successful use cases and wins, etc.   Responsibilities and Tasks include, but not limited to:   * Understanding business needs and strategy to develop data science solutions * Collaborating with other data engineers and business process experts to access existing data in data warehouse and big data environments * Developing new or enhancing prior data acquisition and ETL pipelines from various sources into big data ecosystem. * Preparing data for machine learning using appropriate steps and methods, which may include data cleaning, transformation, augmentation, enrichment, sampling, etc. * Working with various scientific data such as equipment sensor data and logs, image and various types of signals, manufacturing process data, etc. to extract meaningful information for analytics * Creating intuitive user interface for interactive data visualization to explain insights from data * Preparing and delivering powerful presentations with rich data visualizations and meaningful business conclusions * Documenting the train of thoughts used to design and implement solutions along with managed source code * Traveling and participating in various internal forums for strategy building and to build solutions in collaboration with various manufacturing sites","RequirementsQualifications and Experience: * B.S degree or M.S. degree with 2 years’ experience in Computer Engineering, Industrial Engineering, or any other discipline with extensive programming or machine learning work  * Minimum 2 years of experience working in big data and data science projects and teams * Extensive experience with Java, Scala, Python in Hadoop ecosystem (Spark, Hive, HBase, etc.) is a must * Extensive experience with at least one relational databases (MS SQL, Oracle, MySQL, Teradata, etc.) is a must * Experience with building analytical web applications and data visualization technologies (Django, Javascript, Bootstrap, D3, etc.) is a plus * Good grasp of statistical and scientific programming packages in Python, R, etc. * Good grasp of data science concepts with emphasis on machine learning techniques is a plus * Experience with image processing (OpenCV, Python PIL, scikit-image, etc.) is a plus * Proficiency with collaborative source code management and documentation tools. (GIT, JIRA, Confluence, etc.) * Strong communication skills (written, verbal and presentation) * Willing to do international travel"
/job/senior-etl-data-engineer-smartsoft-4b1aeea089cbaa6726eb2cb5dca20fd0,"  Responsibilities include understanding ETL & Data Engineering requirements, architecture design, development of etl mapping and framework using SQL, Informatica, Python, Google Bigquery & Google Dataflow. This is a technical position providing hands-on delivery role, working with the cross-functional teams, while ensuring excellent cross functional relationship.   Job Details:  Advanced working SQL knowledge and experience working with relational databases, query authoring (SQL) as well as working familiarity with a variety of databases. Build the infrastructure required for optimal extraction, transformation, and loading of data from a wide variety of data sources using SQL and Google ‘big data’ technologies. Build processes supporting data transformation, data structures, metadata, dependency and workload management. Work with stakeholders including the BSA, Report developers, Data and Design teams to assist with data-related technical issues and support their data infrastructure needs. Additional responsibilities include troubleshooting, maintenance, and optimization or enhancement of existing processes. Partner with engineering leads and architects to define & coordinate technical design. Design and code reviews to ensure standards and quality level for the build Performance tuning of ETL jobs to meet SLA Prepare technical documentations on the deliverables Identify, define and implement best practices for process improvements for SDLC management ","RequirementsExperiences:  Must have 4 to 6 years of experience using SQL, Informatica, Python & Bigquery. Must be hands-on and have working experience in SQL, Informatica 10.x, Python. Working experience with Google Bigquery, Google Dataflow & Exasol is a big plus. Working experience with Kafka or Google Pubsub is a big plus. Hands-on experience in development using best practices and standards on Informatica products specifically PowerCenter 9.x/10.x and Web Service Transformation Solid working skills preferably in Oracle RDBMS, SQL, PL/SQL and ODS/3NF db design considering performance and SLA. Strong design skills with a proven track record of success on large/highly complex projects preferably in the area of Enterprise Apps and Integration. Must have the ability to communicate technical issues and observations. Must have experience in cross functional domain and end to end knowledge of business and technology. Technical and functional knowledge in Oracle EBS & Siebel CRM are preferred.  Must possess excellent verbal and written communication skills. Must be able to effectively communicate & work with fellow team members and other functional team members to coordinate & meet deliverables"
/job/senior-etl-data-engineer-schellden-global-services-31003e58ccc2f49ba4d79ddd8a696ca4,"Responsibilities include understanding ETL & Data Engineering requirements, architecture design, development of etl mapping and framework using SQL, Informatica, Python, Google Bigquery & Google Dataflow. This is a technical position providing hands-on delivery role, working with the cross-functional teams, while ensuring excellent cross functional relationship.   Job Details:  Advanced working SQL knowledge and experience working with relational databases, query authoring (SQL) as well as working familiarity with a variety of databases. Build the infrastructure required for optimal extraction, transformation, and loading of data from a wide variety of data sources using SQL and Google ‘big data’ technologies. Build processes supporting data transformation, data structures, metadata, dependency and workload management. Work with stakeholders including the BSA, Report developers, Data and Design teams to assist with data-related technical issues and support their data infrastructure needs. Additional responsibilities include troubleshooting, maintenance, and optimization or enhancement of existing processes. Partner with engineering leads and architects to define & coordinate technical design. Design and code reviews to ensure standards and quality level for the build Performance tuning of ETL jobs to meet SLA Prepare technical documentations on the deliverables Identify, define and implement best practices for process improvements for SDLC management ","Requirements Must have 4 to 6 years of experience using SQL, Informatica, Python & Bigquery. Must be hands-on and have working experience in SQL, Informatica 10.x, Python. Working experience with Google Bigquery, Google Dataflow & Exasol is a big plus. Working experience with Kafka or Google Pubsub is a big plus. Hands-on experience in development using best practices and standards on Informatica products specifically PowerCenter 9.x/10.x and Web Service Transformation Solid working skills preferably in Oracle RDBMS, SQL, PL/SQL and ODS/3NF db design considering performance and SLA. Strong design skills with a proven track record of success on large/highly complex projects preferably in the area of Enterprise Apps and Integration. Must have the ability to communicate technical issues and observations. Must have experience in cross functional domain and end to end knowledge of business and technology. Technical and functional knowledge in Oracle EBS & Siebel CRM are preferred. Must possess excellent verbal and written communication skills. Must be able to effectively communicate & work with fellow team members and other functional team members to coordinate & meet deliverables. "
/job/senior-etl-data-engineer-schellden-global-99f611ea6cf10ae6754dd32381943bcd,"Responsibilities include understanding ETL & Data Engineering requirements, architecture design, development of etl mapping and framework using SQL, Informatica, Python, Google Bigquery & Google Dataflow. This is a technical position providing hands-on delivery role, working with the cross-functional teams, while ensuring excellent cross functional relationship.   Job Details:  Advanced working SQL knowledge and experience working with relational databases, query authoring (SQL) as well as working familiarity with a variety of databases. Build the infrastructure required for optimal extraction, transformation, and loading of data from a wide variety of data sources using SQL and Google ‘big data’ technologies. Build processes supporting data transformation, data structures, metadata, dependency and workload management. Work with stakeholders including the BSA, Report developers, Data and Design teams to assist with data-related technical issues and support their data infrastructure needs. Additional responsibilities include troubleshooting, maintenance, and optimization or enhancement of existing processes. Partner with engineering leads and architects to define & coordinate technical design. Design and code reviews to ensure standards and quality level for the build Performance tuning of ETL jobs to meet SLA Prepare technical documentations on the deliverables Identify, define and implement best practices for process improvements for SDLC management ","RequirementsExperiences:  Must have 4 to 6 years of experience using SQL, Informatica, Python & Bigquery. Must be hands-on and have working experience in SQL, Informatica 10.x, Python. Working experience with Google Bigquery, Google Dataflow & Exasol is a big plus. Working experience with Kafka or Google Pubsub is a big plus. Hands-on experience in development using best practices and standards on Informatica products specifically PowerCenter 9.x/10.x and Web Service Transformation Solid working skills preferably in Oracle RDBMS, SQL, PL/SQL and ODS/3NF db design considering performance and SLA. Strong design skills with a proven track record of success on large/highly complex projects preferably in the area of Enterprise Apps and Integration. Must have the ability to communicate technical issues and observations. Must have experience in cross functional domain and end to end knowledge of business and technology. Technical and functional knowledge in Oracle EBS & Siebel CRM are preferred. Must possess excellent verbal and written communication skills. Must be able to effectively communicate & work with fellow team members and other functional team members to coordinate & meet deliverables. "
/job/big-data-engineer-ernst-young-advisory-c94d217a77e02ce6753d0390cf9fdca7,"We are the only professional services organisation who has a separate business dedicated exclusively to the financial services marketplace. Join Financial Services (FSO) and you will work with multi-disciplinary teams from around the world to deliver a global perspective. Aligned to key industry groups including asset management, banking and capital markets, insurance and private equity, we provide integrated advisory, assurance, tax, and transaction services.   The opportunity  As part of our Data and Analytics team of Financial Services Advisory practice you will work with multi-disciplinary teams to support clients in a wide range of big data initiatives aiming to generate and present new, useful and actionable insights. You will have the opportunity to work and take responsibilities in challenging engagements, gaining exposure to clients in various sectors both in Singapore and in the APAC region.    Your key responsibilities  Participation in large-scale client engagements. Contribution towards, or even leading, the delivery of innovative and engaging big data solutions. Understanding of business and technical requirements, provision of subject matter expertise, and implementation of big data engineering techniques. Conducting of data discovery activities, performing root cause analysis, and making recommendations for the remediation of data quality issues. Putting into practice good organizational and time management skills, with the ability to prioritize and complete multiple complex projects under tight deadlines. ","RequirementsSkills and attributes for success  Leverage technology to continually learn, improve service delivery and maintain our leading edge best practices Strong presentation skills and proficiency in the use of PowerPoint, Word and Excel Good understanding of financial services industry    To qualify for the role you must have  Understanding or even practical experience of handling and manipulating semi-structured and unstructured data. Deep understanding of big data technology, concepts, tools, features, functions and benefits of different approaches available. Ability to deploy, manage, and administer Hadoop-based components. Ability to design, build, install, configure and support Hadoop-based applications. Experience with one of Java, C# or C++. Hands-on experience with HiveQL. Familiarity with data ingestion tools such as Kafka, Flume and Sqoop. Knowledge of hadoop related workflow/scheduling tools such as Oozie. Understanding of data modeling (ER models) techniques. Experience with investigating and handling data quality issues. Minimum 5 years hands-on experience in two (2) or more of the above areas. A Bachelor or Masters degree in Computer Science, Engineering, or other related fields.   Ideally, you’ll also have  Design and implementation experience of data models in physical form in one (or more) of the leading RDBMS platforms such as SQL Server, Oracle, IBM DB2/Netezza, Teradata, etc. Experience with Business Intelligence or statistical analysis tools and techniques. Strong communication and business relationship skills to effectively explain analysis, both verbally and in writing, to others and translate analysis into a clear business plan. Strong time management and organizational skills to gather and make use of data (both internal and external).   What we look for Highly motivated individuals with excellent problem-solving skills and the ability to prioritize shifting workloads in a rapidly changing industry. An effective communicator, you’ll be a confident team player that collaborates with people from various teams while looking to develop your career in a dynamic organization.   What working at EY offers We offer a competitive compensation package where you’ll be rewarded based on your performance and recognized for the value you bring to our business. We also offer you:  Support, coaching and feedback from some of the most engaging colleagues around Opportunities to develop new skills and progress your career The freedom and flexibility to handle your role in a way that’s right for you    About EY As a global leader in assurance, tax, transaction and advisory services, we’re using the finance products, expertise and systems we’ve developed to build a better working world. That starts with a culture that believes in giving you the training, opportunities and creative freedom to make things better. Whenever you join, however long you stay, the exceptional EY experience lasts a lifetime. And with a commitment to hiring and developing the most passionate people, we’ll make our ambition to be the best employer by 2020 a reality.   If you can confidently demonstrate that you meet the criteria above, please contact us as soon as possible. Join us in building a better working world. Apply now.  "
/job/big-data-engineer-ernst-young-advisory-0e254e8e63d01bd52efed3f91e4e1c0c,"We are the only professional services organisation who has a separate business dedicated exclusively to the financial services marketplace. Join Financial Services (FSO) and you will work with multi-disciplinary teams from around the world to deliver a global perspective. Aligned to key industry groups including asset management, banking and capital markets, insurance and private equity, we provide integrated advisory, assurance, tax, and transaction services.   The opportunity  As part of our Data and Analytics team of Financial Services Advisory practice you will work with multi-disciplinary teams to support clients in a wide range of big data initiatives aiming to generate and present new, useful and actionable insights. You will have the opportunity to work and take responsibilities in challenging engagements, gaining exposure to clients in various sectors both in Singapore and in the APAC region.    Your key responsibilities  Participation in large-scale client engagements. Contribution towards, or even leading, the delivery of innovative and engaging big data solutions. Understanding of business and technical requirements, provision of subject matter expertise, and implementation of big data engineering techniques. Conducting of data discovery activities, performing root cause analysis, and making recommendations for the remediation of data quality issues. Putting into practice good organizational and time management skills, with the ability to prioritize and complete multiple complex projects under tight deadlines. ","RequirementsSkills and attributes for success  Leverage technology to continually learn, improve service delivery and maintain our leading edge best practices Strong presentation skills and proficiency in the use of PowerPoint, Word and Excel Good understanding of financial services industry    To qualify for the role you must have  Understanding or even practical experience of handling and manipulating semi-structured and unstructured data. Deep understanding of big data technology, concepts, tools, features, functions and benefits of different approaches available. Ability to deploy, manage, and administer Hadoop-based components. Ability to design, build, install, configure and support Hadoop-based applications. Experience with one of Java, C# or C++. Hands-on experience with HiveQL. Familiarity with data ingestion tools such as Kafka, Flume and Sqoop. Knowledge of hadoop related workflow/scheduling tools such as Oozie. Understanding of data modeling (ER models) techniques. Experience with investigating and handling data quality issues. Minimum 3 years hands-on experience in two (2) or more of the above areas. A Bachelor or Masters degree in Computer Science, Engineering, or other related fields.   Ideally, you’ll also have  Design and implementation experience of data models in physical form in one (or more) of the leading RDBMS platforms such as SQL Server, Oracle, IBM DB2/Netezza, Teradata, etc. Experience with Business Intelligence or statistical analysis tools and techniques. Strong communication and business relationship skills to effectively explain analysis, both verbally and in writing, to others and translate analysis into a clear business plan. Strong time management and organizational skills to gather and make use of data (both internal and external).   What we look for Highly motivated individuals with excellent problem-solving skills and the ability to prioritize shifting workloads in a rapidly changing industry. An effective communicator, you’ll be a confident team player that collaborates with people from various teams while looking to develop your career in a dynamic organization.   What working at EY offers We offer a competitive compensation package where you’ll be rewarded based on your performance and recognized for the value you bring to our business. We also offer you:  Support, coaching and feedback from some of the most engaging colleagues around Opportunities to develop new skills and progress your career The freedom and flexibility to handle your role in a way that’s right for you    About EY As a global leader in assurance, tax, transaction and advisory services, we’re using the finance products, expertise and systems we’ve developed to build a better working world. That starts with a culture that believes in giving you the training, opportunities and creative freedom to make things better. Whenever you join, however long you stay, the exceptional EY experience lasts a lifetime. And with a commitment to hiring and developing the most passionate people, we’ll make our ambition to be the best employer by 2020 a reality.   If you can confidently demonstrate that you meet the criteria above, please contact us as soon as possible. Join us in building a better working world. Apply now.  "
/job/big-data-engineer-ernst-young-advisory-5c6015c43915d53b5bec72fef296a1f6,"We are the only professional services organisation who has a separate business dedicated exclusively to the financial services marketplace. Join Financial Services (FSO) and you will work with multi-disciplinary teams from around the world to deliver a global perspective. Aligned to key industry groups including asset management, banking and capital markets, insurance and private equity, we provide integrated advisory, assurance, tax, and transaction services.   The opportunity  As part of our Data and Analytics team of Financial Services Advisory practice you will work with multi-disciplinary teams to support clients in a wide range of big data initiatives aiming to generate and present new, useful and actionable insights. You will have the opportunity to work and take responsibilities in challenging engagements, gaining exposure to clients in various sectors both in Singapore and in the APAC region.    Your key responsibilities  Participation in large-scale client engagements. Contribution towards, or even leading, the delivery of innovative and engaging big data solutions. Understanding of business and technical requirements, provision of subject matter expertise, and implementation of big data engineering techniques. Conducting of data discovery activities, performing root cause analysis, and making recommendations for the remediation of data quality issues. Putting into practice good organizational and time management skills, with the ability to prioritize and complete multiple complex projects under tight deadlines. ","RequirementsSkills and attributes for success  Leverage technology to continually learn, improve service delivery and maintain our leading edge best practices Strong presentation skills and proficiency in the use of PowerPoint, Word and Excel Good understanding of financial services industry    To qualify for the role you must have  Understanding or even practical experience of handling and manipulating semi-structured and unstructured data. Deep understanding of big data technology, concepts, tools, features, functions and benefits of different approaches available. Ability to deploy, manage, and administer Hadoop-based components. Ability to design, build, install, configure and support Hadoop-based applications. Experience with one of Java, C# or C++. Hands-on experience with HiveQL. Familiarity with data ingestion tools such as Kafka, Flume and Sqoop. Knowledge of hadoop related workflow/scheduling tools such as Oozie. Understanding of data modeling (ER models) techniques. Experience with investigating and handling data quality issues. Minimum 5 years hands-on experience in two (2) or more of the above areas. A Bachelor or Masters degree in Computer Science, Engineering, or other related fields.   Ideally, you’ll also have  Design and implementation experience of data models in physical form in one (or more) of the leading RDBMS platforms such as SQL Server, Oracle, IBM DB2/Netezza, Teradata, etc. Experience with Business Intelligence or statistical analysis tools and techniques. Strong communication and business relationship skills to effectively explain analysis, both verbally and in writing, to others and translate analysis into a clear business plan. Strong time management and organizational skills to gather and make use of data (both internal and external).   What we look for Highly motivated individuals with excellent problem-solving skills and the ability to prioritize shifting workloads in a rapidly changing industry. An effective communicator, you’ll be a confident team player that collaborates with people from various teams while looking to develop your career in a dynamic organization.   What working at EY offers We offer a competitive compensation package where you’ll be rewarded based on your performance and recognized for the value you bring to our business. We also offer you:  Support, coaching and feedback from some of the most engaging colleagues around Opportunities to develop new skills and progress your career The freedom and flexibility to handle your role in a way that’s right for you    About EY As a global leader in assurance, tax, transaction and advisory services, we’re using the finance products, expertise and systems we’ve developed to build a better working world. That starts with a culture that believes in giving you the training, opportunities and creative freedom to make things better. Whenever you join, however long you stay, the exceptional EY experience lasts a lifetime. And with a commitment to hiring and developing the most passionate people, we’ll make our ambition to be the best employer by 2020 a reality.   If you can confidently demonstrate that you meet the criteria above, please contact us as soon as possible. Join us in building a better working world. Apply now.  "
/job/senior-data-center-engineer-itcan-5a343fc2c67aacdc5771b512595ef0af,"Title: Senior Data Center Engineer JD:   Provide infrastructure and security monitoring/support for a 24x7 data centre. Carry out service requests which include code deployment, restart servers - VM - backup - storage, manage batch job processing, perform security scanning, escort duty etc. The candidate will work with DC Provider Services team and their vendors to review and coordinate  tech room layout, backbone connectivity, and rack elevation drawings.  ",RequirementsMore than 3+ Years of exp Data Center VM - backup - storage  
/job/-big-data-engineer-f93dc298de35c9c833d992120476878c,"Responsibilities: Be part of a DevOps team that design, build and maintain innovative Smart Manufacturing solutions and Big Data platform.  Participate in Agile development lifecycle for software & solution related to Smart Manufacturing and Big Data platform.   Work with Data Science within company to develop, automate and maintain reliable data analytic and mining solutions for Smart Manufacturing and Big Data platform.  Ability to assess current IT environments and make recommendations to increase capacity needs.  Communicate, collaborate and coordinate on Smart Manufacturing and Big Data related activities to various level of stakeholders and senior management.","RequirementsRequirements: Bachelor’s or Master’s degree Computer Science, Electrical & Electronics/Computer/Software Engineering, Information Systems or related fields.   Fresh graduates are welcome to apply and for those with good understanding and hands-on experience in the following areas will be advantageous.    Hadoop based technologies such as HDFS, MapReduce, Hive, MongoDB, HBase, Spark etc.  Data warehousing solutions and latest (NoSQL) database technologies.  Programming or scripting languages like Java, Linux, Matlab, C#/C++, Python, Perl and/or R on Linux/Windows platforms.  Big Data visualization and reporting software like Tableau.  ETL/BI solutions using Microsoft SSIS, Informatica or having DB programming experience (TSQL, PLSQL).    Effective oral and written communication with strong analytical, problem solving, multitasking and project management skills are essential on the job."
/job/product-data-management-senior-engineer-wanco-manpower-e4ebc7f9c89dcf28691bfa6a882f2795," The person will join our Dynamic Data team to lead the Data projects to support our factory This will require leadership, autonomy and strong technical skills The data group objective is to ensure the data quality and to be the key person in the organization to understand the overall data models The job is based in our Semiconductor factory in (Singapore) and requires close work with people located in our headquarters in France Configuration of new products (BOM, Routings etc) in our MES Siview and our ERP Oracle eBusiness suite Management of Engineering Change Notes (evolutions in the configurations) Help users to define the requirements, validation of the demands, implementation Reference for application of the Data Acquisition corporate rules Documentation of the changes and of the operational procedures Development of relevant tooling to optimize the activities Work closely with other local team: IT CIM (automation), process, production, finance etc... Strong interaction with Data Acquisition team located in France ","Requirements Bachelor’s degree in engineering, IT or related field required. (M) 3 to 5 years of related experience, prior experience in the semiconductor industry desired.(M) Technical skills: DB2, SQL.(M) Proficiency with MES system Siview.(plus) Working level communication skills in French, desired.(plus) Demonstrated leadership skills and coordinate on-site and remote teams Highly organized, practical, analytical and detail oriented Ability to multi-task, prioritize tasks, make critical decisions. Ability to work independently as well as in a team environment. Ability to work productively with frequent interruptions. Flexible schedule and able to work the hours required to meet deadlines. "
/job/research-engineer-e0d13bb6e16d7168d605c8c511db3ed3," Plan, co-ordinate and conduct co-innovation workshops. Lead as Req mgr for the co-innovation program Work closely with researchers to investigate the business challenges, innovate solutions and convert them to business opportunities. Find business value of innovations. Work closely with industrial partners to implement and test the solution prototypes Align & work closely with Dept management to convert prototypes and PoC’s to business proposals to HQ stakeholders Participate and present in User conferences and other seminars to promote the solution concepts. Support marketing team to sell the solution concepts at customer sites, worldwide. ",Requirements Atleast 3~5yrs operations experience in  chemical industry Participated in major turnarounds and worked in the capacity of coordinating major revamp /debottlenecking projects Keen on advanced analytics and has experience in demonstrating these skills Energy Management / Heat integration / Process Optimization Advanced Data Analytics Matlab or R knowledge is an added advantage 
/job/python-etl-big-data-engineer-cxa-group-1b585050532bdd76ad9421adc07b5a92,"In this role, you would be responsible for:  Creating and maintaining robust ETL jobs Ensuring easy access to the data for the various data consumers Providing solutions for different storage and processing-related issues Contributing to the design of the company’s Data Architecture ","RequirementsRequirements  Strong Python skills (including Pandas, SQLAlchemy) Proven ability to work efficiently with databases: SQL / NoSQL Experience with Hadoop / Spark is a strong plus Knowledge in Machine Learning - Optional Experience with Web and Front-end tools - Optional Strong software culture is very recommended Ability to express ideas clearly in writing and verbally University graduate with Engineering Degree Native Speaker / Full Fluency English "
/job/data-engineer-collabera-technologies-60c011eb6b7af24a6e1597fd7d15b727,"Ø  Possess a degree in Computer Science or related fields Ø  At least 8 year of working experience in data engineering on any relevant database technology - Experience in ETL tools, development in Microsoft SQL Server and Microsoft SQL Server Analysis Services (or any similar SQL/OLAP technology) Ø  Good communication skills, able to work independently with minimal supervision Ø  Good team player as this role will be part of a bigger teamØ ","RequirementsØ  Good understanding of data modeling concepts Ø  Experience in Python or Microsoft SQL Server Analysis Services is a plus Ø  Strong understanding of data modeling concepts and good ability to design various components of data model and data engineering solution Able to guide junior team members, review solution design and perform code review"
/job/data-centre-engineer-helius-technologies-a8ee9115e5ac0b43cc6e5d451a14bd3f,"Job Objective Support mission critical data centres and remote buildings operations in Singapore. This roles is an 12-hour shift duty and support the data centre operations in data centres.   Job Description  Possess good knowledge of data centre operation tasks and duties. Perform day-to- day data centre / computer operations duties (key management, escorting vendors, facilities infrastructure checks, degaussing, routine checks, desktop & laptop management) Strong ability to support activities in data centre and computer rooms Ensure data centre physical security procedures are followed strictly. Prompt escalation of  incidents following the standard incident response procedure & track till closure To generate reports to management ","RequirementsIDesired Skills, Knowledge and Experience  Minimum 1 year of Data Centre operations experience preferable in a team. Experience working in a high-pressured environment with 24x7 on-call responsibilities Strong understanding of incident, problem and change management procedures based on ITIL best practices Experienced in supporting Data Centre vendors, out-sourcing vendors. DCIM knowledge and usage (CA DCIM preferred) Ability to multi-task and proficient in Microsoft Office applications; Excel & PowerPoint Good written and verbal communication skills Highly motivated and self-driven An analytical and inquiring mind to derive innovative solutions. Ability to work independently and in a team Must have experience working in data centre operations in financial institutions.    Certification  Minimum diploma holder in computer science or Engineering Certified Data Centre Facilities Operation manager or  Equivalent Qualifications in ITIL Foundation level at a minimum   "
/job/data-engineer-titansoft-8ac4098c795dce10e7a48030a42255b3,"If you believe data makes the world go round, we believe we have found the one we are looking for. Our data and research team are the ultimate managers of data. Others see meaningless figures but they see value. Our team are part of mathematician, part of computer scientist, and part of interpreters. Of data. What a Data Engineer does in Titansoft Manage data warehouse with plans for a business vertical or a group of business verticals Generate and manage all allocated data sets including ensuring its quality based on requirements Work with our Data Infrastructure team to triage and resolve infrastructure issues Manage the delivery of high impact dashboards and data visualisation diagrams","RequirementsWhat we are looking for in a Data Engineer Qualifications BA/BS in Computer Science, Electronics or Electrical Engineering, Information Technology or other qualified achievement Experience Hands-on experience in SQL or similar languages and development experience in at least one scripting language (Python preferred) Understand data architecture, data modeling and schema design What makes a (Super!) Data Engineer in Titansoft Patience to clean up huge amounts of data Passion to research domain knowledge Experience with large data sets, Hadoop, and data visualisation tools Interest in cloud computing and service (GCP, AWS, Azure) Interest in AI/ Machine-Learning product"
/job/big-data-engineer-devops-engineer-software-developer-add-on-apac-singapore-bff289fec02aff0092e988d84800d315," Big Data Engineer  Responsibilities  Data sources integration and manipulation Design and build complex reports and dashboards       DevOps Engineer   Responsibilities  Responsible for deployment of advanced services on the cloud and on prem Implementation of automation solutions     Software Developer  Responsibilities  Assist in creating a tailor-made architecture Deployment of advanced services on the cloud Implement automation solutions Debug, troubleshoot and fix technical issues     ","Requirements Big Data Engineer  Job Requirements   3 years proven experience with big data tools preferably Splunk and/or ELK Proven scripting abilities in at least one of the following: Bash, Python, Ruby, Perl, PowerShell. Hands on Experience in building complex reports and dashboards based on big data platforms Hands on experience as cyber analyst or with SIEM tools– advantage Knowledge of cyber-attack techniques, threat vectors, risk management, and incident management Experience with implantation of cloud based big data systems and data analysis services  – advantage Experience with data visualization and charting (yFiles / d3.js / Chartist.js or similar) - advantage Excellent communication (writing and verbal)  skills in English, other languages - advantage Candidate must possess at least Bachelor's Degree/Post Graduate Diploma/Professional Degree in Engineering (Computer/Telecommunication) or equivalent.     DevOps Engineer   Job Requirements   3 years proven experience as a Linux/Windows Administrator  3 years proven experience with implementing end to end cloud based complex services     Design Implementation and optimization (technical and financial) Operation and monitoring   Hands on experience with big data solutions Hands on experience with cyber security technologies Very good understanding of networking, Linux and Windows administration. Experience with at least two of the following: Amazon Web Services, Microsoft Azure, Google Cloud Platform, VMware. Scripting abilities in at least one of the following: Bash, Python, Ruby, Perl, PowerShell. Creative troubleshooting skills and out-of-the-box thinking Excellent communication (writing and verbal) skills in English     Software Developer  Job Requirements  2+ years experience as full stack developer and web application development. Strong knowledge and experience with HTML5, CSS3, JavaScript(ES6) Experience with frontend frameworks. Proven scripting abilities in at least one of the following: Bash, Python, Ruby, Perl, PowerShell. Hand on experience with big data solutions preferably Splunk and/or ELK - advantage Hand on experience with cyber security technologies - advantage Experience with data visualization and charting (yFiles / d3.js / Chartist.js or similar) - advantage Graphic design orientation, passionate about clean design Experience with CSS preprocessors – advantage. Excellent communication (writing and verbal) skills in English       "
/job/contract-senior-data-engineer-%E2%80%93-python-group-finance-dbs-bank-a88c75d9dd18a1cb9b7d92fc713a8337," Primary owner of cost allocation prototype model for Singapore and other countries Understand and translate cost allocation logic requirements to design and develop python scripts Enhance and modify existing python scripts to suit business needs Analyse all input data details to ensure that the data being sourced is complete and accurate Manage and drive script optimization, data storage and data validation as required    Key Responsibilities  Fit-for-purpose working prototype model to simulate the impact of the new Cost Allocation methodology for Singapore and other countries ","Requirements At least 2 years of experience using Python programming for data analysis preferably in a banking environment Degree in Information Systems, Computer Science, Engineering or related field with relevant experience in Python Strong presentation, analytical and problem-solving skills High attention to details, highly organized and able to work under pressure in a time-critical and fast-paced environment Results focused self-starter with ability to work with ambiguity and ‘can-do’ attitude Highly proficient in data manipulation using Python and Python libraries such as NumPy, Pandas Proven ability in manipulating and presenting large datasets using Business Intelligence (BI) tools including Microsoft Excel Experience with data visualization tools e.g. Tableau, Qlikview Work with various stakeholders from across the bank to understand logic and data requirements 	  "
/job/big-data-software-engineer-adecco-personnel-8cea5272c7993d0c6addc977942ecead,"The department is responsible for development and maintenance of Risk and Finance applications used by worldwide users covering Market Risk, Counterparty Risk, Finance domain. The applications are in-house developments with a mix of Microsoft and open source technologies.  The open position is to join one major investment project to tackle the regulatory requirement by redesigning information system platform to be global and adaptable enabling automated reporting and real-time processing and monitoring. The project will transform application landscape and bring it to the next level.  Main Responsibilities:  Lead technical study into a propose solution, while involving expertise from infrastructure big data expert, business analyst requirement Document proposed design and develop the solution Implicitly ensure all CI-CD artefacts are part of the solution Perform code review while fostering knowledge and coaching best practices to team members Interact and provide reporting to project managers Monitor technical risk and escalate appropriately to management  The position requires autonomy and reliability in performing duties with initiatives and leadership when it comes to all non-functional deliverables such as testing tools, mocking objects, production monitoring concerns, quality control including performance and load testing.","Requirements At least 7 years in Software development At least 6 years in Java/J2EE development At least 4 years experience in streaming solution Hands on Data ingest and data processing technology like Spark streaming and Spark Hands on Messaging systems like Kafka, Flume or ActiveMQ, MQSeries or RabitMQ Hands on knowledge on Hadoop (preferably Hortonworks distribution) - HDFS, HBase, Hive, ORC/Parquet Build tool - Maven/sbt/ant, UML, Restful web services, Jenkins/Team City, Source management – SVN/GIT, TDD using Junit, Jira/QC  Good to have:  Solution design using proven patterns, awareness of anti-patterns, performance tuning, especially in streaming Knowledge of tools like Phoenix, ElasticSearch, Sqoop, StreamSets are good to have. Basic understanding of finance and investment banking  Other Professional Skills and Mind-set  Excellent written and verbal communication skills for both team mates and management Strong analytical and problem solving skills Proficient software development life cycle Appetite to follow technology trend and participate to communities  Prepare your resume in word document (please include your current salary package with full breakdown such as base, incentives, annual wage supplement etc.) and expected package with your notice period (Including leaves to offset) and email it to TechnicalStaffing@adecco.com All shortlisted candidates will be contacted. Wai Yun Wen EA License No: 91C2918 Personnel Registration Number: R1330726"
/job/avp-data-engineer-ntuc-link-2b1e7cfe58b6a681298840d3f44af017,"The rapid adoption of technology and mobile devices have contributed to vast new flows of information which are larger in volume, faster in velocity, diverse in variety, and requires veracity of the information for use. This new type of information composed of structured and unstructured data, broadly known as big data (and combined with tools and platforms), if utilized well, could radically improve business performance.   As the organization embarks to become a data-driven organization, significant decisions and value generation will be based on the data that we capture and deploy. The 7 SE’s range in a broad scope of data from FairPrice (retail), Income (insurance), Unity (healthcare), FoodFare (F&B), LearningHub (training), First Campus(ECE), Link (membership). The leaders of these groups are keen to utilize the data to drive growth, deliver customer service, and create personalized experiences. The Data Architecture & Information Management Team will manage and govern the overall datasets of the organization and drive the execution of how the data will be collected, stored, processed and applied across these social enterprises (SEs). In this role you will work with various industries and most diverse datasets in Singapore.   Responsibility:  Define the overall data engineering and ETL frameworks across each SE for the CAO office. Working closely with data scientists and business analysts map out data requirements and data roadmap that will drive the analytical underpinnings for each SE work. Lead a team of 5-7 data engineers, defining the ETL tool kit, build ETL frameworks, manage the governance and SLA for each ETL deployment for analytical teams. Work closely with each SE tech heads and their external vendors in mapping out data fields and data transfer process.  Design, build, support and optimize new and existing data models and ETL processes. Develop and support the data pipeline to integrate new data from various data sources with emerging data technologies. Develop and manage the various dashboards for management decision and data visualizations. Define and manage SLA for all data processes and own data quality issues.   ","RequirementsPreferred qualification and skills:   Advanced degree in computer science, computer engineering, or other technical fields. 6-10 years’ experience having developed data engineering capabilities for large and complex franchises. Strong data modeling, schema design and SQL development skills. ETL/ELT implementation and data integration. Modern open source data visualization tools, eg. D3js, superset, plotly, leaflet,etc.  Big data platform development (Hadoop/Hive/Hbase/Spark, etc.) REST/Web API development and management. Hands-on experience in any modern programming language (Python or Java preferred). Design pattern, 12-factor app principle and modern cloud architecture. Self-motivated and proactive, willing to learn new things. Good communication skills and strong team player. "
/job/data-engineer-ntuc-link-abcc422cbdff6cbee3e26851b6204764,"The rapid adoption of technology and mobile devices have contributed to vast new flows of information which are larger in volume, faster in velocity, diverse in variety, and requires veracity of the information for use. This new type of information composed of structured and unstructured data, broadly known as big data (and combined with tools and platforms), if utilized well, could radically improve business performance.    As the organization embarks to become a data-driven organization, significant decisions and value generation will be based on the data that we capture and deploy. The 7 SE’s range in a broad scope of data from FairPrice (retail), Income (insurance), Unity (healthcare), FoodFare (F&B), LearningHub (training), First Campus(ECE), Link (membership). The leaders of these groups are keen to utilize the data to drive growth, deliver customer service, and create personalized experiences. The Data Architecture & Information Management Team will manage and govern the overall datasets of the organization and drive the execution of how the data will be collected, stored, processed and applied across these social enterprises (SEs). In this role you will work with various industries and most diverse datasets in Singapore.    Responsibility: ·       As a data engineer, you will be creating, writing and maintaining data transfer process and protocols for the data platform.  ·       Work closely with each SE tech heads and their external vendors in mapping out data fields and data transfer process.  ·       Design, build, support and optimize new and existing data models and ETL processes. ·       Develop and support the data pipeline to integrate new data from various data sources with emerging data technologies. ·       Develop and manage the various dashboards for management decision and data visualizations. ·       Define and manage SLA for all data processes and own data quality issues.  ","RequirementsPreferred qualification and skills:  ·       Advanced degree in computer science, computer engineering, or other technical fields. ·       6-10 years’ experience having developed data engineering capabilities for large and complex franchises. ·       Strong data modeling, schema design and SQL development skills  ·       ETL/ELT implementation and data integration ·       Modern open source data visualization tools, eg. D3js, superset, plotly, leaflet,etc.  ·       Big data platform development (Hadoop/Hive/Hbase/Spark, etc.) ·       REST/Web API development and management ·       Hands-on experience in any modern programming language (Python or Java preferred) ·       Design pattern, 12-factor app principle and modern cloud architecture ·       Self-motivated and proactive, willing to learn new things ·       Good communication skills and strong team player"
/job/data-center-electrical-engineer-singapore-google-asia-pacific-62750ba5cc51c95fadc3b2cc22769e45,"Company overview: Google is not a conventional company, and we don’t intend to become one. True, we share attributes with the world’s most successful organizations – a focus on innovation and smart business practices comes to mind – but even as we continue to grow, we’re committed to retaining a small-company feel. At Google, we know that every employee has something important to say, and that every employee is integral to our success. We provide individually-tailored compensation packages that can be comprised of competitive salary, bonus, and equity components, along with the opportunity to earn further financial bonuses and rewards. Googlers thrive in small, focused teams and high-energy environments, believe in the ability of technology to change the world, and are as passionate about their lives as they are about their work. For more information, visit www.google.com/careers. The area: Engineering & Operations Google is and always will be an engineering company. We hire people with a broad set of technical skills who are ready to take on some of technology's greatest challenges and make an impact on millions, if not billions, of users. At Google, engineers not only revolutionize search, they routinely work on massive scalability and storage solutions, large-scale applications and entirely new platforms for developers around the world. From Google Ads to Chrome, Android to YouTube, Social to Local, Google engineers are changing the world one technological achievement after another. The role: Data Center Electrical Engineer - Singapore Our thirst for technology is a part of everything we do. The Data Center Engineering team takes the physical design of our data centers into the future. Our lab mirrors a research and development department -- cutting-edge strategies are born, tested and tested again. Along with a team of great minds, you take on complex topics like how we use power or how to run state-of-the-art, environmentally-friendly facilities. You're a visionary who optimizes for efficiencies and never stops seeking improvements -- even small changes that can make a huge impact. You generate ideas, communicate recommendations to senior-level executives and drive implementation alongside facilities technicians. Additional Role Description: As a Data Center Electrical Engineer, you'll be involved in the development of complex electrical infrastructure - from site assessments and concept design, to construction projects and major modification and upgrade of existing infrastructure. You will also provide and prepare documents, including statement of work (SOW), total cost of ownership (TCO) analysis, concept designs, drawing markups, budgets, schedules, factory test and acceptance documents, final startup/commissioning reports and review and acceptance of as-built and submittals. Responsibilities: - Collaborate with the core team to understand, develop and update the data center electrical designs, starting from basis of design (BOD) to issue for constructions (IFC) documents for new data center project build-outs and major infrastructure upgrades to all levels of testing and commissioning works. - Manage all power system challenges during concept design, detailed design, procurement, bidding, manufacturing, delivery and installation on site. Identify and resolve issues raised by the cross-functional teams and various external stakeholders. - Generate scope of work for the equipment portions of major infrastructure upgrades based on project needs. Work with internal teams to update and document the configuration as it evolves. - Interface closely with the Global Commodities team, manufacturers and various global and local Engineering teams in order to deliver the electrical solutions needed for each project. - Update and maintain the internal design specifications, drawings and standards in accordance with the latest configurations and including all 'lessons learned' in relation to all equipment.","RequirementsMinimum qualifications: - Bachelor's degree in Electrical Engineering or equivalent practical experience. - 6 years of experience in a bid build environment for mission critical facilities. - Ability to travel domestically and internationally up to 30% of the time as required. Preferred qualifications: - Professional Engineering License. - 10 years of experience in bidding, designing, operating and commissioning of electrical distribution systems, from high voltage (HV) transformer to branch circuits. - Experience with power system analysis and engineering software packages. - Demonstrated knowledge of mechanical and control systems. - Master's degree in Electrical Engineering."
/job/big-data-security-engineer-addstones-sas-540c77673bfefe3bafdb880658498799,"GFI is an international IT services company, currently employing about 18,000 people Worldwide. GFI provides its clients with innovative, long-lasting industrial solutions to leverage performance from their information systems. We design and runs industrial platforms tailored to the economic and human considerations of its clients. • Management Consulting | Digital Transformation | Innovation • Operating over 20 countries • 2017 revenue of over 1,2 billion USD 48 years of existence.  In order to support our forthcoming businesses and technological challenges, we seek innovative and agile people sharing our mind set.  We are now looking for a Big Data Security Engineer to join our team in Singapore.","RequirementsContext: The Bank systems generate a significant amount of data. To realize and increase the benefits from this data, Big Data Technologies and Methodologies are becoming substantially more valuable to organizations across all industries. By leveraging emerging technology, new risks are introduced into the organization, which potentially requires additional controls, protective and detective, to secure the use of Big Data and their environments. For 2019, the Bank is looking to reduce the risks introduced by the adoption of the Big Data through the definition of controls & technologies and awareness trainings for the Big Data users (Analyst, Data Scientist, Data engineer, etc). Skills requirements:  Solid knowledge in Big Data architectures and technologies Good knowledge in the security technologies and modules in use for Big Data platforms Good knowledge in Information Technology Risk assessment methodologies Good Knowledge in the Data protection and governance for Big Data platform Good communication and advocacy skills, both verbal and written, with the ability to express complex technical issues in an easily understood manner. Ability to collaborate and communicate effectively and respectfully with both business-oriented executives and technology-oriented personnel in teams across the organization  Profile: - At least 4 years of experience in managing Big Data platform - Significant experience in designing secured Big Data platform"
/job/data-center-operations-engineer-mcits-technologies-6ae8ced77930ec68b3876e9127e84d5a,"Managed Services Provide 1st and 2nd Level incident/problem management, including ticket logging, problem identification, troubleshooting, resolution and escalation within agreed Service Level Agreement (SLA). Perform health and status monitoring of Systems inlcuding WAN, LAN, Wireless LAN Network using centralise fault and performance monitoring tools. Provide proactive health and status monitoring of server/system, storage, database, IP Telephony, security devices and application using centralised fault and performance monitoring tools. Perform basic server administration tasks including but not limited to creation of user accounts or resetting of passwords. The Individuals must interact with multiple parties and coordinate the recovery of system or network with the relevant vendors or support. Managed and work with agreed Service Level Agreement (SLA) with customers. Participate in UAT to ensure that new equipment/job function(s) are adhered to defined standards and specification. Facility Management Ensure Data Centre is operationally 24x7. Responsible for physical security of the Data Centre as defined in the Corporate Security Policy and standards Ensure Data Centre air conditioning units, lights and temperature are functional and within normal operational standards. Work as part of a team providing coverage on a 7 days a week, 24 hours per day (24x7) basis including public holidays, on a 12 hour rotating shift basis.   Remote Hand Service Provide vendor escorting service when in StarHub secured facilities. Provide basic cabling support like loose cable verification, connecting pre-laid cable – patching, etc. Provide visual checks and verifications of equipment (power cycle, equipment indicators, inspection of equipment, hardware reset). Provide basic checks on environmental conditions in the Data Centre. Provide basic data media loading/unloading to Tape Library using an enterprise backup application. Provide hardware parts replacement of systems (interface card & installation, slotting/removal of blades/line cards, movement of equipment). Assist in the labelling of Tape Media. Keep inventories of the movement of tape media using Tape Management System (TMS). Batch Job Management Ensure Daily Batch jobs for Billing and Revenue Collection are executed correctly and on time using a Enterprise Batch Scheduling tool. Monitor the progress of jobs execution and escalation to Application Support when necessary. Provide 1st Level Incident Management/Troubleshooting and act as point of contact with Banks and Merchants to resolve issues Ensure batch processing is on schedule and monitor all system and batch job status. Respond to all user enquries regarding system functionalities or billing and payment processing.     Tape Backup and Management Ensure daily tape backup are executed as scheduled and completed successfully. Provide 1st Level Incident Management/troubleshooting and escalate to engineering support when necessary. Provide backup jobs status/progress monitoring.  ","RequirementsQualification and Skills Minimum Diploma, preferable in Information Technology discipline, or equivalent required. Data Center Certified Professional , Cisco Certified Network Administrator (CCNA) with minimum 3-5 years hands-on experience in DC operations and/or network administration preferred. Applicant with minimum of 2-3 years Data Centre experience and supporting multi-vendor environment desirable. Experience in automated batch scheduler and enterprise data backup application desirable. Must be detailed oriented, highly organised and able to multi-task in an efficient manner. Knowledge of Sun Solaris, HP UX, MS Windows and Microsoft Office mandatory. Familiair with hardware/software components and terminology. Experience in analysing hardware and software problems and making quick and accurate diagnosis. Minimum of 2 years experience in Managed Services and Smart-Hand Services advantageous. Must be willing to work in a rotating shift and additional hours to support the team as required, including public holidays. Strong ethics, integrity and genuine concern for the needs of others. Must be a team player. Experience in customer support and interaction with corporate customers. Ability to workin a team environment, and also able to work under pressure with minimum supervision. Good initiatives, proactive with good command of spoken and written English."
/job/senior-data-engineer-jewel-paymentech-38ad00cacb9beddc5e5b4a206592fd8f,"As a Senior Data Engineer you will get to work on a wide range of problems using the cutting-edge technologies in Big Data and Data Science. You are required to translate Data Science and Machine learning based solutions into scalable code, and to develop innovative solutions to collect/cleanse/store/process data. In case you are very passionate about building high throughput, low latency, fault tolerant software then this position is for you.   To be successful in this role, you will need to: •               Analyze requirements and deliver solutions that meet requirements. •               Write code by using best software development practices. •               Produce code that meets security standards. •               Estimate timelines and deliver solutions within agreed timeline. •               Write clear & concise documentation for solutions/code. •               Contribute ideas within team to build better code. •               Continuously improve knowledge on new technologies. •               Excellent in English, both written and spoken.  ","RequirementsEducation & Experience which will be relevant •    Three or more years of relevant work experience. •     B.Sc., Masters, or equivalent experience in a quantitative field (Computer Science, Mathematics, Engineering, Artificial Intelligence, etc.). •    Knowledge in the use and application of Python to develop complex software. •    General machine learning techniques and technologies (e.g., Bayesian classifiers, regression techniques, graphical models, working with unbalanced data-sets) as well as applications (e.g., predictive analytics). •     NoSQL Database Programming/Development. •     Manipulation of various types of data; data cleaning, filtering, and pre-processing for example with text/images. •     Knowledge and experience in the use of cloud computing platforms (AWS/Azure/GCP/etc). •     SQL familiarity and database technologies (e.g., row versus column stores, in-memory DB, DB clustering, HA for DB). •     Familiarity and experience with Linux environments. •     Understanding batch (e.g., Apache Hadoop / Map Reduce) and stream processing approaches / frameworks (e.g., Apache Spark).   You’re a perfect fit us if you are •    A master problem solver, and able to use own initiative to develop suitable solutions. •    A strong communicator with the ability to convey information to others in a simple and unambiguous way. •    An innovative, original thinker approach to job responsibilities, methods and processes. •    An energetic person who can be trusted to get a job done.  "
/job/data-engineer-capgemini-singapore-51f97c3a7f16fb63685c1e2f26effbad,"Activities: • Industrialize data integration, data cleansing, data analytics programs or data management processes. • Contribute to the design, development, testing, deployment, performance in production and maintenance of the data-centric software including APIs, cloud-based architectures, libraries, toolbox. • Liaise with the Data Scientists, Architects, software developers, and business experts to understand how data needs to be converted, loaded, processed and presented. • Help the Data Architect to create an overview of the Data Lineage (from data flows, data transformations inside applications). • Provide clear documentation of the business rules embedded in the systems and potentially manage or help solving Data Quality issues. • Adapt to local context and tools provided by AXA’s entity as well as local entity development standards and IT landscape. Skills:  • Technical: Strong development skills - languages will depends on the entity but mainly python and Scala, Big Data experience (Spark, Hadoop Suite) Experience in Git, continuous integration and delivery. • Awareness on Data Management practices, including Data Lifecycle Management across Core IT & Big Data ecosystems as well as Data Privacy & Security constraints. • Knowledge in Data Modelling (including third normal form, star schema, data vault modelling methods). • Focus on end user and customer centricity, Strong oral and written communication skills, Passion for learning new tools, languages and frameworks, Fast adaptation to changing requirements, Strong problem-solving skills, able to work with minimal direct guidance, self-motivated and proactive, in a collaborative model, side by side with the business, Practical, hands on approach to get results. • Experienced in Cloud services & architecture. • Discipline in writing technical & non-technical documentation.","RequirementsActivities: • Industrialize data integration, data cleansing, data analytics programs or data management processes. • Contribute to the design, development, testing, deployment, performance in production and maintenance of the data-centric software including APIs, cloud-based architectures, libraries, toolbox. • Liaise with the Data Scientists, Architects, software developers, and business experts to understand how data needs to be converted, loaded, processed and presented. • Help the Data Architect to create an overview of the Data Lineage (from data flows, data transformations inside applications). • Provide clear documentation of the business rules embedded in the systems and potentially manage or help solving Data Quality issues. • Adapt to local context and tools provided by AXA’s entity as well as local entity development standards and IT landscape. Skills:  • Technical: Strong development skills - languages will depends on the entity but mainly python and Scala, Big Data experience (Spark, Hadoop Suite) Experience in Git, continuous integration and delivery. • Awareness on Data Management practices, including Data Lifecycle Management across Core IT & Big Data ecosystems as well as Data Privacy & Security constraints. • Knowledge in Data Modelling (including third normal form, star schema, data vault modelling methods). • Focus on end user and customer centricity, Strong oral and written communication skills, Passion for learning new tools, languages and frameworks, Fast adaptation to changing requirements, Strong problem-solving skills, able to work with minimal direct guidance, self-motivated and proactive, in a collaborative model, side by side with the business, Practical, hands on approach to get results. • Experienced in Cloud services & architecture. • Discipline in writing technical & non-technical documentation."
/job/data-engineer-grabtaxi-holdings-abf461f251534f876db9a2d23175cb6e," Build, deploy and manage big data solutions that can adequately handle the needs of a rapidly growing data driven company  Spearhead the development of systems, architectures, and platforms that can scale to the 3 Vs of Big data (Volume, Velocity, Variety)   Streamline data access and security to enable data scientists and analysts to easily access to data whenever they need to   Build out scalable and reliable ETL pipelines and processes to ingest data from a large number and variety of data sources   Maintain and optimize the performance of our data analytics infrastructure to ensure accurate, reliable and timely delivery of key insights for decision making     Lead the movement cleaning and normalizing subsets of data of interest as preparatory step before deeper analysis by the data scientists   Run Modern high performance analytical databases and computation engines like RedShift, BigQuery, Greenplum,Presto and others  ","Requirements  A degree or higher in Computer Science, Electronics or Electrical Engineering, Software Engineering, Information Technology or other related technical disciplines.   Experience in handling large data sets (multiple TBs) and working with structured, unstructured and geographical datasets   Designed high performance scalable infrastructure stacks for Big Data Analytics   Deep understanding of databases and best engineering practices - include handling and logging errors, monitoring the system, building human-fault-tolerant pipelines, understanding how to scale up, addressing continuous integration, knowledge of database administration, maintaining data cleaning and ensuring a deterministic pipeline   Real passion for data, new data technologies, and discovering new and interesting solutions to the company’s data needs   Excellent communication skills to communicate with the product development engineers to coordinate development of data pipelines, and or any new products features that can be built on top of the results of data analysis  "
/job/data-engineer-facebook-singapore-5c0cbba35308ed1b1cefe4e70801f488,"Are you passionate about data? Do you like working with big data? Do you want to use data to help drive the direction of products that impact the lives of over 800 million people every day? If yes, we want to talk to you! Data and associated analytics play a huge role in the success of Facebook. We have diverse business needs and very large-scale data. This makes it a wonderful and exciting challenge to provide scalable, actionable, reliable and timely data for our company.   In this role, you’ll see a direct link between your work, company growth, and user satisfaction. You’ll work with some of the brightest minds in the industry, work with one of the richest data sets in the world, use cutting edge technology, and get an opportunity to solve some of the most challenging business and engineering problems, at a scale that few companies can match. You will do so by partnering with (internal) stakeholders/teams and building scalable solutions that provide business critical insights and metrics, while ensuring the best uptime and responsiveness.   This is a full time position based in our office in Singapore.","RequirementsResponsibilties:   Manage data warehouse plans for a business vertical or a group of business verticals;  Partner with internal stakeholders to understand business requirements, work with cross-functional data and products teams and build efficient and scalable data solutions;  Build data expertise and own data quality for allocated areas of ownership;  Design, build, optimize, launch and support new and existing data models and ETL processes in production;  Conduct design and code reviews;  Define and manage SLA for all data sets in allocated areas of ownership;  Work with data infrastructure to triage infra issues and drive to resolution;  Manage the delivery of high impact dashboards and data visualizations;  Minimum Qualifications:  BS/B.Tech./M.Tech in Computer Science, Math or related field;  2+ years hands-on experience in the data warehouse space, custom ETL design, implementation and maintenance;  2+ years hands-on experience in SQL or similar languages and development experience in at least one scripting language (Python preferred);  Strong data architecture, data modeling, schema design and effective project management skills;  Excellent communication skills and proven experience in leading data driven projects from definition through interpretation and execution;  Experience with large data sets, Hadoop, and data visualization tools  Ability to initiate and drive projects, and communicate data warehouse plans to internal clients/stakeholders "
/job/data-engineer-honestbee-a330651fbfd55e72e33da59c6fff3b38,"As a Data Engineer at honestbee, you will be working alongside the brightest minds in the industry, solving some of the most challenging business problems using terabyte-scale of behavioural and transactional data. The solutions you create have a direct impact on millions of users in eight markets. What you'll be doing: - Be part of Asia’s strongest technology team in one of the world’s most exciting startups - Own, architect and scale honestbee’s bleeding-edge data platform  - Manage our data warehouse, OLAP, ETL systems, and data pipelines  - Contribute to further develop our best practices and innovation initiatives - Grow your skills and career in an environment that values continuous learning and personal development","RequirementsWho you are: - Experienced in Python development - Proficient in SQL, Shell Scripting or another languages - Experience working with cloud-based and distributed systems (E.g. AWS ecosystem, Google Cloud, etc..) - Experience with building real-time stream-processing systems (E.g.Kafka, Fluentd, etc) - Knowledge of NoSQL databases (E.g.Redis, Elasticsearch, etc) - 2 to 5+ years of experience with data modelling and designing/supporting Data Warehouses (E.g. Redshift, BigQuery, etc) - 1 to 3+ years of experience in data processing/ETL implementation - Familiar with gunicorn, nginx, deployment and scalability (E.g. Kubernetes, Mesos, Marathon, etc)"
/job/senior-data-engineer-thoughtworks-443ad7cb21097edb976947a1c864d995,"Singapore, SingaporeThoughtWorks Singapore is looking for talented engineers passionate about building large scale data processing systems to help manage the ever-growing information needs of our clients.    You will be responsible for -   Creating complex data processing pipelines, as part of diverse, high energy teams Designing scalable implementations of the models  Hands-on programming based on TDD, usually in a pair programming environment Deploying data pipelines in production based on Continuous Delivery practices Advising clients on the usage of different distributed storage and computing technologies from the plethora of options available in the ecosystem ","RequirementsIdeally, you should have -   5+ years of experience building and deploying large scale data processing pipelines in a production environment Production-level hands-on experience working on HDFS, Java MapReduce, Hive, Apache Spark, Oozie etc. Solid understanding of YARN, Mesos, MPP Databases, SQL-on-Hadoop solutions like Impala etc. Experience working with, or an interest in Agile Methodologies, such as Extreme Programming (XP) and Scrum Knowledge of software best practices, like Test-Driven Development (TDD) and Continuous Integration (CI) Strong communication and client-facing skills with the ability to work in a consulting environment is essential Senior developers (7+ years) are expected to be the Architect for small and large enterprise projects. On larger projects, you are expected to work closely with the fellow architects to come up with the architecture and take it further. Desire to contribute to the wider technical community through collaboration, coaching, and mentoring of other technologists  If you relish the idea of being part of a community that extends beyond the work we do for our customers, you may find ThoughtWorks is the right place for you. If you share our passion for technology and want to help change the world with software, we want to hear from you! To apply, please submit your CV and tell us why you want to join ThoughtWorks. We will ask you to write code as part of your interview process, so be prepared! Our recruiters will be in touch."
/job/data-center-support-engineer-servlink-technology-resources-7175b74b3afe2f9160b03e9bd778f5e1," Perform data daily walkthrough and update client shared database. Monitoring, update and closing of ticket via ticketing system with resolution summary. Using approved tools for incident and problem management, perform IMAC tasks when required. Support hardware replacement and Break-fix.  Restore on-site equipment back to working status. Media Management. Escort 3rd party vendor to all local data centers (during office hour & after office hour) Perform data center power up/down (PDU), preventive maintenance work on equipment. Manage onsite equipment and update relevant inventory systems. Compile relevant data and statistics for monthly reporting Other ad hoc data center activities as and when required. Other duties and job functions as may be instructed from time to time by the Company and may be transferred from one section to another at the sole discretion of the Company ","Requirements Min Diploma in IT or Computer Science or 1 - 2 years of relevant working experience  Required to work on permanent night shift (8pm - 8am), shift allowance will be given Working pattern (work 3 days, rest 3 days; work 2 days, rest 2 days) "
/job/data-center-engineer-techcom-solutions-asia-pacific-e2d23fa69f59f15f092b39e622c18c1d," 4+ years working experience in an Operations Centre (OCT), performing monitoring and issuing of commands to computers and IT equipment. Working experience of doing shift work would be highly preferred. OCT shall be on 12-hour shifts, performing day-shifts and night-shifts alternating with teammates in accordance to a shift pattern, with sufficient breaks. Alerts signalling abnormalities from various IT domains (e.g. applications, infrastructure, network, IT security) are centrally channelled to IOC. IOC is expected to monitor such alerts round-the-clock, and react accordingly, i.e. either escalate within SLA to the correct party who can resolve the issue, or execute well-defined instructions or procedures as prescribed or as instructed by domain experts. OCT is expected to execute well-defined routine operational instructions or procedures which are formulated by and handed over from various IT domains, in accordance to an approved daily schedule (which content might differ on different days and on different shifts). OCT is also expected to provide feedback on documents and update when assigned (periodically only), in order to keep them up-to-date. Able to read general IT instructions / procedures (in English) and execute accurately. [This part will be tested during interview session.]   ","Requirements 4+ years working experience in an Operations Centre (OCT), performing monitoring and issuing of commands to computers and IT equipment. Working experience of doing shift work would be highly preferred. OCT shall be on 12-hour shifts, performing day-shifts and night-shifts alternating with teammates in accordance to a shift pattern, with sufficient breaks. Alerts signalling abnormalities from various IT domains (e.g. applications, infrastructure, network, IT security) are centrally channelled to IOC. IOC is expected to monitor such alerts round-the-clock, and react accordingly, i.e. either escalate within SLA to the correct party who can resolve the issue, or execute well-defined instructions or procedures as prescribed or as instructed by domain experts. OCT is expected to execute well-defined routine operational instructions or procedures which are formulated by and handed over from various IT domains, in accordance to an approved daily schedule (which content might differ on different days and on different shifts). OCT is also expected to provide feedback on documents and update when assigned (periodically only), in order to keep them up-to-date. Able to read general IT instructions / procedures (in English) and execute accurately. [This part will be tested during interview session.]   "
/job/data-engineer-nec-corporation-cbbbf5fffe0ae23aedc84c16eadb476c,"The Innovation and Transformation Office (ITO) of Global Safety Division (GSD) leads disruptive idea generation, research, testing and prototyping with the goal of launching breakthrough products and services inspired by global trends and emerging technologies, contributing to a Safer City. We aim to take our deep technical and product expertise and develop innovative solutions that helps to transform businesses. This position is a good match for a passionate and technical leader who enjoys technical challenges and possess excellent communication skills. The successful candidate should preferably have a strong start-up mentality and experience, as well as proven track record within a cross-cultural multi-national corporation, delivering large mission critical solutions in the area of data science and machine learning. As a Data Engineer, you'll work closely with our customers to produce innovative and actionable quantitative models and analysis to address the challenges in the areas of Public Safety. The Innovation and Transformation Office (ITO) team is a catalysing force that crystalizes visionary concepts into proof-of-concepts (POCs) and prototypes that will bring real value to organizations. These solutions need to be scalable to support millions of customers worldwide.    Provide leadership in the areas of data analytics and modelling with a strong focus on Public Safety. Develop and deploy AI technologies for public safety. Manage machine learning projects, including writing functional and program specifications and documentation, data (structured and unstructured) acquisition from external and internal sources, data preparation (data cleaning, data mapping, data quantity and quality validation), identifying suitable machine learning algorithms to apply on the data sets, building machine learning model from the data, and tuning model parameters for enhanced performance. Develop processes and tools for evaluating the performance of machine learning algorithms and robustness of the models. Establish specific success criteria for selecting the best machine learning model to address a real-world problem. Perform system testing and user acceptance testing to validate the robustness and performance of the machine learning models. Mine and analyze data from company databases to drive optimization and improvement of product development, marketing techniques and business strategies. Design, build, test, validate, and deploy statistical and machine learning models to answer business needs and increase operational efficiency. Develop custom data models and algorithms to apply to data sets. Develop processes and tools to monitor and analyze model performance and data accuracy. Actively engage in the creation of new disruptive and transformational products and services through an understanding of the end user’s requirements and operating environment. Participate in the building and enhancement of a robust pipeline to support the automation of various development associated tasks to achieve continuous integration and delivery. Create Intellectual Property (IP) in the form of patents, publication of papers in the relevant areas that is tightly aligned to the strategic direction of the GSD. ","RequirementsEducation & Experience  Bachelor’s degree in Computer Science or Data Science (preferred). Or, Bachelor’s degree in any of Statistics/Mathematics/Technology plus a certification or rich experience in Machine Learning/Deep Learning/ETL. Minimum of 5 years of quantitative analytics experience with a focus on statistical modeling, Machine Learning, forecasting, optimization and/or predictive analytics. Experience in biometrics and facial recognition technologies is a plus.    Skill Requirements  At least 2 years’ relevant experience. Must have strong programming experience with Python and R. Experience in machine learning, deep learning, data visualization, statistical, text analytics libraries, jupyter notebook and/or frameworks in Python or R. Experience with data processing and data analytics. "
/job/senior-database-consultant-big-data-engineer-palo-singapore-1d231290ad1b00aef2b0266e339cdcd4,"Your profile & role on the project YOU:  Thrive on challenge. When was the last time you failed? Are curious & always learning. What are you up to right now? Can deal with constant change. When were you last surprised? Have mastered at least one skill of your trade but you’re not defined by it. What can you teach us? Can you wear many hats?  YOU AGAIN: The DevOps Architect will install, maintain, and support an on-premises cloud infrastructure and apply DevOps practices and solutions. The person will also implement cloud-related and DevOps technologies such as AWS/Puppet/Chef/Elk/Azure/Openstack. Other infrastructure related activities such as maintaining the company internal server infrastructure and respond to consultant requests when required will be expected.  Install, maintain, and support on-premises and off-premises cloud stack. Configure, maintain, and support the cloud-related infrastructures. Act as a system administrator on different OSes (e.g. RHEL, Opensolaris, Ubuntu, etc.) and help teams deploy their application and automate their development and releases on the cloud. Ability to develop solutions and self-learn new tools and technologies. Document, and share knowledge on developed DevOps solutions.  STILL YOU:  Unix / Linux / Bash knowledge Very good understanding of cloud computing (e.g. Technologies, Deployment, costing, HA/DR, etc.) Good understanding of DevOps principles (e.g. testing automation, BDD, TDD, Release automation, CI/CD, etc.) 2 years experience with cloud deployment (e.g. Openstack, VMWare, AWS, Azure, Terraform, etc.) 1 year experience with testing automation (e.g. Maven, Selenium, HP QC, LoadRunner) 1 year experience with release automation process (e.g. CA-RA, Jenkins, etc.) 1 year experience with Configuration Management (e.g. Ansible, SaltStack, Puppet/Chef, etc.) 1 year experience with monitoring tools (e.g. ELK, Prometheus, Grafana and Splunk) Experience with developing and implementing processes to handle releases from Development to Operations while respecting internal rules, and offering solutions for rollback) Experience with designing an architecture to implement development-to-production workflows. Knowledge of SRE, Containers, Kubernetes, Openshift is a plus. Good understanding of microservice architecture and DevOps practices that support. Strong RDMS and NoSQL skill in deploying and fine tuning such as MySQL, Oracle, Elasticsearch.  Your role at PALO IT You will be invited to take part in R&D works done within our Practices. You will have the chance to assist or be a speaker at must-attend international IT conferences. You will have the opportunity to write articles for our Blog or specialized press. Genuine ambassador of PALO IT, you will present our offers and take an active role in the development of the company.  Your technical environment # Cloud and DevOps based technologies (AWS/Puppet/Chef/Elk/Azure/Opencloud) # DevOps practices # Linux OS, Shell Scripting, SQL # Agile and scrum environment","Requirements✔     You hold a Bachelor, Master or PhD degree in IT, Information Management and/or Computer Science ✔     You are just graduated or have less than 3 years of working experience ✔     Good knowledge of big data technology landscape and concepts related to distributed storage / computing ✔     Experience with big data frameworks (e.g. Hadoop, Spark) and distributions (Cloudera, Hortonworks, MapR) ✔     Experience with batch & ETL jobs to ingest and process data from multiple data sources ✔     Experience with NoSQL databases (e.g. Cassandra, MongoDB, Neo4J, ElasticSearch) ✔     Experience with querying tools (e.g Hive, Spark SQL, Impala) ✔     Experience or willingness to go in real-time stream processing, using solutions such as Kafka, Flume and/or Spark Streaming ✔     You are passionate about technology and continuous learning comes naturally to you  "
/job/senior-database-consultant-big-data-engineer-palo-singapore-2d499a6a8a10936226fd9d712342007f,"Your profile & role on the project YOU:  Thrive on challenge. When was the last time you failed? Are curious & always learning. What are you up to right now? Can deal with constant change. When were you last surprised? Have mastered at least one skill of your trade but you’re not defined by it. What can you teach us? Can you wear many hats?  YOU AGAIN: The DevOps Architect will install, maintain, and support an on-premises cloud infrastructure and apply DevOps practices and solutions. The person will also implement cloud-related and DevOps technologies such as AWS/Puppet/Chef/Elk/Azure/Openstack. Other infrastructure related activities such as maintaining the company internal server infrastructure and respond to consultant requests when required will be expected.  Install, maintain, and support on-premises and off-premises cloud stack. Configure, maintain, and support the cloud-related infrastructures. Act as a system administrator on different OSes (e.g. RHEL, Opensolaris, Ubuntu, etc.) and help teams deploy their application and automate their development and releases on the cloud. Ability to develop solutions and self-learn new tools and technologies. Document, and share knowledge on developed DevOps solutions.  STILL YOU:  Unix / Linux / Bash knowledge Very good understanding of cloud computing (e.g. Technologies, Deployment, costing, HA/DR, etc.) Good understanding of DevOps principles (e.g. testing automation, BDD, TDD, Release automation, CI/CD, etc.) 2 years experience with cloud deployment (e.g. Openstack, VMWare, AWS, Azure, Terraform, etc.) 1 year experience with testing automation (e.g. Maven, Selenium, HP QC, LoadRunner) 1 year experience with release automation process (e.g. CA-RA, Jenkins, etc.) 1 year experience with Configuration Management (e.g. Ansible, SaltStack, Puppet/Chef, etc.) 1 year experience with monitoring tools (e.g. ELK, Prometheus, Grafana and Splunk) Experience with developing and implementing processes to handle releases from Development to Operations while respecting internal rules, and offering solutions for rollback) Experience with designing an architecture to implement development-to-production workflows. Knowledge of SRE, Containers, Kubernetes, Openshift is a plus. Good understanding of microservice architecture and DevOps practices that support. Strong RDMS and NoSQL skill in deploying and fine tuning such as MySQL, Oracle, Elasticsearch.  Your role at PALO IT You will be invited to take part in R&D works done within our Practices. You will have the chance to assist or be a speaker at must-attend international IT conferences. You will have the opportunity to write articles for our Blog or specialized press. Genuine ambassador of PALO IT, you will present our offers and take an active role in the development of the company.  Your technical environment # Cloud and DevOps based technologies (AWS/Puppet/Chef/Elk/Azure/Opencloud) # DevOps practices # Linux OS, Shell Scripting, SQL # Agile and scrum environment","Requirements✔     You hold a Bachelor, Master or PhD degree in IT, Information Management and/or Computer Science ✔     You are just graduated or have less than 3 years of working experience ✔     Good knowledge of big data technology landscape and concepts related to distributed storage / computing ✔     Experience with big data frameworks (e.g. Hadoop, Spark) and distributions (Cloudera, Hortonworks, MapR) ✔     Experience with batch & ETL jobs to ingest and process data from multiple data sources ✔     Experience with NoSQL databases (e.g. Cassandra, MongoDB, Neo4J, ElasticSearch) ✔     Experience with querying tools (e.g Hive, Spark SQL, Impala) ✔     Experience or willingness to go in real-time stream processing, using solutions such as Kafka, Flume and/or Spark Streaming ✔     You are passionate about technology and continuous learning comes naturally to you  "
/job/data-engineer-microsec-25cd0d5ffef2fd9be93c58763bc96425,"Responsibilities: 1. Developing, enhancing, automating, and managing analytics models for anomaly detection. 2. Run those models into production environment with static as well as distributed databases. 3. Exploring and evaluating new digital tools and techniques to improve the product’s operational capabilities 4. Provide engineering support of key testing activities, including support of laboratory and field testing activities Outcome: The candidate will get to work on the state of the art intrusion attacks and how to prevent them. As a startup company, the candidate will get to work on wide domain of technologies which will increase the breadth of the experience of the candidate. This will provide an insight information about the industry trend and will groom the candidate for future prospects.","RequirementsRequirements: At least 2 year of experience in Python, Unix/Linux with machine learning tools including Tensorflow, LSTM and other models. Should have designed and built at least one system from ground up and made it into an application. Should also have experience in building APIs and using it for application integration along with Visualization tools using Python based production environment."
/job/senior-data-research-engineer-titansoft-2a1269ac23a2fa6f8d993d86db70e47e,"Our research team at Titansoft focuses on Human Behaviour Imitation, Artificial Intelligence, and Probability Theory including, but not limited to, feedback control, algorithms, automatic processing, and machine learning models with the overall goal of building an automation system. We are looking for a Senior Data Research Engineer who shares a deep passion for machine learning programming and embrace the idea of teamwork. If you feel strongly about AI areas, then we definitely want to speak with you.  ","RequirementsQualifications Minimum Degree in Computer Science, Math, Physics, Engineering, Statistics or other technical fields. Experiences  Prior experience or course work in analytics and data mining, with focus on segmentation strategies and predictive models. Extensive programming experience with either Python, R, C# or other programming languages. Knowledge and experience in at least one of three of the following: Keras, Tensorflow and Pytorch. Demonstrated history of building prototypes for an AI project. Experience with AI / Machine Learning product or Kaggle Experience with multi-threaded design and parallel / distributed computing Working knowledge of C# and SQL  Skills  Systematic problem-solving approach, coupled with strong communication skills. Have strong algorithms/data structure knowledge Ability to understand complex systems Strong business sense and logical skills to balance data-driven decisions with intuition desire and capacity to learn, develop and lead the team. "
/job/data-research-engineer-titansoft-3d6111d96157c9a00507bd1fc9cf4796,"Our research team at Titansoft focuses on Human Behaviour Imitation, Artificial Intelligence, and Probability Theory including, but not limited to, feedback control, algorithms, automatic processing, and machine learning models with the overall goal of building an automation system. We are looking for a Data Research Engineer who shares a deep passion for machine learning programming and embrace the idea of teamwork. If you feel strongly about AI areas, then we definitely want to speak with you.  ","Requirements Minimum Degree in Computer Science, Math, Physics, Engineering, Statistics or other technical fields. Knowledge and experience in at least one of these: Keras, Tensorflow or Pytorch. Strong knowledge and experience in Python. Strong knowledge of algorithm design.  To succeed in this role, it will be good to have:  Experience with an Artificial Intelligence or Machine Learning product or Kaggle. Knowledge in SQL or other programming languages. Contributions to open source projects. Familiarity with multi-threaded design and parallel or distributed computing. Working knowledge on C#. "
/job/technical-big-data-security-engineer-keyteo-consulting-dcb2608aa088d095a1473874285d0a74,"Our Company:  Founded in 2014, Keyteo Consulting is a company specialized in organization and information system management in financial and banking environments that work with its clients as they outsource their projects in innovation, as well as research and development. Our purpose is to improve the innovation, competitiveness and performances of our clients. We contribute to all the key steps in our clients’ project lifecycles, from an analysis of the needs through implementation and industrialization.  Keyteo Consulting offers strategic, operational and technological solutions intended to accompany clients as they carry out their projects, by providing complete expertise. Keyteo Consulting is strongly dedicated to sustain the strong growth of companies specializing in key sectors such as banking/finance and others.","RequirementsSkills & Competencies requirements: i. Solid technical knowledge in Data discovery technologies and process ii. Solid technical knowledge in security technologies and modules in use for Big Data platforms iii. Good knowledge in Information Technology Risk assessment methodologies iv. Good Knowledge in the Data protection and governance for Big Data platform v. Good communication and advocacy skills, both verbal and written, with the ability to express complex technical issues in an easily understood manner. vi. Ability to collaborate and communicate effectively and respectfully with both business-oriented executives and technology-oriented personnel in teams across the organization Experience and Qualifications requirements: i. At least 4 years of experience in implementing Security technologies for Big Data platform ii. Significant experience in running comparative study for security technologies and deployment of proof of concepts iii. Holder of information Security Certificate in Big Data technologies is preferable"
/job/data-platform-engineer-8f859201827cc192dffeea3e4271b2b3,"UCARE. AI'S team of data scientists and technologists came together with one mission: to use data ethically to solve real world problems and improve lives by creating the most advanced artifical intelligence capable of making accurate predictions years into the future. We are looking for 3 top-notch Python Hackers, who are well-versed in Python, hand-crafting our high performance data platform and AI engine (AlgoServer) and fine-tuning our proprietary algorithms (AlgoPacks) working side-by-side with our data scientists.  Your primary focus will be the on-going development and the enhancement of our data infrastructure, ingesting and analyzing ""big data"" across myriad of data sources, including our frontend mApp. You also will be working closely with senior data scientists to deliver proprietary algorithms running at scale across our data platform sitting on top of Spark. Duties and responsibilities:  Writing modular, scalable and efficient code jointly developed with senior tech team on agreed architecture. Implementation of security and data protection while ingesting and analyzing ""big data"" Real-time integration of various data sources, ingestion (ETL- extract, transform and load) of data through our data pipes, and execution of algo packs delivering insights back to client's systems. Liaising with frontend developers/vendors to support the backend data platform. Create and maintain software documentation. ","Requirements Preferred background in Computer Science, Computer Engineering or related disciplines. 1-4 years of relevant working experience, especially in large-scale production environment.  Fresh graduates with strong Python skills are encouraged to apply. Excellent prgramming skill in one or more scripting languages.  Python (must), Scala, Java, JavaScript. Understanding of the threading limitations of Python. and multi-process architecture. Background in machine learning is advantageous.  Additional experience in Node JS and React Native would be great (but not necessary). Experience in any one of the following field is highly preferred: (i)cloud computing platform (ii) database management (No SQL preferred) (iii) distributed computing/lambda architecture (iv) Sparks and HDFS Prior startup or entrepreneurial experience would be a bonus Can-do attitude "
/job/data-engineer-integration-specialist-changi-airport-group-d216fafc5067577a57f35ff1fde33ae8,"An exciting opportunity is waiting for you in the newly set up Digital Factory, who will spearhead the digital transformation efforts of Changi Airport Group. You will be working on Commercial and Operational digital applications and projects that will transform our business and bring customer experience to greater heights. You will be working in squads with fellow enthusiasts, re-imagining how we serve our connected customers. As a digital disrupter, you’ll focus on building the data foundations for Changi’s existing / new digital products. You will be responsible for the below areas:  Define the data models and data layer for new applications Identify opportunities to match, merge or blend data from multiple systems Identify and analyse data discrepancies and data quality issues and work to ensure data consistency and integrity Plan activities to ensure data quality is in line with the standards set by the organisation Optimize, develop and maintain integration solutions using Informatica ETL/MDM and ETL Framework (BIDS) as necessary to connect legacy data stores, the data warehouse, and third-party platforms Ensure the stabilization and high performance of existing ETL processes Troubleshoot any complex data-related issues as well as provide support to production Solution, design, develop and deploy ETL job workflow with reliable error/exception handling and rollback Drive process improvement and improve process efficiency Document all ETL and data warehouse processes and flows Communicate issues, risks and concerns proactively to management Adopt the agile approach: Develop, test, analyze and iterate the applications with the end objectives and key results in mind ","Requirements Bachelor's degree in Computer Science, Engineering or related discipline 4-6 years in-depth knowledge and experience of ETL development and Informatica ETL and MDM stack 4-6 years in-depth knowledge and experience of T-SQL development, debugging and optimization Experience with Netezza Database/Oracle Database a plus Experience with working collaboratively with cross-functional teams including engineering, product management and user research   "
/job/data-engineer-orica-international-a6afa6b4ba52dfdb024217fcb0b4eba0,"Orica is seeking a bright and motivated individual to join our Data Science team. The candidate's primary responsibility will be to provide analytics services for the digital hub initiatives to help improve and monitor product reliability and operational efficiency. This will include developing insights from diverse data sources and creating platforms to make these insights actionable for key stakeholders.   The successful Data Engineer will propose creative Data Science solutions to problems faced by various groups at Orica, evaluate those solutions, and then work with the team to develop and deploy those solutions.   RESPONSIBILITIES    Perform large-scale data analysis and develop effective statistical models for segmentation, classification, optimization, time series, etc. Uses analytical platforms such as R and Python to model complex systems and derive actionable insights. Design and implement reporting dashboards that track key business metrics and provide actionable insights. Works with the team to review, analyse, and develop solutions for operational leaders. Work closely with both business units and engineering teams to formulate measurement problems and associated technical solution strategies Work closely with engineering and product management teams to build tools and applications on our unique big data platform to efficiently generate and deploy insights into decision-making systems at Orica. ","Requirements An advanced degree (Masters or PhD) in statistics, mathematics, computer science, engineering or scientific field Proficiency with statistical analysis tools to include: R, SAS, SPSS Proficiency with software development technologies to include: Python, C++, Java Knowledge of machine learning tools, basic statistics, data visualization techniques and databases (SQL) to Perform large-scale data analysis and develop effective statistical models for segmentation, classification, optimization, time series, etc. Excellent verbal and communication skills, ability to explain predictive analytics to non-technical audience Interface with Engineers, Product Managers and Product Analysts to understand product goals and data needs Build data expertise and own data quality for allocated areas of ownership Numerical skills with the ability to think logically and practically to deal with complexity. Ability to:   Work in a fast-paced environment Promptly recognize emerging problems and identify potential solutions Deliver high-quality results on time   "
/job/senior-data-engineer-dataspark-d165fec9f2768af3e28feec4dfe6f4d3,"Responsibilities  design and implement scalable and robust software platform for ingesting and transforming telco network datasets in (near) real-time using a variety of open-source and proprietary Big Data technologies recommend and implement ways to improve data reliability, efficiency and quality collaborate with product management, sales and marketing, and solution delivery teams to support the objectives that customer requirements are well managed and reflected in product releases support the deployment of DataSpark software within clients' IT environment working closely with stakeholders to ensure high standards of data governance during implementation serve as technical subject matter expert in latest big data technologies ","RequirementsRequirements  7+ years of superior software development experience building commercial large-scale software systems and database systems Excellence in algorithms, data structure, discrete math, data base and data warehousing Expert knowledge in data management technologies and software engineering tools to efficiently process large volume of data Demonstrated clear and thorough logical and analytical thinking, as well as problem solving skills Experience of data warehouses in excess of 10TB Experience of Web UI, middle tier, and data back end development Production coding experience in choice of programming languages and development frameworks Proven professional experience in processing large-scale commercial data. Experience with telco data a plus. Superior and proactive communications skills, including verbal, written, and presentation. A proven team player and contributor. Self-directed, ability to work independently and research innovative solutions to business problems Aptitude of working on multiple projects in parallel Attention to details and data accuracy MS or BS degree in Computer Science/Engineering, Statistics, Mathematics, or equivalent is required for this position. "
/job/data-quality-engineer-alphatech-business-solutions-6e7dd9f9380e41c9fc9fe4887a078696, Evaluate and recommend solutions via data analysis regarding issues related to the improvement of product qua;oty and resolving of customer feedback Apply software and programming abilities to manage and analyse data from a variety of sources ,"Requirements   Must know JAVA8 and SPARK Experience in distributed data architecture Have working knowledge of SQL, Python, Airflow Scala, Hadoop, SPARK Good to know CI/CD Experience (Jenkins Github), AWS, Kubernetes, Docker Preferred to have banking domain experience "
/job/research-associate-national-university-singapore-3221d10d99d0b258bc2f476978aa8e9f,"A Research Associate position is immediately available at the Institute of Data Science, National University of Singapore, in the areas of Data Mining and Machine Learning. The position involves developing and maintaining state-of-the-art data science and machine learning platforms and applications for the institute, and working with data science researchers to conduct research and development on state-of-the-art data science projects in collaboration with industry partners. The job scope includes data preparation and cleaning, designing and implementing of scalable and effective algorithms and methods in data mining, machine learning and artificail intelligence, performing empirical study on real-world data, developing applications and visualization demos etc.   The successful candidate will be a hands-on data engineer with solid coding and application development skills and experience, with a passion and pride to write robust, readable, and reusable code components and applications. He/She should be familiar with at least one ML library/framework, and have up-to-date knowledge in the latest cloud computing and other big data technologies. He/She should also have excellent interpersonal communication skills for working closely with internal and external collaborators to implement data science applications.  Prior R&D exposure would be a plus.","Requirements- Master's degree in computer science or related disciplines - More than 2 Years of experience, industry experience would be a plus - Programing language: Python, R, JAVA or C++ - Knowledge and experience in database management and machine learning algorithms - Knowledge and experience in GPU-based computation would be a plus - Experience with various data analysis and visualization tools and big data computing platforms - Experience in developing and deploying machine learning algorithms including deep learning - Experience in Ux design - An independent and self-driven worker and a fast learner - Well-organized and has an eye for details - Excellent written and verbal communication skills"
/job/big-data-engineer-d9dec34e1ae3d1b6df34ccf43fb87c9b,"The Big Data Engineer will execute master data management policies developed by the data architect and perform the data quality evaluations. He/She is required to work closely with business representatives to improve the quality of data to the required levels.   Responsibilities  Responsible for the integration of large, structured and unstructured data volumes into the cloud platforms Development of scalable end-to-end data pipelines for batch and stream processing Execution of the datalake integration workflow and activities for populating the data lake and integrating diverse data sources Execution an further development of the physical implementation of the logical data model into a physical implementation in the data lake Implementation of solutions for reference data and master data management within the context of the mobility data business Execution of data quality measurements and implementation of data quality improvement activities to the required levels of data quality Support of build-up and maintenance of a data directory for all data relevant to the mobility data business Representation of the Data Architecture team in selected data architecture, data modelling, and metadata management work teams inside Mobility   ","Requirements Diploma or University degree in an appropriate area (e.g. informatics) Relevant work experience Experience with data ingestion tools like Nifi, Streamsets, Node Red Experience with modern big data technologies like Hadoop, MapReduce, Kafka, Hive, Presto, Spark, Storm Experience with cloud solutions like AWS, Azure Experience with programming languages like R, SQL, Scala, Python, Java Experience with NoSql and traditional databases like Mongodb, MSSQL, Hadoop Experience with enterprise application integration and with approaches in one of the leading tool suites (e.g. Kibana, Solr, ElasticSearch, R, Python) Strong technical design and analysis skill Creativity and lateral thinking Ability to deal with ambiguity and work in fast paced environment Deep experience supporting mission critical applications quickly Excellent communication skills, both through written and verbal channels Excellent collaboration skills to work with multiple teams in the organization Ability to understand and adapt to changing business priorities and technology advancements Strong knowledge and technology trends in implementing of Big data ecosystem Strategic thinking and critical problem solving skills "
/job/data-engineer-leadbook-995d39b7e98f157a50df98d041569510,"Data Engineer If you are a data science and python enthusiast who likes to build best-in-class python crawlers and data processing pipe, we are interested in you. Leadbook.com is a global leader in customer intelligence. Leadbook helps sales team discover new opportunities, build targeted lists in seconds and gain deep insights about their prospects and customers. Responsibilities:    * Design and develop a highly scalable, data crawlers to extract large volumes of data from www.    * Wrangle the raw data to get cleaned, normalized, and enriched datasets using transformations, normalization and mapping.    * Work in Agile / Scrum environments with remote team    * Develop creative ideas on how to work better and smarter.","RequirementsQualifications: 2 years of tangible Python development experience Excellent English communication skills both spoken and written Develop clean, elegant, well-commented, and reusable code with version control (Git) Degree in Computing or equivalent"
/job/data-engineer-rakuten-asia-b6cd750d78ac8eb52fe762130f97b186," Implement cutting-edge data infrastructure platform which is vendor unlocked and multi-tenant. Implement and manage robust ETL pipeline based on streaming. Implement easy-to-use generalized data accessing layer by leveraging the details of storage engine. Implement distributed machine learning pipeline by coordinating with data science team. Develop data driven culture for integrated partners. Propose new technologies, tools to improve whole process of data system integration. ","RequirementsMust have  Bachelor degree or higher in Computer Science or related field. Experience in at least one language for web backend application & data processing, such as Java, Python, etc. Experience in NoSQL database, such as Redis, Solr, MongoDB, etc. Experience in Linux system operation, ability to manage system level task such as monitoring and troubleshooting your deployed applications. Good communication skills, ability to work in fast pace R&D. High motivation for learning, skill up, system ownership and contribution to the team.  Must have for Senior position  3+ years of experience in developing large scale data processing platform of various unstructured data. 3+ years of experience in using various big data frameworks and NoSQL databases, such as Hadoop, Kafka, Redis, Solr, etc. Practical knowledge of web system performance tuning including OS, middleware, I/O and application.  Good to have  Experience on cloud computing service, such as AWS. Experience in handling multilingual data. Knowledge in data science domains, such as NLP, Data Mining, and Deep Learning will help your collaboration with the data scientists. "
/job/data-visualisation-engineer-8a1a2ec41c135c42eabd062ad3c83471,"If you have a passion for data analytics, and wants to make an impact by designing and building visually intuitive, information-rich data products, this is your opportunity. In this position, you will be a torchbearer for data visualisation and UI design, and the incredible results it brings in organizations.   Responsibilities  Shape our data visualisation and UI design consulting business by leading business development efforts and consulting projects Gathering and documenting client requirements and translating these into process and UI architecture designs Providing thought leadership and actively participating in the application design, implementation, and roll-out of the solutions Act as a trusted advisor for data visualisation solutions and services for our clients and prospects Design and develop eye-catching data visualisation demos and storylines, adding to and expanding the services Spearhead the evangelisation of and demonstrate the power of data visualisation and UI design by teaching, leading community activities and by building reusable assets ","Requirements Relevant data visualisation and UI design experience (i.e. visualising complex data, designing data-rich user interfaces, data-driven design and development of charts, dashboards and infographics etc.), ideally in a consulting function Result oriented self-starter, with an ability to lead and mentor other team members Experience in designing, building, deploying and maintaining scalable, highly available and performance optimized data visualization solutions for enterprise Combine an analytical and creative approach to problem solving and have business strategy skills to ask the right questions and find the right answers to build the solutions necessary Be a clear, confident and persuasive communicator, with excellent presentation skills and with the ability to structure a coherent, logical argument and the confidence to defend assumptions, projections and recommendations Strong client communication and consulting skills. Should be able to lead conversations across all levels of an organization Ability to understand and challenge constraints, and recommend alternative choices Solid understanding of analytical data applications, open source solutions, and technologies, e.g. Elastic Stack, Solr, R, etc. A passion for data visualisation and a keen design sense, with an eye for what makes a visual design aesthetically pleasing and intuitive to use Understanding of Design Thinking "
/job/required-data-centre-engineer-12-months-contract-path-infotech-7616f787bea6fc4c9d046896a7879562,"5 Years working experience in Operation Centre/Data Centre Performing monitoring and issuing of commands to computers and IT equipment’s Working experience of doing shift work would be highly preferred OCT shall be on 12 hours shifts ,performing day shifts and night shifts Alerts signalling abnormalities from various IT domain (eg application, Infrastructure ,network IT Security) are channelled to IOC. IOC if expected to monitor such alerts round the clock and react accordingly i.e OCT is expected to execute well defined routine operational instructions or procedures which are formulated by handed over from various IT domain.","Requirements5 Years working experience in Operation Centre/Data Centre Performing monitoring and issuing of commands to computers and IT equipment’s Working experience of doing shift work would be highly preferred OCT shall be on 12 hours shifts ,performing day shifts and night shifts Alerts signalling abnormalities from various IT domain (eg application, Infrastructure ,network IT Security) are channelled to IOC. IOC if expected to monitor such alerts round the clock and react accordingly i.e OCT is expected to execute well defined routine operational instructions or procedures which are formulated by handed over from various IT domain."
/job/data-center-engineer-techcom-solutions-consultancy-de3140d8875464b26482d29c4a96ff78," 4+ years working experience in an Operations Centre (OCT), performing monitoring and issuing of commands to computers and IT equipment. Working experience of doing shift work would be highly preferred. OCT shall be on 12-hour shifts, performing day-shifts and night-shifts alternating with teammates in accordance to a shift pattern, with sufficient breaks. Alerts signalling abnormalities from various IT domains (e.g. applications, infrastructure, network, IT security) are centrally channelled to IOC. IOC is expected to monitor such alerts round-the-clock, and react accordingly, i.e. either escalate within SLA to the correct party who can resolve the issue, or execute well-defined instructions or procedures as prescribed or as instructed by domain experts. OCT is expected to execute well-defined routine operational instructions or procedures which are formulated by and handed over from various IT domains, in accordance to an approved daily schedule (which content might differ on different days and on different shifts). OCT is also expected to provide feedback on documents and update when assigned (periodically only), in order to keep them up-to-date. Able to read general IT instructions / procedures (in English) and execute accurately. [This part will be tested during interview session.] ","Requirements 4+ years working experience in an Operations Centre (OCT), performing monitoring and issuing of commands to computers and IT equipment. Working experience of doing shift work would be highly preferred. OCT shall be on 12-hour shifts, performing day-shifts and night-shifts alternating with teammates in accordance to a shift pattern, with sufficient breaks. Alerts signalling abnormalities from various IT domains (e.g. applications, infrastructure, network, IT security) are centrally channelled to IOC. IOC is expected to monitor such alerts round-the-clock, and react accordingly, i.e. either escalate within SLA to the correct party who can resolve the issue, or execute well-defined instructions or procedures as prescribed or as instructed by domain experts. OCT is expected to execute well-defined routine operational instructions or procedures which are formulated by and handed over from various IT domains, in accordance to an approved daily schedule (which content might differ on different days and on different shifts). OCT is also expected to provide feedback on documents and update when assigned (periodically only), in order to keep them up-to-date. Able to read general IT instructions / procedures (in English) and execute accurately. [This part will be tested during interview session "
/job/data-engineer-abakus-ec80cf4678d1bf50b66a251f06283161,"To reinvent an industry, you need to build an all-star team. Join Wecash if you want to realise a world of better living through responsible credit, by developing and promoting products that provide businesses with comprehensive and accurate evaluation of consumer credit worthiness as well as underwrite loans between funding sources and consumers. Wecash leverage upon the power of mobile technology, big data and machine learning to prevent fraud and determine consumer credit worthiness. Wecash started in 2014 and has since raised more than US$200 million in financing, acquired over 100 million users and processed more than US$5 billion in loans in 2017 alone. Wecash is creating a platform for financial products for the financially underserved utilizing artificial intelligence, big data and mobile technology. At Wecash, we move really quickly, get stuff done, and are constantly iterating. We are looking for a data engineer to support our expansion in Southeast Asia who will collaborate with the Data Science team to streamline our data products for analytics, operation and research. The candidate should be proactive and willing to keep-up with cutting-edge technologies. Responsibilities:  Develop, deploy and maintain machine learning models Design simulation and testing frameworks for model validation Identify, collect and organize new data sources Research on new technologies for efficient data management   ","Requirements Degree in Computer Science/Mathematics/Statistics/Physics, or related fields Proficiency in Python, SQL and Linux shell with minimum 1 year of hands-on experience Experience in statistical modelling Knowledge in Web Frameworks and RESTful APIs Knowledge in Version Control and Continuous Integration tools Willing to learn, innovative, good communication skills and team player  Bonus Skills  Working experience in NoSQL Working experience in Machine learning Ability to communicate in Mandarin or Bahasa Indonesia or other Asian language to communicate with counterparts in China, Indonesia and other APAC offices. "
/job/data-engineer-observational-pragmatic-research-institute-25e186a613429a46f1cf306ce5478751,"The Company OPRI is an academic research institution striving to improve the lives of patients through global research. OPRI has been leading the paradigm shift in real world evidence for the past 12 years, by delivering pragmatic clinical trials, disease registries and database research. The Role We are looking for a Data Engineer to work alongside our research, statistical and database teams in the UK, Singapore and Australia (Brisbane). In this position you will gain invaluable experience within an internationally recognised research organisation involved in analysis and dissemination of data from large-scale observational studies and pragmatic randomised controlled trials. The successful candidate will have high attention to detail, strong time management skills, and most importantly experience in the management and engineering of relational databases. Your responsibilities  Design, construct, install, test and maintain data collection and management systems:     Integrate data management technologies and software engineering tools for custom data collection applications Programming knowledge: Employ a variety of languages and tools (e.g. scripting languages) to combine systems together Ensure seamless integration of data across multiple databases       SQL, queries   Building APIs for data consumption Integrating external or new datasets into existing data pipelines Continuously monitoring and testing the system to ensure optimized performance   Build and maintain data collection platforms for specific organisational projects     Set up automated integration processes for Patient Reported Outcomes into various data collection platforms   EMR/EDC integration with Registry Database     Data collected via Registry EDCs to be uploaded into EMRs Data collected via site specific EMRs/EDCs to be uploaded into Registry EDCs    The role is for a permanent full-time position. Salary is dependent on qualifications and experience. Immediate start is available.","RequirementsQualifications  Bachelor degree in Computer Science, Engineering, Maths or equivalent qualification  Required Experience  Strong working knowledge of SQL (Essential) Experience working with large databases  Preferred Experience  Experience of developing and maintaining data dictionaries for databases Knowledge of statistical analysis tools (e.g. R, STATA, SPSS, SAS) Interest and knowledge of epidemiology, public health and clinical research "
/job/data-engineer-ninja-logistics-e3e85a4ec5ef7433d78457b22da2085e,"  Design, develop and maintain Ninja Van’s infrastructure for streaming, processing and storage of data. Build tools for effective maintenance and monitoring of the data infrastructure.   Contribute to key data pipeline architecture decisions and lead the implementation of major initiatives.   Work closely with stakeholders to develop scalable and performant solutions for their data requirements, including extraction, transformation and loading of data from a range of data sources.   Develop the team’s data capabilities - share knowledge, enforce best practices and encourage data-driven decisions.   Develop Ninja Van’s data retention policies, backup strategies and ensure that the firm’s data is stored redundantly and securely.   Tech Stack   Data storage: Percona XtraDB Cluster, Elasticsearch, Apache Cassandra   In-Memory data grid: Hazelcast   Real-time data pipeline: Apache Kafka   Backend webservice stack: Play (Java 8), GoLang, Node.js   Web frontend: AngularJS, React   Mobile: Android SDK, React Native   Containerization: Docker on Kubernetes  ","Requirements  Solid Computer Science fundamentals, excellent problem-solving skills and a strong understanding of distributed computing principles.   At least 3 years of experience in a similar role, with a proven track record of building scalable and performant data infrastructure.   Expert SQL knowledge and deep experience working with relational and NoSQL databases (e.g. HBase, Cassandra).   Advanced knowledge of Apache Kafka and demonstrated proficiency in Hadoop v2, HDFS, MapReduce.   Experience with stream-processing systems (e.g. Storm, Spark Streaming), big data querying tools (e.g. Pig, Hive) and data serialization frameworks (e.g. Protobuf, Thrift, Avro).   Bachelor’s or Master’s degree in Computer Science or related field from a top university.  "
/job/data-engineer-grabtaxi-holdings-189dd8637b4193915e4a37247baa461c," Build, deploy and manage big data solutions that can adequately handle the needs of a rapidly growing data driven company  Spearhead the development of systems, architectures, and platforms that can scale to the 3 Vs of Big data (Volume, Velocity, Variety)   Streamline data access and security to enable data scientists and analysts to easily access to data whenever they need to   Build out scalable and reliable ETL pipelines and processes to ingest data from a large number and variety of data sources   Maintain and optimize the performance of our data analytics infrastructure to ensure accurate, reliable and timely delivery of key insights for decision making     Lead the movement cleaning and normalizing subsets of data of interest as preparatory step before deeper analysis by the data scientists   Run Modern high performance analytical databases and computation engines like RedShift, BigQuery, Greenplum,Presto and others  ","Requirements  A degree or higher in Computer Science, Electronics or Electrical Engineering, Software Engineering, Information Technology or other related technical disciplines.   Experience in handling large data sets (multiple TBs) and working with structured, unstructured and geographical datasets   Designed high performance scalable infrastructure stacks for Big Data Analytics   Deep understanding of databases and best engineering practices - include handling and logging errors, monitoring the system, building human-fault-tolerant pipelines, understanding how to scale up, addressing continuous integration, knowledge of database administration, maintaining data cleaning and ensuring a deterministic pipeline   Real passion for data, new data technologies, and discovering new and interesting solutions to the company’s data needs   Excellent communication skills to communicate with the product development engineers to coordinate development of data pipelines, and or any new products features that can be built on top of the results of data analysis  "
/job/data-centre-engineer-operator-itcan-a864322e752c5980eb08977bbe744d8c," Ensure tasks in Ops daily checklist are being carried out in a timely manner Coordinate Data Centre incidents, maintenance and shutdowns Coordinate incident management Accountable for any emergency and logon id accounts, issue or use it according to instruction and procedure given and record its usage during the shift Control of keys kept with operations and record its usage Accountable for all physical security access cards available in the Data Centre   Responsible for equipment movement in Data Centre Coordinate preventive maintenance for hardware equipment with vendors, where applicable Ensure physical environment in the Data Centre is in normal function (e.g.. UPS, temperature control, humidity, etc.) Account for the inventory of hardware equipment and manage external vendors providing the support Manage the roster in the shift Ensure incidents are responded and attended to, else redirect for 2nd/3rd level resolution base on criticality, impact and SLA. Monitor and ensure timely completion of scheduled batch jobs at end of day Manage and mitigate escalations of high impact system failures and assist in tracking the incidents ","Requirements Diploma with 2 years into Data Centre environment Troubleshoot Data Centre systems/networks to diagnose a problem and administer Perform backup on all systems to ensure recovery of important data in event of system failure. Install Hardware, server, Switches and Appliance. "
/job/application-engineer-smart-systems-ai-data-technology-infineon-technologies-asia-pacific-843285eddedf6ceef0541d567426f31a," Be a member of the Systems team that delivers embedded reference solutions / kits using Infineon semiconductors, microcontrollers Have particular focus to apply artificial intelligence and data technologies and to implement smart connected systems Be responsible for specification, set up and implementation of solution comprising of hardware / circuits and application software, towards target application Deliver on required components to complete a reference solution / demo / kit – including documentation Maintain close cooperation with Marketing, Application teams and Field Application Engineers ","Requirements University degree in Computer Science or Electrical Engineering No prior employment required if you are an active technical hobbyist Coding experience in Python  Experience with embedded system development using C-language Understanding of electronics / electrical circuits, can debug the system Experience in embedded Linux is preferred Microcontroller and standard peripherals know-how is preferred A team self-motivator, demonstrated ability to independently explore and acquire new technologies to enable his project Able to travel occasionally when required "
/job/avp-data-engineer-ibg-digital-institutional-banking-group-dbs-bank-1f257f3fe7b5eebd4832a6d4f3f9bfe6,"Job Purpose  The Data Engineer will provide big data engineering support to the Institutional Banking Group (IBG) Business Analytics Team in various data science projects. This role’s primary job responsibility is defining the framework and process for preparing data for analytical uses. The right candidate will be one excited by the prospect of designing data engineering solutions from ground up and will support data analysts and data scientists on data initiatives and will ensure optimal data delivery architecture is consistent throughout ongoing projects. Responsibilities  Create and maintain optimal data pipeline architecture; Assemble large, complex data sets that meet functional / non-functional business requirements; Identify, design, and implement internal process improvements: automating manual processes, Perform ETL/ELT, Data Modelling, Data Profiling, Data Cleansing, Feature Engineering tasks as part of Data Analytics Life Cycle (DALC); Work with stakeholders (data analysts, data scientists, technology support team) to assist with data-related technical issues and support data infrastructure needs; Build processes supporting data transformation, data structures, dependency and workload management ","Requirements Master’s Degree in software Engineering, Computer Science or related fields with minimum 3 years data engineering work experience in big data analytics environment Strong in data engineering skills with big data stack (Hadoop, Spark, Kafka, etc) Strong in transactional SQL, Enterprise Data Warehouse Experience with Graph Database, NoSQL databases Experience with Feature Engineering Experience with Master Data Management Experience with scripting languages: UNIX/Linux Shell, SQL, Python (Pandas, PySpark etc), Scala, R, etc "
/job/senior-associate-data-engineer-ibg-digital-institutional-banking-group-dbs-bank-89827330ea0c49864b2a6ea27caa1932,"Job Purpose  The Data Engineer will provide big data engineering support to the Institutional Banking Group (IBG) Business Analytics Team in various data science projects. This role’s primary job responsibility is defining the framework and process for preparing data for analytical uses. The right candidate will be one excited by the prospect of designing data engineering solutions from ground up and will support data analysts and data scientists on data initiatives and will ensure optimal data delivery architecture is consistent throughout ongoing projects. Responsibilities  Create and maintain optimal data pipeline architecture; Assemble large, complex data sets that meet functional / non-functional business requirements; Identify, design, and implement internal process improvements: automating manual processes, Perform ETL/ELT, Data Modelling, Data Profiling, Data Cleansing, Feature Engineering tasks as part of Data Analytics Life Cycle (DALC); Work with stakeholders (data analysts, data scientists, technology support team) to assist with data-related technical issues and support data infrastructure needs; Build processes supporting data transformation, data structures, dependency and workload management ","Requirements Master’s Degree in software Engineering, Computer Science or related fields with minimum 3 years data engineering work experience in big data analytics environment Strong in data engineering skills with big data stack (Hadoop, Spark, Kafka, etc) Strong in transactional SQL, Enterprise Data Warehouse Experience with Graph Database, NoSQL databases Experience with Feature Engineering Experience with Master Data Management Experience with scripting languages: UNIX/Linux Shell, SQL, Python (Pandas, PySpark etc), Scala, R, etc "
/job/data-engineer-moka-technology-solutions-9a2882ca74c6e52d5a8f33fbc7a5a572,"Do you have a passion for data? Are you looking to push the frontiers of innovation and build the Next Big Data Product? We are looking for excellent Data Engineers who are keen to help us manage the end-to-end data pipeline and drive big data solutions.  You will:  Design, implement and manage end to end data pipelines (ETL, data streaming and warehousing) so as to make data easily accessible for analysis. Integrate with third party APIs for accessing external data. Create and maintain data warehouses for reporting or analysis. Consult and partner with engineering and product teams to execute data-related product initiatives. Ability to quickly resolve performance and systems incidents. Evaluate the latest monitoring and automation tools. ","RequirementsYou have:  BS (MS preferred) in Computer Science or Computer Engineering. Excellent software engineering skills and proven track record (4+ years experience) in building automated, scalable and robust data processing systems. Proficiency in SQL, bash scripts and Python (or similar languages). Intermediate understanding of database technologies. Experience with data warehouse systems (e.g. Redshift) and batch/semi-online building blocks (e.g. MapReduce, Spark etc). Demonstrated expertise in working with large scale quantitative data. Excellent attention to detail and team player. "
/job/data-engineer-prudential-assurance-company-singapore-a16594f4efee319e982c895bbf67e8ed,"Job Description Summary In this role, you will design, develop and provide support for various data systems (based on both traditional RDBMS and big data platform) in Prudential Singapore. As part of this dynamic role, you will report to Lead System Analyst, and work closely with business units and other IT teams to deliver leading edge technology to enable digital capabilities of Prudential Singapore.  Analyse business needs in order to design, develop and deliver data solutions to meet business objectives Provide application maintenance and support for various data systems in accordance to Service Level Agreement Deliver data solutions in accordance to relevant IT policies and procedures Provide and share knowledge to other team members ","RequirementsCompetencies & Personal Traits    Independent and works well across different functions   Excellent problem analysis skill. Innovative and creative in developing solutions   Strong sense of drive and commitment to deliver on responsibilities   Strong verbal and written communication skills   Works well in a dynamic environment   Ability and willingness to be hands-on   Experience in 2 or more of the following technology: 	 RDBMS: Oracle, Postgres, MSSQL, Netezza ETL and Data Integration Tools:  IBM Datastage, Pentaho, Talend, Attunity BI Tools: PowerBI, Qlik Big Data: Hadoop (Hortonworks), Hive QL, Spark, Sqoop, etc Programming and Scripting: Linux/Unix Shell Scripting, Java, Scala, Hive QL, PL/SQL, NoSQL      Working Experience:    2-8 years in designing and developing and support applications. Fresh graduates are welcome to apply   Experience in Agile software development    Education    Bachelor in Computer Science, Computer Engineering or equivalent   "
/job/data-center-operations-engineer-mcits-technologies-6ce1bdabdd4547c748dbc3a13f1ace8a,"  Minimum GCE ‘O’ Level holder or diploma, preferably in Information Technology discipline, or equivalent required  Applicant with minimum of 3 to 5 years’ Data Center experience and supporting multi-vendor environment preferred  Experience in BMC Control-M Batch Scheduler and Veritas Netbackup preferred  Must be detail oriented, highly organized and able to multi task in an efficient manner  Applicant with knowledge of Sun Solaris, HP UX, MS Windows and Microsoft Office mandatory  Familiar with hardware/software components and terminology preferred  Experience in analyzing hardware and software problems and making quick diagnosis preferred  Must be willing to work in a rotating shift and additional hours to support the team as required, including major public holidays  Strong ethics, integrity and genuine concern for the needs of others. Must be a team player  Applicant with customer service background desired but not a must  Ability to work in a team environment, and also able to work under pressure with minimum supervision  Good initiatives, proactive with good command of spoken and written English ","Requirements Batch Job Management   Ensure Daily Batch Jobs for Billing and Revenue Collection are executed correctly and on time using a Enterprise Batch Scheduling tool.  Monitor the progress of jobs execution and escalation to Application Support when necessary.  Provide 1st Level Incident Management/Troubleshooting and act as point of contact with Banks and Merchants to resolve issues.  Ensure batch processing is on schedule and monitor all system and batch jobs status.  Respond to all user enquiries regarding system functionalities or billing and payment processing.  Participate in UAT to ensure that new job function(s) are adhered to defined standards and specification.  Tape Backup and Management   Ensure daily tape backup are executed as scheduled and completed successfully.  Provide 1st Level Incident management/troubleshooting and escalate to engineering support when necessary.  Provide backup jobs status/progress monitoring.  Facility Management   Ensure Data Centre is operationally 24 x 7.  Responsible for physical security of the Data Center as defined in the Corporate Security Policy and standards.  Ensure Data Centre air conditioning units, lights and temperature are functional and within normal operational standards.  Work as part of a team providing coverage on a 7 day a week, 24 hour per day (24/7) basis including public holidays, on a 12 hour rotating shift basis.  Remote Hand Service   Provide vendor escorting service when in StarHub secured facilities.  Provide basic cabling support like loose cable verification, connecting pre-laid cable – patching, etc.  Provide visual checks and verifications of equipment (power cycle, equipment indicators, inspection of equipment, hardware reset.)  Provide basic checks on environmental conditions in the Data Centre.  Provide basic data media loading/unloading.  Provide hardware replacement of systems (parts replacement – interface card & installation, slotting/removal of blades/line cards, movement of equipments).  Assist in the loading/unloading of tapes to StarHub Tape Library using an enterprise backup application.  Assist in the labelling of Tape media.  Keep inventories of the movement of tape using TMS (Tape Management System). "
/job/research-engineer-astar-research-entities-3a3c70eb175dd9ae8a2f7e8e44fa9c60,He/She will mainly work on data preprocessing and preliminary analysis for dengue risk modeling research in this project. He/She will also be responsible for database construction and maintenance in this project and assist research scientist to fulfil the research tasks and deliverables.,"Requirements Master/Bachelor Degree in mathematics, engineering and electronics With good programming experiences and capabilities in python, c sharp, R and Java Experience in data analysis, parallel computing, optimization, agent-based simulation, and/or visualization is an added advantage "
/job/bigdata-engineer-helius-technologies-1b9774ae6562ff847639b9148fc59f6f,"We are looking for a Senior Big data engineer with python background to help us build and evolve Data Management Platform. Your primary focus will be the development of all server-side backend logic, ensuring high performance and responsiveness to requests from the front-end / API requests.","RequirementsBig Data:  2+ years of working experience in enterprise level big data projects. Should have strong understanding of Distributed computing environment In-depth knowledge of  Hadoop ecosystem tools (HDFS, YARN, MapReduce, Hive, Zookeeper, Amabri, etc.) Scripting Data Pipelines (Apache Hive / PIG) Good understanding of  Storm and MongoDB Architecture Required  Python:  5+ years of experience working  in the enterprise setting developing python applications in multiple projects. Experience writing python applications that interact with  ORM (Object Relational Mapper) libraries Able to integrate multiple data sources and databases. Strong unit test and debugging skills Strong knowledgeable in XML and JSON parsing in python. Developing ETL processing in python as needed.  Other desired skills:  Added advantage if the candidate has  java  experience/background. Basic  experience with SQL, data analysis and linux shell scripting. Knowledge in Kafka, message queues. Worked with rest APIs. Proficient understanding of code versioning, unit testing tools (e.g. Git) An excellent team player and communicator who can work effectively with cross functional teams. Flexible to work in PST or SGT on weekdays and be On-call during weekends in shift model as situation demands. Willingness to learn new tools as needed. "
/job/data-engineer-fixed-mobile-2215e8a8684aaa50c17489883ae473b0,"TransferTo operates a leading global digital value services network offering safe, reliable and more accessible mobile value services for emerging markets. Our B2B cross-border network interconnects and provides mobile operators, money transfer operators, retailers, distributors, NGOs and corporates with unparalleled infrastructure and reach to offer solutions that better connect loved ones across borders. A career with TransferTo provides invaluable experience in an exciting and rapidly expanding market and an opportunity to be part of a truly global company with 7 offices worldwide and a workforce that includes over 50 different nationalities. The Data Science & Data Engineering department is focusing on the creation of new data sciences capabilities for the business by envisioning and executing strategies that will improve performance by enabling informed decision making. We are seeking an energetic and passionate data engineer to help build the robust foundations that will support current and future data-intensive computations across the company. As a Data Engineer, you will be working closely with the Infrastructure, Software development, Business Intelligence and Data Science teams. You will have the opportunity to shape our data stack, ensuring that our ever-flowing data is adequately collected, organized and made accessible for advanced analytics and beyond. Key Role Responsibilities  Build a reliable, scalable and efficient cloud-based data processing platform and applications Play a central role in delivering our next generation real-time, big data platform Conceive, develop, monitor and optimize reliable data pipelines that convert data into insights Be involved in whole data platform development process including infra, data ETL and service implementation  About Us TransferTo operates a leading global digital value services network offering safe, reliable and more accessible mobile value services for emerging markets. Our B2B cross-border network interconnects and provides mobile operators, money transfer operators, retailers, distributors, NGOs and corporates with unparalleled infrastructure and reach to offer solutions that better connect loved ones across borders. For more information, visitwww.transfer-to.com/digitalvalue","RequirementsEssential Experience  More than 3 years of experience in data engineering Advanced knowledge of real-time data streams, ETL processes and how to clean, structure and manage sensitive data effectively Strong development skills in some of the following languages: R, Python, Hive, Pig, Mahout, Java, ... Working knowledge of big data concepts like Hadoop, Spark, MapReduce, and HDFS Deep understanding of both SQL and NoSQL data stores Familiar with data tools and services in Azure, AWS, and/or GCP eco-system is preferred Familiar with data management and visualization tools such as Tableau Knowledge of Amazon AWS services and their applications (RDS, Redshift, S3, EC2, ...) Knowledge in RESTful API development Knowledge in CI tools like Jenkins Knowledge in QA processes and automation Coursework in machine learning, data science, data mining, big data, and/or statistical inference is a plus Comfortable with GIT version control Excellent written and verbal communication skills in English A DevOps attitude - you build it, run it & maintain it The ability to execute independently Enjoy learning and adopting new technologies to push the team forward Thrilled to find creative solutions for the challenges you face Finally, wanting to have responsibilities that make a significant contribution and impact on the company "
/job/data-engineer-hooq-digital-b1e875e5bdf56b69b285c64dccfc666c,"We are looking for a Data Engineer to join our rapidly expanding Data & Analytics team. You will help shape how we build and grow our service in the region. We look for self-starters who demand the best. Key Responsibilities:   Develop ETL/ELT jobs to integrate new data into the data warehouse or build new reporting schemas   Develop data pipelines, both bath and realtime from various platforms into the data lake   Manage various data platforms and seek out new technologies to improve efficiency   Develop advanced analytical models that help the business identify trends within customer base and behavior   Work closely with the business to understand data needs and create data sets to enable reporting and dashboards to monitor business performance   Ensure the data warehouse load jobs run as per schedule and data availability to the business is uninterrupted   Continuously improve the information management platforms of the company to leverage benefits ","RequirementsDesired Skills and Experience  Minimum 3 years of solid development experience within a data warehouse/information management team with strong understanding of programming languages like Java, Python, JavaScript and SQL.   Hands on experience in full-stack development, design and architecture. Experience in creating a REST API that can handle a production load (code + deploy).   Familiarity with AWS (DynamoDB, Redshift, S3, EC2, RDS, Lambda) (Will be an advantage but not mandatory)   Minimum 3 years development experience with ETL/ELT tools (preferably Pentaho DI, Informatica, Datastage or Talend)   Proven experience with Data Warehousing and Big Data technologies   Working knowledge of big Data Technologies like Hadoop, Hive, Spark and streaming/messaging services like Kafka,Spark streaming.   Solid understanding of some BI tools such as Cognos, QlikView or Tableau.   Comfortable working in dynamic fast paced environment with competing priorities. Self-starter and willing and able to learn on your own   Work well within a team environment and willing to accommodate task and duties that maybe outside of your JD for limited time periods "
/job/data-technical-support-engineer-talent-trader-group-b95b9c1978e790c94a48ba244a7a8edd," 1st level support on transmission, VoIP services and switching equipment  Manage ticket queue and responsibility for the issues Provide technical support through emails, tickets and phone Manage the network and systems for internal issues Responsible for support and maintenance for tracking, documentation and verification Arrange the roster shift for the team members ","Requirements Hands-on experience in network concepts Comfortable to work in Data Centre environment Independent, self-motivated and dynamic personality Experience in Data Centre NOC    Interested candidates who wish to apply for the advertised position, please email us an updated copy of your resume to; Email Address: it@talenttradergroup.com   EA License No.: 13C6305 Registration ID: R1333012   For candidate who applied for the advertised position is deemed to have consented to us that we may collect, use or disclosed your personal information for purpose in connection with the services provided by us.  "
/job/data-centre-technical-engineer-7419e3f2257cd519bb62f11f7fdfc090,"- Provide infrastructure and security monitoring/support for a 24x7 data centre.  - Carry out service requests which include code deployment, restart servers - VM - backup - storage, manage batch job processing, perform security scanning, escort duty etc.   ","Requirements  - At least 3-4 years of relevant working experieces - Experiences in IBM System Storage, Microsoft Windows Server Administration, NetBackup Backup Operations         Licence No: 12C6060"
/job/cyber-security-big-data-engineer-2971a7516b523a443afe3df36cb834a9,"Working in Cybersecurity takes pure passion for technology, speed, a constant desire to learn, and above all, vigilance in keeping every last asset safe and sound. You’ll be on the front lines of innovation, working with a highly-motivated team laser-focused on analyzing, designing, developing and delivering solutions built to stop adversaries and strengthen our operations. Your research and work will ensure stability, capacity and resiliency of our products in emerging industry trends. Working in tandem with your internal team, as well as technologists and innovators across our global network, your ability to identify threats, provide intelligent analysis and positive actions will stop adversaries and strengthen our products.   Responsibilities  Focus on the development of tools and technologies that are at the core of the company’s capabilities to manage, monitor and hunt for cyber security incidents Architecture and development of large scale solution (big data) to be used in a very large production environment System, network and application troubleshooting Provide engineering support for cyber security products developed ","Requirements Knowledge of Cybersecurity organization practices, operations, risk management processes, principles, architectural requirements, engineering and threats and vulnerabilities, including incident response methodologies Ability to collaborate with high-performing teams and individuals throughout taghe firm to accomplish common goals Proficiency in the use of skills tools, staying current with skills, participating in multiple forums Experience with Agile and can work with at least one of the common frameworks is highly desired Ability to analyze vulnerabilities, threats, designs, procedures and architectural design, producing reports and sharing intelligence Strong research, analytical and problem solving skills Independent problem-solving, highly motivated and self-directing Ability to write and debug administrative and reporting tools in some programming languages (Shell/Perl or Python, Scala/Java/R, C/C++, HTML5, or other experiences acceptable) Comfortable with most aspect of operating system administration such as tweaking, hardening and configuring services A solid understanding of Unix-based operating systems, including paging/swapping, IPC, drivers and filesystem (inode, partitions, etc.) Experience with host and network security (identity/password management, ACLs, file permissions and integrity) Strong interpersonal and communication skills; capable of writing documentation, training users in complex topics, making presentations to junior and very senior audience Ability to work under pressure in a fast-paced environment while remaining productive and professional; exercise patience and ability to multi task    Bonus Points  Experience with hadoop ecosystem: Hadoop, Spark, Map/Reduce, Hive/Pig, Impala/Drill, etc. Experience with Data Science: MLlib, Scikit, h2o, TensorFlow, Pytorch, Caffe, Singa, etc. Experience with NoSQL stacks: Elasticsearch, MongoDB, etc. Experience with SIEM products: Qradar, Arcsight, Splunk, etc. Experience with messaging and data transport tools: Kafka, NiFi, LogStash, Syslog-ng, rsyslog, etc. Experience with Link Analysis tools and GraphDBs Experience with data visualization tools: Hue, Kibana, Qlikview, Tableau, etc. Knowledge in RIA: HTML5, node.js, bootstrap, angular, extJS, etc. "
/job/facilities-engineer-supreme-hr-advisory-893461e81cb7a2343b546240e2afb8ee,"• Attractive salary packages • Company Bonuses, Benefits & Privileges • Career Progression Opportunities   Interested applicants can send your resume to supreme.cathrynteng@gmail.com and allow our Consultants to match you with our Clients. No Charges will be incurred by Candidates for any service rendered.   Role:  Daily health check non-critical/critical facilities & records. Attendance/initial troubleshooting to fault/breakdown/complaint & records. Attend user request for handyman works, eg. Cabinet door faulty, minor shifting etc and report to client CAS for follow up action. Generating the 1st incident report & escalation. Coordination/supervision of contractor's work (maintenance/rectification/fault). Maintaining records for utilities,chilled water & condenser water usage/monthly work carried out/monthly fault call-out /outstanding works. Coordination/supervision of landlord on building related work (aircon,toilet, lighting,etc). Reporting of abnormality. 7 days/24 hours standby for any M & E related emergency call out. Monitoring of FMAS on Data Centre M & E facilities. Scheduling of FCUs and AHUs for aircon extension request. Obtain quotation for maintenance and improvement works from vendors/contractors. Carry out duties in accordance with QEHS policy, procedures and work instructions. Aware of the legal and other requirements and significant environment aspects/impacts (EAI) and occupational safety and health hazard/risks associated with their work activities.  Requirement:  Minimum qualification Diploma or equivalent. Minimum experience 2 years & above in relevant field. Tactful, analytical skills and responsible. Experience in Data Centre, M&E and facilities management is a must. Willing to standby for emergency call out.    Please include the following in your Resume Document * (*.DOC/PDF - Files should not exceed 2MB)    • Name    • Contact No.    • Nationality/PR Status    • Location/Address    • Recent Photo    • Expected Salary.","Requirements• Attractive salary packages • Company Bonuses, Benefits & Privileges • Career Progression Opportunities   Interested applicants can send your resume to supreme.cathrynteng@gmail.com and allow our Consultants to match you with our Clients. No Charges will be incurred by Candidates for any service rendered.   Role:  Daily health check non-critical/critical facilities & records. Attendance/initial troubleshooting to fault/breakdown/complaint & records. Attend user request for handyman works, eg. Cabinet door faulty, minor shifting etc and report to client CAS for follow up action. Generating the 1st incident report & escalation. Coordination/supervision of contractor's work (maintenance/rectification/fault). Maintaining records for utilities,chilled water & condenser water usage/monthly work carried out/monthly fault call-out /outstanding works. Coordination/supervision of landlord on building related work (aircon,toilet, lighting,etc). Reporting of abnormality. 7 days/24 hours standby for any M & E related emergency call out. Monitoring of FMAS on Data Centre M & E facilities. Scheduling of FCUs and AHUs for aircon extension request. Obtain quotation for maintenance and improvement works from vendors/contractors. Carry out duties in accordance with QEHS policy, procedures and work instructions. Aware of the legal and other requirements and significant environment aspects/impacts (EAI) and occupational safety and health hazard/risks associated with their work activities.  Requirement:  Minimum qualification Diploma or equivalent. Minimum experience 2 years & above in relevant field. Tactful, analytical skills and responsible. Experience in Data Centre, M&E and facilities management is a must. Willing to standby for emergency call out.    Please include the following in your Resume Document * (*.DOC/PDF - Files should not exceed 2MB)    • Name    • Contact No.    • Nationality/PR Status    • Location/Address    • Recent Photo    • Expected Salary."
/job/data-engineer-fpt-information-system-singapore-bc0291fbb49ac5361cc9a5932c5b59d7,"We are looking for data engineers resources to develop data & ingestions into our data lake, build data marts, etc. Responsibilities include,   •             Understand business processes, applications and how data is stored and gathered. •             Develop and manage streaming data pipelines at enterprise scale. •             Build expertise on the data. Own data quality for various data flows. •             Design, build and manage data marts to satisfy our growing data needs. •             Support data marts to provide intuitive analytics for internal customers. •             Design and build new framework and automation tools to enable teams to consume and understand data faster. •             Coding across a number of languages like SQL, Python and Java to support data scientists. •             Interface with internal customers to understand data needs. •             Collaborate with multiple teams and own the solution end-to-end. •             Maintain infrastructure for our data pipelines.","RequirementsCandidate will work with our client data engineers and must have the following skillsets and experience, •             BS degree in Computer Science or a related technical field. MS or PhD degree is a plus. •             2+ years of advanced Python or Java development is necessary. Scala or Kotlin experience is a plus. •             2+ years of SQL (such as PostgreSQL, Oracle, AWS Redshift, or Hive) experience is required. NoSQL experience is a plus. •             2+ years working with Linux OS. Knowledge of networks and cybersecurity is a plus. •             Experience with modern MapReduce/workflow distributed systems, especially Apache Spark. Experience with Apache Kafka is a plus. •             Experience working with infrastructure-as-code systems like AWS CloudFormation. DevOps experience is a plus. •             Experience in custom ETL pipeline design, implementation and maintenance. •             Experience working with visualization tools like Tableau or Apache Superset. •             Ability in analyzing data to identify deliverables, gaps and inconsistencies. •             Ability in managing and communicating data mart plans to internal customers."
/job/data-center-operator-noc-engineer-7dbd8853ca265ffd8349c429114e38bc,"- Administration and management of IT Infrastructure and data centre support, which include basic systems, network, database and application support. - Respond to the incoming alerts (system triggered, e-mail etc.) - Manage, track, record and follow up on incident tickets or service requests in Service Management Systems. - Follow documented support procedures for incident management, which include identifying and determining the root cause and resolving the incident or escalate to the appropriate resolver group according to SLA (Service level Agreement). - Maintenance of technical documentation of processes and procedures used throughout normal operations.",Requirements- Diploma in Electrical / Electronic / Computer Engineering / Information Systems - Experience in Data Center Operation or NOC - Possess basic working knowledge and hands-on experience in Windows Server and/or Linux and/or Unix Systems administration - Good analytical and troubleshooting skills in the area of technical fault isolation and rectification. - Willing and able to perform 12-hour Shift Work   Licence No: 12C6060
/job/devops-engineer-data-science-artificial-intelligence-government-technology-agency-ed592471e3bf926a6bcee241bc6dfe58,"The Government Technology Agency (GovTech) aims to transform the delivery of Government digital services by taking an ""outside-in"" view, putting citizens and businesses at the heart of everything we do. We also develop the Smart Nation infrastructure and applications, and facilitate collaboration with citizens and businesses to co-develop technologies. Join us as we support Singapore’s vision of building a Smart Nation - a nation of possibilities empowered through info-communications technology and related engineering. Who we are: GovTech's Data Science and Artificial Intelligence team uses technology and data to help deliver high-quality digital services to citizens and businesses in Singapore. We build software for government agencies to better understand and use their data to improve operations and decision making. What the role is: You will work on both small and large scale projects, building and maintaining the infrastructure behind them. We are fully aligned with the Government’s cloud-first policy and you will bring capability to help us realise this. The role includes:  Managing the development, deployment, orchestration and maintenance of data pipelines for our Data Science products Providing DevOps architecture implementation and operational support Architecture and planning for cloud deployments (Private and Public cloud) Developing and managing processes, automation, best practices, documentation Development and operation of continuous integration and deployment pipelines.   What it is like working here: We build products that serve a variety of agency users, who use them to solve highly meaningful problems pertinent to our society, from transportation, to education, to healthcare. You are expected to have ownership over the problems that you solve. This means having ideas on how things should be done and taking responsibility for seeing them through. Building something that you believe in is the best way to build something good. As we often deal with big data and computing requirements, you are also able to take a long-term strategic view of the platforms you work on, and help provide this perspective to the team. To do so, you will:  Effectively prioritise and execute tasks in a high-pressure environment  Develop and maintain internal engineering productivity tools and environments Perform independent research into product and environment issues as required  Monitoring automation to effectively detect/predict/prevent issues in the environment and code base Future-proofing the technical environments and ensuring extreme high levels of automation, availability, scalability and resilience Hands-on coding and mentoring, working in highly collaborative teams and building quality environments Have knowledge in and/or continuously learn lots of different open source technologies and configurations  What we are looking for: The customers for our products are normally agency users, which means that breadth of knowledge in government IT infrastructure and experience in government networks will help. Since our direction is cloud-first, you will likely have some experience in patch/update scheduling, and knowledge of security incident response procedures. A disciplined approach and strong problem-solving instincts are fundamental to succeed. Your aptitude for completing the tasks and attitude to continuous learning are more valued than any formal certification. To succeed you will need to possess some of the following:  Excellent problem solving and methodical troubleshooting skills Strong knowledge and experience in DevOps automation, containerisation and orchestration using tools eg. Ansible, Airflow, Docker, Kubernetes, Terraform, Artifactory/Nexus Sonatype Cloud computing deployment and management experience in AWS, GCP Strong scripting skills e.g. Python, Bash, JavaScript, Scala, Rust, Go Strong understanding of Apache Spark/Flink, Hadoop, distributed file systems and resource scaling/scheduling, streaming message queues (RabbitMQ, Kafka) Strong understanding of virtualization and networking concepts Experience with patch maintenance, regression testing and security incident response Experience with interactive workloads, machine learning toolkits and how they integrate with cloud computing e.g. Databricks, KX Experience with highly scalable distributed systems Experience with on-premise deployments, government application and networking infrastructure/routing Breadth of knowledge - OS, networking, distributed computing, cloud computing ",Not Available
/job/big-data-architect-sciente-international-46e81b9e0a43e56b9af6161855b379f1,"Our client is looking for an experienced Data Architect who will be responsible to design and implement Big Data Platform, providing leadership for data management at the enterprise level such as data modeling, metadata management and infrastructure.","RequirementsMandatory Skill-set  At least Degree in Computer Science or Information Technology; Minimum 10 years of experience in data management involving architecture, design and development of data management solutions and data governance policies/standards; Experience in implementation of Big data platform and datawarehouse projects; Should be familiar with industry architectural standards like TOGAF, FEA and/or Zachman; Expertise Enterprise Metadata Management, Object Management Group standards & Information management program life cycle, process modeling, semantic modeling and data modelling; Familiarity with industry data models such as IBM BDW and IIW, Teradata FSLDM, and SAS IIA; Solid knowledge of the organization's industry and its challenges in the use of data and information; Proven track record in successful end-to-end data warehousing project implementation experience; Adept in leveraging latest technologies, best practices and lead in formation of effective information analytics expertise; Comfortable to tackle complex and technical development and learn new technologies to support business solutions; Ability to help define and articulate the enterprise data management strategic vision and translate it into tactical implementable steps to senior stakeholders.  Desired Skill-set  TOGAF certified; Financial services industry experience specifically in risk, finance and customer.  Responsibilities  Lead and facilitate techno-functional design workshops & project implementation involving big data platform,data analytics solutions & data visualisation ; Conduct Proof of Concepts (POCs),develop and evaluate technical solutions in area of AI and Analytics; Establish and govern of checklists/standards/guidelines, processes, frameworks, tools and best practices for process modeling, semantic modeling, and logical and physical data modeling; Manage the standard information architecture best practices in accordance with enterprise’s overall architecture; Manage and understand data flows/lineage of operational data sources to analytical data sources; Review and approve project designs including data architecture, models and ETL including creation of ETL specifications/documentation; Development and maintenance of corporate data architecture, data management standards and conventions, data dictionaries and data element naming standards and conventions for multiple computing environments; Work with Information Security to ensure proper classification and protection of enterprise data; Continuously keep abreast, evaluate, research alternative/better solutions for efficient and cost effective data solutions for improved data integrity; Explore emerging technologies to assess their relevance/viability in solving on-going information management challenges e.g.Cloud Computing, Big Data, Datavisualization/masking, Enterprise business metadata management and Data SOA.  Should you be interested in this opportunity, please send your updated resume to apply@sciente.com at the earliest. Confidentiality is assured, and only shortlisted candidates will be notified. EA License: 07C5639    "
/job/senior-data-architect-manager-de644eab3ea893c1e4f08a31743aeb76,"PURPOSE You will be an individual contributor in a highly entrepreneurial work environment, responsible for planning and implementing data architecture, data warehouse and data lake across FWD group. KEY ACCOUNTABILITIES Lead big data and data warehouse implementation in FWD countries.","RequirementsQUALIFICATIONS / EXPERIENCE  Minimum 10 years of professional experience in big data, data warehousing, operational data stores, and large scale architecture and implementations.  KNOWLEDGE & TECHNICAL SKILLS  Expertise in Big Data and Data Lake technologies. Experience with Hadoop, Spark, Hortonwork, MapR, Cloudera, RDBMS, Hbase, and Stream Processing. Experience with ETL, Talend, Informatica. Experience in solution crafting and developing proposals to illustrate business value provided by technical solutions. Strong understanding of data analytics and data visualization. Ability to provide strategic and architectural direction to address unique consortium problems. System design and modeling skills (e.g. domain driven design, data modeling, API design). Excellent communication and presentation skills, specifically able to convey technical information in a clear and unambiguous manner.  Drive change management of new data capabilities and architectural direction. "
/job/senior-data-architect-manager-8d4b8e6c618b15bcfbc50e9f80b0c61d,"PURPOSE  Analyse database implementation methods to make sure they are in line with company policies and any external regulations that may apply Provide insight into the changing database storage and utilization requirements for the company and offer suggestions for solutions Develop database design and architecture documentation for the management and executive teams Provide insight into leading analytic practices, design and lead iterative learning and development cycles, and ultimately produce new and creative analytic solutions that will become part of our core deliverables. Meet user reporting & analytical requirements for the development and maintenance of system. ","RequirementsQUALIFICATIONS / EXPERIENCE  University degree or equivalent professional qualification 10 years of enterprise data warehouse/ data lake experience with at-least 4 years of experience with ETL/data mart Proven experience in developing and managing EDW or ODS projects in insurance domain. Should have had experience of building data lake solutions on AWS stack Should have had experience on BI tools like Qlik / BO / Cognos Experience and understanding of data sources including 3rd party RDBMS, MS access, SQL server and oracle Demonstrate strong written and verbal communication and decision making skills Strong analytic, problem solving, negotiation, issue resolution and facilitation skills are required Familiarity with Insurance domain& systems Experience on Data Modeling Experience in Qlik/Tableau will be a plus  KNOWLEDGE & TECHNICAL SKILLS  Hands-on analyst, technologist with good experience in Information management, data warehousing and analytics technologies to provide   The tactical and strategic direction in the areas of business intelligence analytics, data mining and visualization Assessment of data quality and consistency across platforms, products and geographical areas.   Prior experience in BI / DW / Analytics implementation is a must. "
/job/data-management-consultant-capgemini-singapore-68db2ab2945c5f1207829a4b621d42b6, Architect the data flow from On premise to cloud and engage with information security for CRP reviews Liaise with the Infrastructure team to optimise the technical specs required for new or existing data platform setup. Providing Best practices of data management. Provide Estimates for new development and customizations Vendor Management - Manage service delivery and provide support in commercials. Relationship management with key client stakeholders and incubation of new business ideas ,"Requirements Technical Skills – Microsoft Azure, SQL Server Data onboarding - For Azure Data lake and data warehouse Security and access management for Azure resources Teradata experience is preferred "
/job/data-architect-sandbox-consulting-9ecb1315d194a64bc7040b665dbc8f80,"Delivering New Application Solution and Design Business engagement – requirements analysis, acts as a product owner and prioritize backlog Hands on Development on frameworks Subject matter expert in any one of these domains – E/M-Commerce, Customer / Partner relationship management, Card & Wallet Payment Landscape(initiation to settlement), Gaming Distribution and Gamer Community, Small & Medium Enterprises Define system-level application architecture that includes high-level design, architectural policies and principles, design and programming guidelines, implementation risks and mitigation measures, software development and integration strategies, software configuration controls, etc Maintain control over the solution throughout the entire software development lifecycle by continuously making critical adjustments to the solution to ensure desired results are achieved  Involve in requirement analysis phase to ensure the implementation feasibility of functional specifications. Highlight requirement gaps, disproportional construction efforts, technical challenges and any other issues to business analyst teams Provide technical leadership in the development through established design and development methodologies, to ensure system meets functional and system requirements  Engage customers to explain the rationale of architecture’s selection, or other technical issues Ensure best practices, frameworks and re-useable components are employed in the development project Understand Information Security standards, methodologies and practices. Design and deliver complex security solutions that integrate an effective and efficient network infrastructure design. Trouble-shoot technical problems faced by the team. Experience in designing solutions using appropriate platforms and system technologies such as enterprise database design, web and application server and network technologies  Experience in payment or telco billing related system is good to have. Ability to lead, develop and maintain respectful and trusting relationship; Ability to setup the product backlogs for iterative development Proficient in written and spoken English Able to travel as required   Primary Skill Set Good working knowledge of Amazon Cloud Services such as EC2, EBS, S3, ELB, ElasticCache, CloudFront, Route53, RDS, Kinesis, DynamoDB, etc Data Modeling Experience, designing LDM/PDM using RDBMS or NoSQL Database migration experience (e.g. upgrading RDBMS versions, moving from RDBMS to NoSQL) Practical knowledge in Agile and DevOps environments, open source technologies and related tools.","RequirementsDelivering New Application Solution and Design Business engagement – requirements analysis, acts as a product owner and prioritize backlog Hands on Development on frameworks Subject matter expert in any one of these domains – E/M-Commerce, Customer / Partner relationship management, Card & Wallet Payment Landscape(initiation to settlement), Gaming Distribution and Gamer Community, Small & Medium Enterprises Define system-level application architecture that includes high-level design, architectural policies and principles, design and programming guidelines, implementation risks and mitigation measures, software development and integration strategies, software configuration controls, etc Maintain control over the solution throughout the entire software development lifecycle by continuously making critical adjustments to the solution to ensure desired results are achieved  Involve in requirement analysis phase to ensure the implementation feasibility of functional specifications. Highlight requirement gaps, disproportional construction efforts, technical challenges and any other issues to business analyst teams Provide technical leadership in the development through established design and development methodologies, to ensure system meets functional and system requirements  Engage customers to explain the rationale of architecture’s selection, or other technical issues Ensure best practices, frameworks and re-useable components are employed in the development project Understand Information Security standards, methodologies and practices. Design and deliver complex security solutions that integrate an effective and efficient network infrastructure design. Trouble-shoot technical problems faced by the team. Experience in designing solutions using appropriate platforms and system technologies such as enterprise database design, web and application server and network technologies  Experience in payment or telco billing related system is good to have. Ability to lead, develop and maintain respectful and trusting relationship; Ability to setup the product backlogs for iterative development Proficient in written and spoken English Able to travel as required   Primary Skill Set Good working knowledge of Amazon Cloud Services such as EC2, EBS, S3, ELB, ElasticCache, CloudFront, Route53, RDS, Kinesis, DynamoDB, etc Data Modeling Experience, designing LDM/PDM using RDBMS or NoSQL Database migration experience (e.g. upgrading RDBMS versions, moving from RDBMS to NoSQL) Practical knowledge in Agile and DevOps environments, open source technologies and related tools."
